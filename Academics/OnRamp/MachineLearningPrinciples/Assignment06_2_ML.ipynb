{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Assignment 6B__\n",
    "\n",
    "1. [Import](#Import)\n",
    "1. [Assignment 6B](#Assignment-6B)\n",
    "    1. [Load-data](#load-data)\n",
    "    1. [Cross-validation](#Cross-validation)    \n",
    "    1. [Evaluation](#Evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Import'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T18:35:12.414233Z",
     "start_time": "2018-12-01T18:35:12.406063Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:88% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold, StratifiedShuffleSplit, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "np.set_printoptions(threshold = np.inf, suppress = True)\n",
    "from IPython.core.display import display, HTML; display(HTML(\"<style>.container { width:88% !important; }</style>\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 6B\n",
    "Assignment Content:\n",
    "\n",
    "1. Using the dataset tae.data implement two different cross-validation procedures in the following way:\n",
    "\n",
    "    - Import data\n",
    "    - Split data as needed into training and test sets\n",
    "    - Fit a decision tree algorithm to the training data (Hint: we did this in the Decision Tree module)\n",
    "    - Test the trained decision tree to the test data\n",
    "    - Evaluate the performance of the decision tree on the test data reporting error rate or accuracy rate\n",
    "\n",
    "Deliverables:\n",
    "\n",
    " -Two .ipynb files each pertaining to a different cross-validation procedure and each following steps 1 through 5. The code should also print out the error rate or accuracy rate of the cross-validation procedure (averaged over the number of iterations if needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Assignment-6B'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'load-data'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T18:21:17.727895Z",
     "start_time": "2018-12-01T18:21:17.722160Z"
    }
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "ta_eval_raw = pd.read_csv('tae.data')\n",
    "\n",
    "# split independent and dependent variables\n",
    "X = ta_eval_raw.iloc[:,:-1].values\n",
    "y = ta_eval_raw.iloc[:,-1].values.reshape(-1)\n",
    "\n",
    "# Xtrain, XTest will be used in the CV procedure.\n",
    "# yTrain, yTest is the holdout data set and will be used as a final evaluation of the model\n",
    "# outside of the CV procedure.\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X, y, test_size = 0.1, random_state = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Cross-validation'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T18:35:53.451042Z",
     "start_time": "2018-12-01T18:35:53.437656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual scores: \n",
      " [0.42857142857142855, 0.7142857142857143, 0.6428571428571429, 0.5, 0.7857142857142857, 0.8461538461538461, 0.6923076923076923, 0.6923076923076923, 0.46153846153846156, 0.6923076923076923]\n",
      "\n",
      "Mean score: 0.6456043956043956\n"
     ]
    }
   ],
   "source": [
    "# create decision tree model and evaluate using KFold cross validation\n",
    "decision_tree = tree.DecisionTreeClassifier(random_state = 1)\n",
    "kf = KFold(n_splits = 10, random_state = 1, shuffle = True)\n",
    "\n",
    "scores = []\n",
    "for train_index, test_index in kf.split(XTrain):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    decision_tree.fit(X_train, y_train)\n",
    "    y_pred = decision_tree.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "print('Individual scores: \\n {0}'.format(scores))\n",
    "print('')\n",
    "print('Mean score: {}'.format(np.mean(scores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Remarks - I am intentionally passing in XTrain and yTrain, as opposed to the full dataset comprised by X and y. cross_val_score internally splits the data its given into train and test sets, then performs KFold cross validation. In this case, XTrain and yTrain will be evaluated in 10 folds. Then I will make predictions using XTest and evaluate against yTest, which is truly unseen data in this implementation.\n",
    "\n",
    "> Instead of using cross_val_score, I used KFold to perform a 10 fold split. KFold creates sets of indices that are used for specifying which samples from the training data will be in the training fold or the validation fold. For each split, I fit the decision tree model using the training fold, then calculate the accuracy score on the fold set aside as the validation set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Evaluation'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T18:41:40.898597Z",
     "start_time": "2018-12-01T18:41:40.893537Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future Data Prediction Accuracy: 0.5625%\n"
     ]
    }
   ],
   "source": [
    "# baseline\n",
    "decision_tree.fit(XTrain, yTrain)\n",
    "\n",
    "yPredTest = decision_tree.predict(XTest)\n",
    "\n",
    "print('Future Data Prediction Accuracy: {0}%'.format(sum(yTest == yPredTest) / len(yPredTest)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Remarks - The model's performance on the holdout set is quite a bit worse than the average cross validation accuracy. The cross_validation accuracy is slightly worse in this implementation (with this random number seed)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
