{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Chapter 15 - Classifying Images with Deep Convolutional Neural Networks__\n",
    "\n",
    "1. [Building blocks of convolutional neural networks](#)\n",
    "    1. [Understanding CNNs and learning feature hierarchies](#Understanding-CNNs-and-learning-feature-hierarchies)\n",
    "    1. [Performing discrete convolutions in one dimension](#Performing-discrete-convolutions-in-one-dimension)\n",
    "1. [](#)\n",
    "1. [](#)\n",
    "1. [](#)\n",
    "1. [](#)\n",
    "1. [](#)\n",
    "1. [](#)\n",
    "1. [](#)\n",
    "1. [](#)\n",
    "1. [](#)\n",
    "1. [](#)\n",
    "1. [](#)\n",
    "1. [](#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libary and settings\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import itertools\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "dataPath = os.path.abspath(os.path.join('../../Data'))\n",
    "modulePath = os.path.abspath(os.path.join('../../CustomModules'))\n",
    "sys.path.append(modulePath) if modulePath not in sys.path else None\n",
    "from IPython.core.display import display, HTML; display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "\n",
    "# Data extensions and settings\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold = np.inf, suppress = True)\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.options.display.float_format = '{:,.6f}'.format\n",
    "\n",
    "\n",
    "# Modeling extensions\n",
    "import sklearn.base as base\n",
    "import sklearn.cluster as cluster\n",
    "import sklearn.datasets as datasets\n",
    "import sklearn.decomposition as decomposition\n",
    "import sklearn.discriminant_analysis as discriminant_analysis\n",
    "import sklearn.ensemble as ensemble\n",
    "import sklearn.feature_extraction as feature_extraction\n",
    "import sklearn.feature_selection as feature_selection\n",
    "import sklearn.linear_model as linear_model\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.model_selection as model_selection\n",
    "import sklearn.neighbors as neighbors\n",
    "import sklearn.pipeline as pipeline\n",
    "import sklearn.preprocessing as preprocessing\n",
    "import sklearn.svm as svm\n",
    "import sklearn.tree as tree\n",
    "import sklearn.utils as utils\n",
    "\n",
    "\n",
    "# Visualization extensions and settings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Custom extensions and settings\n",
    "from quickplot import qp, qpUtil, qpStyle\n",
    "from mlTools import powerGridSearch\n",
    "sns.set(rc = qpStyle.rcGrey)\n",
    "\n",
    "\n",
    "# Magic functions\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Building-blocks-of-convolutional-neural-networks'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building blocks of convolutional neural networks\n",
    "\n",
    "Convolutional neural networks (CNNs) were inspired by how the visual cortex of the human brain functions when it is recognizing objects. Due to the high performance of CNNs for image classification, this approach has gained a lot of attention and this led to great improvements in machine learning and computer vision applications. Neural networks are able to automatically learn the features from raw data that are most useful for a particular task. This is why neural networks are often thought of as feature extraction engine: that is, the intial layer that immediately follow the input nodes are those that are used to extract low-level features.\n",
    "\n",
    "Multilayer neural networks, and in particular, deep convolutional neural networks, construct a feature hierarchy by combing low-levek featurs in layer-like fasion to form high-level features. In the context of images, low-level features like edges and blobs are extracted in the early layers, which are combined together to form high-level features that take more familiar shapes, such as buildings, cars or dogs. CNNs contruct feature maps from input images, where each element in the feature map comes from a local patch of pixels in the input images.\n",
    "\n",
    "A local patch of pixels is refered to as the local receptive field. A CNN's performance on image-related tasks is driven by two important concepts:\n",
    "\n",
    "1. Sparse connectivity - A single element in the feature map is connected to just a small patch of pixels, as opposed to the whole input image. The latter is true of perceptrons.\n",
    "2. Parameter sharing - The same weights are used for different patches of the input image.\n",
    "\n",
    "Because of the two concepts, the number of weights in the network drastically decrease, and there is also an improvement in the algorithm's ability to capture salient features. It makes intuitive sense that the nearby pixles are more relevant to each other than pixels that are far away from each other.\n",
    "\n",
    "CNNs are typically composed of several convolutional layers and subsampling/pooling layers that are followed by one or more full connected layers at the end. The fully connected layers are effectively a multilater perceptron, where every input unit $i$ is connected to every output unit $j$ with weight $w_{ij}$. One thing to note about pooling/subsampling layers is that these do not have any learnable parameters - there are no weights or bias units. Both convolutional and fully connected layers have weights and biases to be optimized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Understanding-CNNs-and-learning-feature-hierarchies'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding CNNs and learning feature hierarchies\n",
    "\n",
    "Salient, or relevant, features are essential for high performing machine learning algorithms. Traditional machine learning algorithms rely on features determined by a domain expert, or by some computational feature extraction technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Performing-discrete-convolutions-in-one-dimension'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing discrete convolutions in one dimension\n",
    "\n",
    "A discrete convolution (or just a convolution) is a fundamental concept of CNNs. As a basic example, we can look at a discrete convolution between two on-dimensional vectors $\\textbf{x}$ and $\\textbf{w}$. This is denoted by the formula: $\\textbf{y} = \\textbf{x} * \\textbf{w}$, where vector $\\textbf{x}$ is the input, or signal, and $\\textbf{w}$ is referred to as the filter, or kernel. A discrete convolution is mathematically defined as follows:\n",
    "\n",
    "$$\n",
    "\\textbf{y} = \\textbf{x} * \\textbf{w} \\rightarrow \\textbf{y}[i] = \\sum^\\infty_{k = -\\infty} \\textbf{X}[i - k]\\textbf{w}[k]\n",
    "$$\n",
    "\n",
    "The brackets [] are used to denote the indexing ofr vector elements. The index $i$ runs through each element of the output vector $\\textbf{y}$. To clarify the positive and negative infinity indexing for $\\textbf{x}$. A sum that runs through indices in such as range seems odd because, generally speaking, machine learning applications deal with finite feature vectors. As an example, if vector $\\textbf{x}$ has 10 features with indices 0,1,2,3,4,5,6,7,8,9, then the indices $-\\infty$ to -1 and 10 to $\\infty$ are out of bounds for $\\textbf{x}$. So in order to compute the summation shown in the predecing formula, it is assumed that $\\textbf{x}$ and $\\textbf{w}$ are filled with zero. This results in an output vetor $\\textbf{y}$ that also has an infinite size with lots of zeros as well. Since this isn't useful in practice, $\\textbf{x}$ is padded only with a finite number of zeros. This process is called zero-padding, or just padding. The original vector $\\textbf{x}$, with padding $p$ = 2 zeroes, the vector changes from [3,2,1,7,1,2,5,4] to [0,0,3,2,1,7,1,2,5,4,0,0].\n",
    "\n",
    "Let's assume the original input $\\textbf{x}$ and $\\textbf{w}$ have n and m elements, respectively, where m <= n. So the padded vector $\\textbf{x}^p$ has the size $n + 2p$, and the practical formula for computing a discrete convolution will change to:\n",
    "\n",
    "$$\n",
    "\\textbf{y} = \\textbf{x} * \\textbf{w} \\rightarrow \\textbf{y}[i] = \\sum^{k=m-1}_{k = 0} \\textbf{x}^p[i + m - k]\\textbf{w}[k]\n",
    "$$\n",
    "\n",
    "This solves the infinite index issue. The second issue is indexing $\\textbf{x}$ with $i + m - k$. The problem is that $\\textbf{x}$ and $\\textbf{w}$ are indexed in different directions in this summation. For this reason, we flip one of the vector, could be either one, after adding the padding. Then we can compute their dot product. So if we flip the filter $\\textbf{w}$ to get $\\textbf{w}^r$, then the dot product $\\textbf{x}[i:i+m] \\cdot \\textbf{w}^r$ is computed to get one element $\\textbf{y}[i]$, where $\\textbf{x}[i:i+m]$ is a patch of $\\textbf{x}$ with size m.\n",
    "\n",
    "This is repeated in a way that mimic a window sliding across the image, which gets all of the output elements. A one-dimensional example would be:\n",
    "\n",
    "$$\n",
    "x = (3,2,1,7,1,2,5,4)\n",
    "\\\\\n",
    "w = \\bigg(\\frac{1}{2}, \\frac{3}{4}, 1, \\frac{1}{4}\\bigg)\n",
    "$$\n",
    "\n",
    "If we flip $\\textbf{w}$ we get:\n",
    "\n",
    "$$\n",
    "\\textbf{w}^r = \\bigg(\\frac{1}{4}, 1, \\frac{3}{4}, \\frac{1}{2})\\bigg)\n",
    "$$\n",
    "\n",
    "$m$ = 4, since $\\textbf{w}$ has four elements, so the index takes on the values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = ''></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = ''></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = ''></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = ''></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = ''></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = ''></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = ''></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = ''></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = ''></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = ''></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = ''></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = ''></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
