{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Chapter 14 - Going Deeper â€“ The Mechanics of TensorFlow__\n",
    "\n",
    "1. [TensorFlow ranks and tensors](#TensorFlow-ranks-and-tensors)\n",
    "    1. [How to get the rank and shape of a tensor](#How-to-get-the-rank-and-shape-of-a-tensor)\n",
    "1. [Understanding TensorFlow's computation graphs](#Understanding-TensorFlows-computation-graphs)\n",
    "1. [Placeholders in TensorFlow](#Placeholders-in-TensorFlow)\n",
    "    1. [Defining placeholders](#Defining-placeholders)\n",
    "    1. [Feeding placeholders with data](#Feeding-placeholders-with-data)\n",
    "    1. [Defining placeholders for data arrays with varying batchsizes](#Defining-placeholders-for-data-arrays-with-varying-batchsizes)\n",
    "1. [Variables in TensorFlow](#Variables-in-TensorFlow)\n",
    "    1. [Defining variables](#Defining-variables)\n",
    "    1. [Initializing variables](#Initializing-variables)\n",
    "    1. [Variable scope](#Variable-scope)\n",
    "1. [](#)\n",
    "1. [](#)\n",
    "1. [](#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T13:32:50.936119Z",
     "start_time": "2018-12-10T13:32:32.157826Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Standard libary and settings\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import itertools\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "dataPath = os.path.abspath(os.path.join('../../Data'))\n",
    "modulePath = os.path.abspath(os.path.join('../../CustomModules'))\n",
    "sys.path.append(modulePath) if modulePath not in sys.path else None\n",
    "from IPython.core.display import display, HTML; display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "\n",
    "# Data extensions and settings\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold = np.inf, suppress = True)\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.options.display.float_format = '{:,.6f}'.format\n",
    "\n",
    "\n",
    "# Modeling extensions\n",
    "import sklearn.base as base\n",
    "import sklearn.cluster as cluster\n",
    "import sklearn.datasets as datasets\n",
    "import sklearn.decomposition as decomposition\n",
    "import sklearn.discriminant_analysis as discriminant_analysis\n",
    "import sklearn.ensemble as ensemble\n",
    "import sklearn.feature_extraction as feature_extraction\n",
    "import sklearn.feature_selection as feature_selection\n",
    "import sklearn.linear_model as linear_model\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.model_selection as model_selection\n",
    "import sklearn.neighbors as neighbors\n",
    "import sklearn.pipeline as pipeline\n",
    "import sklearn.preprocessing as preprocessing\n",
    "import sklearn.svm as svm\n",
    "import sklearn.tree as tree\n",
    "import sklearn.utils as utils\n",
    "\n",
    "\n",
    "# Visualization extensions and settings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Custom extensions and settings\n",
    "from quickplot import qp, qpUtil, qpStyle\n",
    "from mlTools import powerGridSearch\n",
    "sns.set(rc = qpStyle.rcGrey)\n",
    "\n",
    "\n",
    "# Magic functions\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'TensorFlow-ranks-and-tensors'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow ranks and tensors\n",
    "\n",
    "The TensorFlow library allows users to define graphs which perform operations and functions over tensors. Tensors are a generalizable mathematical for multidimensional arrays holding data values. The dimensionality of a tensor is generally referred to as its rank. Up to this point, we have worked with tensors of rank zero to two. A scalar is a tensor of rank 0, a vector is a tensor of rank 1, and a matrix is a tensor of rank 2. Tensor notation can be generalized to higher dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'How-to-get-the-rank-and-shape-of-a-tensor'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to get the rank and shape of a tensor\n",
    "\n",
    "TensorFlow has several built in functions which easily facilitate retrieval of a Tensor's rank and shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T13:33:03.435079Z",
     "start_time": "2018-12-10T13:32:52.088000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (), (4,), (2, 2)\n",
      "Ranks: 0, 1, 2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "g = tf.Graph()\n",
    "\n",
    "# defint the computation graph\n",
    "with g.as_default():\n",
    "    # define tensors as t1, t2, t3\n",
    "    t1 = tf.constant(np.pi)\n",
    "    t2 = tf.constant([1,2,3,4])\n",
    "    t3 = tf.constant([[1,2],[3,4]])\n",
    "    \n",
    "    # get the ranks\n",
    "    r1 = tf.rank(t1)\n",
    "    r2 = tf.rank(t2)\n",
    "    r3 = tf.rank(t3)\n",
    "    \n",
    "    # get the shapes\n",
    "    s1 = t1.get_shape()\n",
    "    s2 = t2.get_shape()\n",
    "    s3 = t3.get_shape()\n",
    "    print('Shapes: {0}, {1}, {2}'.format(s1,s2,s3))\n",
    "    \n",
    "with tf.Session(graph = g) as sess:\n",
    "    print('Ranks: {0}, {1}, {2}'.format(r1.eval(), r2.eval(), r3.eval()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Remarks - The rank of the t1 tensor is zero since it's just a scalar. The rank of the t2 vector is 1, and since it has four elements its shape is a one element tupe of (4,). The last shape t3 is a 2 by 2 matrix, and therfore has a rank of 2 and its shape is (2,2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Understanding-TensorFlows-computation-graphs'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding TensorFlow's computation graphs\n",
    "\n",
    "At its core, TensorFlow relies on building a computation graph. This graph is used to derive relationships between tensors from the input all the way through to the output. As an example, if we have rank 0 tensor (a scalar) and tensors a, b and c, and we want to evaluate $z = 2 \\times (a-b) + c$. The graph can be described as follows: Tensors a and b feed into $r_1$, which is equal to $a-b$. The resulting $r_1$ is referred to as an intermediate result tensor. $r_1 = a-b$ feeds into another intermediate graph $r_2$, which is equal to $2 \\times r_1$. The intermediate result tensor $r_2$, along with c, are fed into the final result tensor $z$, which is equal to $r_2 + c$. This series of operations can be reimagined as a network of nodes, where each node represents an operation where a function is applied to one or more input tensors, and yields zero or more output tensors.\n",
    "\n",
    "TensorFlow needs to be able to build this computational graph. The individual steps for building a typical graph are:\n",
    "\n",
    "1. Instantiate a new, empty computation graph\n",
    "2. Add nodes (tensors and operations) to the graph\n",
    "3. Execute the graph by:\n",
    "    1. Start a new session\n",
    "    2. Initialize the variables in the graph\n",
    "    3. Run the computation graph in this session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T13:50:24.696621Z",
     "start_time": "2018-12-10T13:50:24.689134Z"
    }
   },
   "outputs": [],
   "source": [
    "# computation graph for the equation above\n",
    "\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    a = tf.constant(1, name = 'a')\n",
    "    b = tf.constant(2, name = 'b')\n",
    "    c = tf.constant(3, name = 'c')\n",
    "    \n",
    "    z = 2 * (a - b) + c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above, 'with g.as_default()' adds nodes described within to the graph. By setting 'g' as the default graph, we are overriding the default graph that would otherwise takeover. Explicitly declaring which graph we want to use helps to avoid losing track of nodes.\n",
    "\n",
    "A TensorFlow session is an enviroment in which operations and tensors of a graph can be executed. A session gets created by calling 'tf.Session' that receives an existing graph as an argument. If 'tf.Session(graph = g)' is called, the session uses the graph 'g', otherwise it uses the default graph, which may be empty and not what we expect.\n",
    "\n",
    "Once a graph is launched in a TensorFlow session, we can execute its nodes containing tensors and/or its declared operations. Evaluating each individual tensor involves calling the 'eval' method inside the current session. When a specific tensor in the graph, TensorFlow executes all of the nodes that preceed that tensor until it reaches the tensor being specified.\n",
    "\n",
    "Operations can also be excuted by using a session's 'run' method. In the previous chappter, an example executed an operator called 'train_op'. This operator doesn't return any tensor, but can still be executed by running 'train_op.run(). Further, there is a universal way of running both tensors and operators - 'tf.Session().run()'. This approach can be used to place multiple tensors and operators in a list or a tuple. As a result 'tf.Session().run()' will return a list or tuple of the same size.\n",
    "\n",
    "Below, the previous graph is launched in a TensorFlow session and evaluates the tensor $z$ as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T13:52:20.888210Z",
     "start_time": "2018-12-10T13:52:20.880505Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 * (a - b) + c => 1\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "\n",
    "with tf.Session(graph = g) as sess:\n",
    "    print('2 * (a - b) + c => {0}'.format(sess.run(z)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Placeholders-in-TensorFlow'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Placeholders in TensorFlow\n",
    "\n",
    "Placeholders are a special mechanism for feeding data into TensorFlow. These are predefined tensors with specific data types and shapes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Defining placeholders'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining placeholders\n",
    "\n",
    "Placeholders are defined using 'tf.placeholder'. The shape and data type are determined by the shape and the data type of the data that is fed into the placeholder at the time of execution. We can define the another graph that also evaluates $z = 2(a-b)+c$, but this time use placeholders for the scalars a, b and c. We also store the intermediate tensors $r_1$ and $r_2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T14:00:03.152809Z",
     "start_time": "2018-12-10T14:00:03.144568Z"
    }
   },
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    tf_a = tf.placeholder(tf.int32, shape = [], name = 'tf_a')\n",
    "    tf_b = tf.placeholder(tf.int32, shape = [], name = 'tf_b')\n",
    "    tf_c = tf.placeholder(tf.int32, shape = [], name = 'tf_c')\n",
    "    \n",
    "    r1 = tf_a - tf_b\n",
    "    r2 = 2 * r1\n",
    "    z = r2 + tf_c\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Remarks - Three placeholders, tf_a, tf_b and tf_c are set with the data type tf.int32 and a shape equal to [], which is what we use for rank 0 tensors (aka scalars). If we were using tensors of higher dimensions, such as a rank 3 tensor with a shape of 3 x 4 x 5, the shape might be [2, 3, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Feeding-placeholders-with-data'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feeding placeholders with data\n",
    "\n",
    "A python dictionary is used to feed the values of placeholders into the session's graph. We need to ensure the data we feed in is consistent with the data type and shape of the placeholders. In the graph declared above, we have three placeholders that are tf.int32 scalars. Now we can feed in arbitrary int32 integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T14:06:03.686208Z",
     "start_time": "2018-12-10T14:06:03.678551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z: 1\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "\n",
    "with tf.Session(graph = g) as sess:\n",
    "    feed = {tf_a : 1, tf_b : 2, tf_c : 3}\n",
    "    print('z: {0}'.format(sess.run(z, feed_dict = feed)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Defining-placeholders-for-data-arrays-with-varying-batchsizes'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining placeholders for data arrays with varying batchsizes\n",
    "\n",
    "Neural network models often deal with min-batches of data that have different sizes. For example, training may occur with mini-batches of a user-defined size, but then prediction may be made on only a single sample.\n",
    "\n",
    "TensorFlow placeholders can accomodate this by specifying None for the dimension that will be varying in size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T14:26:05.896977Z",
     "start_time": "2018-12-10T14:26:05.884005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feeding data with shape: (5, 2)\n",
      "Result: [0.6208972  0.46750155]\n",
      "Feeding data with shape: (10, 2)\n",
      "Result: [0.46306401 0.48766556]\n"
     ]
    }
   ],
   "source": [
    "# Create graph\n",
    "\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    tf_x = tf.placeholder(tf.float32, shape = [None, 2], name = 'tf_x')\n",
    "    x_mean = tf.reduce_mean(tf_x, axis = 0, name = 'mean')    \n",
    "\n",
    "# Run graph in session\n",
    "np.random.seed(123)\n",
    "\n",
    "with tf.Session(graph = g) as sess:\n",
    "    x1 = np.random.uniform(low = 0, high = 1, size = (5,2))\n",
    "    print('Feeding data with shape: {}'.format(x1.shape))\n",
    "    print('Result: {}'.format(sess.run(x_mean, feed_dict = {tf_x : x1})))\n",
    "    \n",
    "    x2 = np.random.uniform(low = 0, high = 1, size = (10,2))\n",
    "    print('Feeding data with shape: {}'.format(x2.shape))\n",
    "    print('Result: {}'.format(sess.run(x_mean, feed_dict = {tf_x : x2})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T14:27:04.183710Z",
     "start_time": "2018-12-10T14:27:04.179529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"tf_x:0\", shape=(?, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Review the shape of tf_x\n",
    "\n",
    "print(tf_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Variables-in-TensorFlow'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables in TensorFlow\n",
    "\n",
    "Variables are a special type of tensor object that allows us to store and update parameters of our models in a TensoFlow session during the training process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Defining-variables'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining variables\n",
    "\n",
    "TensorFlow variables store the parameters of a model that can be updated during training. The obvious example would the weights in the input, hidden and output layers of a neural network. When a variable is defined, we need to initialize it with a tensor of values. There are two ways to define variables\n",
    "\n",
    "- tf.Variable()\n",
    "\n",
    "This is a class that creates an object for a new variable and adds it to the graph. It does not have explicit shape and dtype parameters. These attributes are inferred from the initial values of the variable.\n",
    "\n",
    "- tf.get_variable(\n",
    "\n",
    "This approach enables us to reuse an existing variable with a certain name, or create a new variable if the name used does not exist in the graph yet. This approach also allows for declaration of dtype and shape, which are only necessary when declaring a new variable.\n",
    "\n",
    "In both initialization techniques, the initial values are not set until the graph is launched via tf.Session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T14:36:17.202078Z",
     "start_time": "2018-12-10T14:36:17.194688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'w:0' shape=(2, 4) dtype=int64_ref>\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "\n",
    "g1 = tf.Graph()\n",
    "\n",
    "with g1.as_default():\n",
    "    w = tf.Variable(np.array([[1, 2, 3, 4]\n",
    "                             ,[5, 6, 7, 8]]), name = 'w')\n",
    "    print(w)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Initializing-variables'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing variables\n",
    "\n",
    "The computer memory that holds the variable is not allocated until the variables are initialized. Therefore, if we want to evaluate a tensor that includes a variable somewhere with its portion of the graph, we need to initialize the variables in that graph first. Initialization can occur using two methods. TensorFlow has a function named tf.global_variables_initializer, which, when executed, initializes the variables. We can also store this operator in an object, such as init_op = tf.global_variables_initializer(), which can then be executed later by sess.run(init_op) or init_op.run(). The key is that the operator is created after all variables that we need have been defined. A quick example illustrates this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T14:42:52.955095Z",
     "start_time": "2018-12-10T14:42:52.945760Z"
    }
   },
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "g2 = tf.Graph()\n",
    "\n",
    "with g2.as_default():\n",
    "    w1 = tf.Variable(1, name = 'w1')\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    w2 = tf.Variable(2, name = 'w2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T14:43:57.510617Z",
     "start_time": "2018-12-10T14:43:57.501150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1: 1\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph = g2) as sess:\n",
    "    sess.run(init_op)\n",
    "    print('w1: {}'.format(sess.run(w1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T14:44:07.146934Z",
     "start_time": "2018-12-10T14:44:07.121747Z"
    }
   },
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value w2\n\t [[Node: _retval_w2_0_0 = _Retval[T=DT_INT32, index=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](w2)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m~/.ve/main/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.ve/main/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.ve/main/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value w2\n\t [[Node: _retval_w2_0_0 = _Retval[T=DT_INT32, index=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](w2)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-9c0458335a2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'w2: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.ve/main/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.ve/main/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.ve/main/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.ve/main/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value w2\n\t [[Node: _retval_w2_0_0 = _Retval[T=DT_INT32, index=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](w2)]]"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph = g2) as sess:\n",
    "    sess.run(init_op)\n",
    "    print('w2: {}'.format(sess.run(w2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Remarks - In the example above, 'w2' is declared after the variables are initialized, so it couldn't be evaluated. Reordering the lines would fix this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Variable-scope'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable scope\n",
    "\n",
    "Variable scopes allow variables to be organized into separate subparts. As an example, if we have two subnetworks within one neural network, we can define to scopres named 'net_A' and 'net_B'. Then each layer will be defined one of these two scopes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = ''></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = ''></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = ''></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = ''></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
