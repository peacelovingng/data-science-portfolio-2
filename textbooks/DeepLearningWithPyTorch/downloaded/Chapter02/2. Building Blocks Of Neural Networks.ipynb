{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T01:00:07.624685Z",
     "start_time": "2019-03-24T01:00:07.315995Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1.post2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T01:00:09.065621Z",
     "start_time": "2019-03-24T01:00:08.835791Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Neural Network Using Pytorch\n",
    "\n",
    "We present our first neural network which learns to map training examples (input array) to targets (output array). \n",
    "Lets assume that we work for one of the largest online companies called Wondemovies, which is into serving videos on-demand. Our training dataset contains a feature which represents average hours spent by users watching movies in the platform, we would like to predict how much time each user would spend on the platform in the coming week. Its just a imaginary use case, don't think too much about it. Some of the high level activities for building such a solution are:\n",
    "\n",
    "1. Data preperation : **get_data()** function prepares the tensors (arrays) containing input and output data.\n",
    "2. Create learnable parameters : **get_weights()** function provides us with tensors containing random values , which we will optimize to solve our problem.\n",
    "3. Network Model : **simple_network()** produces the output for the input data applying a linear rule , multiply weights with input data and add the bias term (y = Wx+b).\n",
    "4. Loss : **loss_fn()** provides information about how good the model is.\n",
    "5. Optimizer : **optimize()** function helps us in adjusting random weights created initially to help the model calculate target values more accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T01:01:00.974890Z",
     "start_time": "2019-03-24T01:01:00.958709Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training Data\n",
    "def get_data():\n",
    "    train_X = np.asarray([3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,\n",
    "                         7.042,10.791,5.313,7.997,5.654,9.27,3.1])\n",
    "    train_Y = np.asarray([1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221,\n",
    "                         2.827,3.465,1.65,2.904,2.42,2.94,1.3])\n",
    "    dtype = torch.FloatTensor\n",
    "    X = Variable(torch.from_numpy(train_X).type(dtype),requires_grad=False).view(17,1)\n",
    "    y = Variable(torch.from_numpy(train_Y).type(dtype),requires_grad=False)\n",
    "    return X,y\n",
    "\n",
    "def plot_variable(x,y,z='',**kwargs):\n",
    "    l = []\n",
    "    for a in [x,y]:\n",
    "        if type(a) == Variable:\n",
    "            l.append(a.data.numpy())\n",
    "    plt.plot(l[0],l[1],z,**kwargs)\n",
    "\n",
    "def get_weights():\n",
    "    w = Variable(torch.randn(1),requires_grad = True)\n",
    "    b = Variable(torch.randn(1),requires_grad=True)\n",
    "    return w,b\n",
    "\n",
    "def simple_network(x):\n",
    "    y_pred = torch.matmul(x,w)+b\n",
    "    return y_pred\n",
    "\n",
    "def loss_fn(y,y_pred):\n",
    "    loss = (y_pred-y).pow(2).sum()\n",
    "    for param in [w,b]:\n",
    "        if not param.grad is None: param.grad.data.zero_()\n",
    "    loss.backward()\n",
    "    return loss.data.item()\n",
    "\n",
    "\n",
    "def optimize(learning_rate):\n",
    "    w.data -= learning_rate * w.grad.data\n",
    "    b.data -= learning_rate * b.grad.data\n",
    "\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T01:01:02.025743Z",
     "start_time": "2019-03-24T01:01:01.925654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1741.1322021484375\n",
      "2.61663556098938\n",
      "2.616497039794922\n",
      "2.616460084915161\n",
      "2.616424560546875\n",
      "2.6163899898529053\n",
      "2.6163573265075684\n",
      "2.616326332092285\n",
      "2.6162962913513184\n",
      "2.616266965866089\n"
     ]
    }
   ],
   "source": [
    "x,y = get_data()               # x - represents training data,y - represents target variables\n",
    "w,b = get_weights()           # w,b - Learnable parameters\n",
    "for i in range(500):\n",
    "    y_pred = simple_network(x) # function which computes wx + b\n",
    "    loss = loss_fn(y,y_pred)   # calculates sum of the squared differences of y and y_pred\n",
    "    if i % 50 == 0: \n",
    "        print(loss)\n",
    "    optimize(learning_rate)    # Adjust w,b to minimize the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T01:01:05.170758Z",
     "start_time": "2019-03-24T01:01:05.152756Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3687333e9a57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx_numpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplot_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Fitted line'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-2b59a766eaca>\u001b[0m in \u001b[0;36mplot_variable\u001b[0;34m(x, y, z, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "x_numpy = x.data.numpy()\n",
    "plot_variable(x,y,'ro')\n",
    "plot_variable(x,y_pred,label='Fitted line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Tensor introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T01:01:33.758914Z",
     "start_time": "2019-03-24T01:01:33.751405Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(10)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T01:01:34.945349Z",
     "start_time": "2019-03-24T01:01:34.937046Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = torch.FloatTensor([23,24,24.5,26,27.2,23.0])\n",
    "temp.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T01:01:39.301519Z",
     "start_time": "2019-03-24T01:01:38.995370Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "print(boston.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T01:01:39.318461Z",
     "start_time": "2019-03-24T01:01:39.309407Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "       'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T01:01:39.340117Z",
     "start_time": "2019-03-24T01:01:39.325539Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([506, 13])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_tensor = torch.from_numpy(boston.data)\n",
    "boston_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T01:01:39.363977Z",
     "start_time": "2019-03-24T01:01:39.350842Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.3200e-03, 1.8000e+01, 2.3100e+00, 0.0000e+00, 5.3800e-01, 6.5750e+00,\n",
       "         6.5200e+01, 4.0900e+00, 1.0000e+00, 2.9600e+02, 1.5300e+01, 3.9690e+02,\n",
       "         4.9800e+00],\n",
       "        [2.7310e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01, 6.4210e+00,\n",
       "         7.8900e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02, 1.7800e+01, 3.9690e+02,\n",
       "         9.1400e+00]], dtype=torch.float64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_tensor[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T01:01:39.383862Z",
     "start_time": "2019-03-24T01:01:39.371178Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.3200e-03, 1.8000e+01, 2.3100e+00, 0.0000e+00, 5.3800e-01],\n",
       "        [2.7310e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01],\n",
       "        [2.7290e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01],\n",
       "        [3.2370e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01],\n",
       "        [6.9050e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01],\n",
       "        [2.9850e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01],\n",
       "        [8.8290e-02, 1.2500e+01, 7.8700e+00, 0.0000e+00, 5.2400e-01],\n",
       "        [1.4455e-01, 1.2500e+01, 7.8700e+00, 0.0000e+00, 5.2400e-01],\n",
       "        [2.1124e-01, 1.2500e+01, 7.8700e+00, 0.0000e+00, 5.2400e-01],\n",
       "        [1.7004e-01, 1.2500e+01, 7.8700e+00, 0.0000e+00, 5.2400e-01]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_tensor[:10,:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3d- tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "panda = np.array(Image.open('../data/images/panda.jpg').resize((224,224)))\n",
    "panda_tensor = torch.from_numpy(panda)\n",
    "panda_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(panda);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T01:01:47.542729Z",
     "start_time": "2019-03-24T01:01:47.537096Z"
    }
   },
   "outputs": [],
   "source": [
    "sales = torch.FloatTensor([1000.0,323.2,333.4,444.5,1000.0,323.2,333.4,444.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T01:01:47.558857Z",
     "start_time": "2019-03-24T01:01:47.549956Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1000.0000,  323.2000,  333.4000,  444.5000, 1000.0000])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T01:01:47.574751Z",
     "start_time": "2019-03-24T01:01:47.565853Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1000.0000,  323.2000,  333.4000])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales[:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(panda_tensor[:,:,0].numpy());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(panda_tensor[25:175,60:130,0].numpy());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select specific element of tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T01:02:18.739752Z",
     "start_time": "2019-03-24T01:02:18.730962Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch.eye(shape) produces an diagonal matrix with 1 as it diagonal #elements.\n",
    "sales = torch.eye(3,3)\n",
    "sales[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4D Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T01:02:20.367282Z",
     "start_time": "2019-03-24T01:02:20.355237Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([0, 224, 224, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "#Read cat images from disk\n",
    "data_path='/Users/vishnu/Documents/fastAIPytorch/fastai/courses/dl1/data/dogscats/train/cats/'\n",
    "cats = glob(data_path+'*.jpg')\n",
    "#Convert images into numpy arrays\n",
    "cat_imgs = np.array([np.array(Image.open(cat).resize((224,224))) for cat in\n",
    "cats[:64]])\n",
    "cat_imgs = cat_imgs.reshape(-1,224,224,3)\n",
    "cat_tensors = torch.from_numpy(cat_imgs)\n",
    "cat_tensors.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor addition and multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T01:02:41.325331Z",
     "start_time": "2019-03-24T01:02:41.272955Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.1168, 2.9546],\n",
       "        [3.5009, 2.7355]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Various ways you can perform tensor addition\n",
    "a = torch.rand(2,2) \n",
    "b = torch.rand(2,2)\n",
    "c = a + b\n",
    "d = torch.add(a,b)\n",
    "#For in-place addition\n",
    "a.add_(5)\n",
    "\n",
    "#Multiplication of different tensors\n",
    "\n",
    "a*b\n",
    "a.mul(b)\n",
    "#For in-place multiplication\n",
    "a.mul_(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(10000,10000)\n",
    "b = torch.rand(10000,10000)\n",
    "\n",
    "a.matmul(b)\n",
    "#Time taken : 3.23 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move the tensors to GPU\n",
    "a = a.cuda()\n",
    "b = b.cuda()\n",
    "a.matmul(b)\n",
    "#Time taken : 11.2 µs  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T01:02:57.856637Z",
     "start_time": "2019-03-24T01:02:57.842767Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2500, 0.2500],\n",
       "        [0.2500, 0.2500]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "x = Variable(torch.ones(2,2),requires_grad=True)\n",
    "y = x.mean()\n",
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T01:02:57.864351Z",
     "start_time": "2019-03-24T01:02:57.859033Z"
    }
   },
   "outputs": [],
   "source": [
    "x.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T01:02:57.881609Z",
     "start_time": "2019-03-24T01:02:57.869377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T01:02:57.895149Z",
     "start_time": "2019-03-24T01:02:57.884159Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MeanBackward1 at 0x7f84b5a73470>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data for our neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T01:03:04.892020Z",
     "start_time": "2019-03-24T01:03:04.879905Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    train_X = np.asarray([3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,\n",
    "                         7.042,10.791,5.313,7.997,5.654,9.27,3.1])\n",
    "    train_Y = np.asarray([1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221,\n",
    "                         2.827,3.465,1.65,2.904,2.42,2.94,1.3])\n",
    "    dtype = torch.FloatTensor\n",
    "    X = Variable(torch.from_numpy(train_X).type(dtype),requires_grad=False).view(17,1)\n",
    "    y = Variable(torch.from_numpy(train_Y).type(dtype),requires_grad=False)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create learnable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T01:03:19.610196Z",
     "start_time": "2019-03-24T01:03:19.602456Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_weights():\n",
    "    w = Variable(torch.randn(1),requires_grad = True)\n",
    "    b = Variable(torch.randn(1),requires_grad=True)\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T01:03:19.629704Z",
     "start_time": "2019-03-24T01:03:19.615250Z"
    }
   },
   "outputs": [],
   "source": [
    "def simple_network(x):\n",
    "    y_pred = torch.matmul(x,w)+b\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Neural Network in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T01:03:40.026638Z",
     "start_time": "2019-03-24T01:03:40.019415Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=17, out_features=1, bias=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "f = nn.Linear(17,1) # Much simpler.\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T01:03:40.033840Z",
     "start_time": "2019-03-24T01:03:40.029453Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss_fn(y,y_pred):\n",
    "    loss = (y_pred-y).pow(2).sum()\n",
    "    for param in [w,b]:\n",
    "        if not param.grad is None: param.grad.data.zero_()\n",
    "    loss.backward()\n",
    "    return loss.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T01:03:40.041521Z",
     "start_time": "2019-03-24T01:03:40.038618Z"
    }
   },
   "outputs": [],
   "source": [
    "### Implementing Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T01:03:40.054102Z",
     "start_time": "2019-03-24T01:03:40.045321Z"
    }
   },
   "outputs": [],
   "source": [
    "def optimize(learning_rate):\n",
    "    w.data -= learning_rate * w.grad.data\n",
    "    b.data -= learning_rate * b.grad.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class DogsAndCatsDataset(Dataset):\n",
    "    def __init__(self,):\n",
    "        pass\n",
    "    def __len__(self):\n",
    "        pass\n",
    "    def __getitem__(self,idx):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogsAndCatsDataset(Dataset):\n",
    "    def __init__(self,root_dir,size=(224,224)):\n",
    "        self.files = glob(root_dir)\n",
    "        self.size = size\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    def __getitem__(self,idx):\n",
    "        img = np.asarray(Image.open(self.files[idx]).resize(self.size))\n",
    "        label = self.files[idx].split('/')[-2]\n",
    "        return img,label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining DataLoader to iterate over Dogs and Cats Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "dataloader = DataLoader(DogsAndCatsDataset,batch_size=32,num_workers=2)\n",
    "for imgs , labels in dataloader:\n",
    "        #Apply your DL on the dataset.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
