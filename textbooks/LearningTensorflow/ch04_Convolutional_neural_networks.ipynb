{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Chapter 4 - Convolutional neural networks__\n",
    "\n",
    "1. [Import](#Import)\n",
    "1. [Introduction to CNNs](#Introduction-to-CNNs)\n",
    "1. [MNIST - Take 2](#MNIST)\n",
    "    1. [Convolution](#Convolution)\n",
    "    1. [Pooling](#Pooling)\n",
    "    1. [Dropout](#Dropout)\n",
    "    1. [Model](#Model)\n",
    "1. [CIFAR10](#CIFAR10)\n",
    "    1. [Load data](#Load-data)\n",
    "    1. [Simple model](#Simple-model)\n",
    "    1. [Better model](#Better-model)\n",
    "    1. [Even better model](#Even-better-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Import'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Standard libary and settings\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import itertools\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "modulePath = os.path.abspath(os.path.join('../../CustomModules'))\n",
    "sys.path.append(modulePath) if modulePath not in sys.path else None\n",
    "from IPython.core.display import display, HTML; display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "# Data extensions and settings\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold = np.inf, suppress = True)\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.options.display.float_format = '{:,.6f}'.format\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Visualization extensions and settings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Magic functions\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Introduction-to-CNNs'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to CNNs\n",
    "\n",
    "Contrasting with fully connected neural networks, units in CNNs are connected to a (typically  small) number of nearby units in the previous layer. Further, all units are connected to the previous layer in the same way, with the exact same weights and structure. This facilitates an operation know as convolution, which can be thought as the application of a 'window' of weights. This windows slides along the surface of the image. This helps to address the fact that an object can appear in many different locations in a picture, and the perspective of an object will certainly differ from image to image. The is known as 'invariance'. The convolutional approach to learning weights addressse this by performing the same exact computation on different parts of the image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'MNIST'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST - Take 2\n",
    "\n",
    "Modeling using the MNIST dataset, this time with a small CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Convolution'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution\n",
    "\n",
    "The convolutation operation is the fundamental means by which layers are connected in CNNs. TensorFlow has a build in operation conv2d()\n",
    "\n",
    "```python\n",
    "tf.nn.conv2d(x, W, strides = [1,1,1,1], padding = 'SAME'\n",
    "```\n",
    "\n",
    "Here, 'x' is the data - which is either the input image or a downstream feature map obtained further along in the network following previous convolutional layers. A feature map is the output of each layer. The output of each layer can also be thought of as a 'processed' image, the result of applying a filter and perhaps some other operations. \n",
    "\n",
    "The filter is parameterized by W, which is comprised of the learned weights of our network. This convolutional filter is the small 'sliding window' that slides across the face of the image.\n",
    "\n",
    "The output of this operation will depend on the shape of X and W. In this case, the output is four-dimensional. The image data X is of shape: [None, 28, 28, 1], meaning we have an unknown number of images, each has 28 x 28 pixels, with one color channel (grayscale). The weights W is of shape: [5, 5, 1, 32], where the initial 5 x 5 x 1 represents the size of the 'window' in the image to be convolved, which in this is a 5 by 5 region. The 32 represents the number of feature maps. In other words, we have multiple sets of weights for the convolutional layer. The idea of a convolutional layer is to compute the same feature along the image - we would like to compute many such features and thus use multiple sets of convolutional filters.\n",
    "\n",
    "The 'strides' argument controls the spatial movement of the filter window W across the image (or feature map) x. The value [1,1,1,1] means that the filter is applied to the input in 1-ixel intervals, which can be thought of as a full convolution. Increasing the stride will result in a smaller feature map.\n",
    "\n",
    "Lastly, the padding argument is set to 'SAME', which means that the border of x are padded such that the size of the result of the operation is the same as the size of x. This allows the window to give similar attention to the pixels on the border of the image and the pixels in the middle of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Pooling'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling\n",
    "\n",
    "Pooling means reducing the size of the data with some local aggregation function, typically within each feature map. The technical aspect of this operation is that pooling reduces the size of the data processed downstream. This drastically reduces the number of parameters in the model, particularly if we use fully connected layers after the convolutional layer. The theoretical aspect of pooling is that we would like our features to not care too much about small changes in position in an image. This allows the process to over spatial variability between images.\n",
    "\n",
    "```python\n",
    "tf.nn.max_pool(x, ksize = [1,2,2,1], stides = [1,2,2,1], padding = 'SAME')\n",
    "```\n",
    "\n",
    "The ksize argument controls the size of the pooling and strides controls how much the pooling grid slides across x, just as it does in the convolution layer. Setting strides to a 2x2 grid means the output of the pooling will be exactly one-half of the height and width of the original - one-quarter of the original size overall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Dropout'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "\n",
    "Dropout is a regularization trick used to force the network to distribute the learned representation across all nuerons. Dropout 'turns off a random preset fraction of units in a layer by setting their values to zero during training. These dropped neurons are random, and different for each computation, which forces the network to learn a representation that will work despite the dropout. This process can be thought of training an 'ensemble of multiple network that have a different understanding of the training data, which tends to increase generalization. Dropout is not used in the test phase.\n",
    "\n",
    "```python\n",
    "tf.nn.dropout(layer, keep_prob = 0.1)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Model'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def weight_variable(shape):\n",
    "    \"\"\"\n",
    "    Info:\n",
    "        Description:\n",
    "            Specifies weights for either a fully connected layer or convolutional layer. \n",
    "            Randomized initially using a truncated normal distribution with a SD of 0.1. \n",
    "            This is a pretty typical randomization method.\n",
    "    \"\"\"\n",
    "    initial = tf.truncated_normal(shape, stddev = 0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    \"\"\"\n",
    "    Info:\n",
    "        Description:\n",
    "            Defines bias elements in either a fully connected layer or convolutional layer.\n",
    "            Initialized with the constant value of 0.1\n",
    "    \"\"\"\n",
    "    initial = tf.constant(0.1, shape = shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    \"\"\"\n",
    "    Info:\n",
    "        Description:\n",
    "            Specifies the convolution that will typically be used.\n",
    "            This represents a full convolution (no skipping) with padding \n",
    "            that creates an output that is the same size as the input.\n",
    "    \"\"\"\n",
    "    return tf.nn.conv2d(x, W, strides = [1,1,1,1], padding = 'SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    \"\"\"\n",
    "    Info:\n",
    "        Description:\n",
    "            Sets the max pool to half the size across both the height and width.\n",
    "            In total, the output is one quarter of the size of the input feature map.\n",
    "    \"\"\"\n",
    "    return tf.nn.max_pool(x, ksize = [1,2,2,1]\n",
    "                          ,strides = [1,2,2,1], padding = 'SAME')\n",
    "\n",
    "def conv_layer(input, shape):\n",
    "    \"\"\"\n",
    "    Info:\n",
    "        Description:\n",
    "            The convolutional layer, linear convolution as defined in conv2d, with a\n",
    "            bias followed by the ReLU activation function.\n",
    "    \"\"\"\n",
    "    W = weight_variable(shape)\n",
    "    b = bias_variable([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input, W) + b)\n",
    "\n",
    "def full_layer(input, size):\n",
    "    \"\"\"\n",
    "    Info:\n",
    "        Description:\n",
    "            A standard full layer with a bias. To be used for the final output.\n",
    "    \"\"\"\n",
    "    in_size = int(input.get_shape()[1])\n",
    "    W = weight_variable([in_size, size])\n",
    "    b = bias_variable([size])\n",
    "    return tf.matmul(input, W) + b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Remarks - Random initialization, as opposed to constant initialization, helps break the symmetry between learned features which allows the modle to learn a diverse and rich representation. Using a bound (truncated) distribution helps control the magnitude of the gradients, allowing the network to ocnverge more efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup model\n",
    "\n",
    "# 28 x 28 pixel input\n",
    "x = tf.placeholder(tf.float32, shape = [None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape = [None, 10])\n",
    "\n",
    "x_image = tf.reshape(x, [-1,28,28,1])\n",
    "\n",
    "# 5 x 5 x 32 feature map. Creates 28 x 28 x 32 feature map\n",
    "# Followed by 2x2 max pooling\n",
    "conv1 = conv_layer(x_image, shape = [5,5,1,32])\n",
    "conv1_pool = max_pool_2x2(conv1)\n",
    "\n",
    "# 5 x 5 x 32 x 64 (5 by 5 tiles, 32 deep, 64 sets)\n",
    "# Creates 14 x 14 x 64 feature map\n",
    "# Followed by 2x2 max pooling\n",
    "conv2 = conv_layer(conv1_pool, shape = [5,5,32,64])\n",
    "conv2_pool = max_pool_2x2(conv2)\n",
    "\n",
    "# 7 x 7 x 64 fully connected layer\n",
    "conv2_flat = tf.reshape(conv2_pool, [-1,7*7*64])\n",
    "full_1 = tf.nn.relu(full_layer(conv2_flat, 1024))\n",
    "\n",
    "# dropouts\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "full1_drop = tf.nn.dropout(full_1, keep_prob = keep_prob)\n",
    "\n",
    "y_conv = full_layer(full1_drop, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Remarks - First placeholders are defined for the input images and correct labels. Next the input image is reshaped into the @D image format of size 28 x 28 x 1. In the basic logistic regression implemented earlier, since all pixels were treated independently. With a CNN, however, its power comes from the utilization of spatial meaning pixels and nearby pixels.\n",
    "\n",
    "> Next, two consecutive convolutional layers and pools, each with 5 x 5 convolutions and 32 feature maps. These are followed by a single fully connected layer with 1,024 units. Prior to the image arriving at this fully connected layer, we flatten the image back to a single vector form since the fully connected layer derives no benefit from the spatial relationships of between pixels.\n",
    "\n",
    "> After the second convolution/pooling layer, the size of the image is 7 x 7 x 64. the original 28 x 28 pixel image is reduced to 14 x 14 by the first pooling operation, and then to 7 x 7 by the second pooling operation. The '64' in 7 x 7 x 64 is the number of feature maps creates in the second convolutional layer.\n",
    "\n",
    "> One interesting thing to note is that the number of parameters between the 7 x 7 x 64 layer and the fully connected 1 x 1 x 1,024 layer is 3.2 million. Without max pooling, which would give us a 28 x 28 x 64 feature map, would yield 51 million parameters.\n",
    "\n",
    "> Lastly, the output is a fully connected layer with 10 units, one unit for each handwritten digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-8c2f33962f2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Execute model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmnist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_data_sets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mone_hot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
      "\u001b[1;31mNameError\u001b[0m: name 'input_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Execute model\n",
    "\n",
    "mnist = input_data.read_data_sets(DATA_DIR, one_hot = True)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "                               logits = y_conv, labels = y))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in rnage(STEPS):\n",
    "        batch = mnist.train.next_batch(50)\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            train_accuracy = sess.run(accuracy, feed_dict = {x : batch[0]\n",
    "                                                             ,y_ : batch[1]\n",
    "                                                             ,keep_prob : 1.0})\n",
    "            print('step {}, training accuracy {}'.format(i, train_accuracy))\n",
    "            \n",
    "        sess.run(train_step, feed_dict = {x : batch[0]\n",
    "                                         ,y_ : batch[1]\n",
    "                                         ,keep_prob : 0.5})\n",
    "    \n",
    "    X = mnist.test.images.reshape(10, 1000, 784)\n",
    "    Y = mnist.test.labels.reshape(10, 1000, 10)\n",
    "    test_accuracy = np.mean([sess.run(accuracy\n",
    "                            ,feed_dict = {x : X[i]\n",
    "                                         ,y_ : Y[i]\n",
    "                                         ,keep_prob : 1.0})\n",
    "                                for i in rnage(10)])\n",
    "\n",
    "print('test accuracy: {}'.format(test_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'CIFAR10'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10\n",
    "\n",
    "The CIFAR10 dataset contains a set of 60,000 color images of size 32 x 32 pixels, each belonging to one of ten categories:\n",
    "\n",
    "- airplane\n",
    "- automobile\n",
    "- bird\n",
    "- cat \n",
    "- deer\n",
    "- dog\n",
    "- frog\n",
    "- horse\n",
    "- ship\n",
    "- truck\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Load-data'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "path = ''\n",
    "\n",
    "class CifarLoader():\n",
    "    \n",
    "    \n",
    "    def __init__(self, source_files):\n",
    "        self._source = source_files\n",
    "        self._i = 0\n",
    "        self.images = None\n",
    "        self.labels = None\n",
    "        \n",
    "    def load(self):\n",
    "        data = [unpickle(f) for f in self._source]\n",
    "        images = np.vstack([d['data'] for d in data])\n",
    "        n = len(images)\n",
    "        self.images = images.reshape(n,3,32,32).transpose(0,2,3,1).astype(float) / 255\n",
    "        self.labels = one_hot(np.hstack([d['labels'] for d in data]), 10)\n",
    "        return self\n",
    "    \n",
    "    def next_batch(self, batch_size):\n",
    "        x, y = self.images[self._i : self._i + batch_size]\\\n",
    "                ,self.labels[self._i : self._i + batch_size]\n",
    "        self._i = (self._i + batch_size) % len(self.images)\n",
    "        return x, y\n",
    "\n",
    "def unpickle(file):\n",
    "    \"\"\"\n",
    "    Info:\n",
    "        Description:\n",
    "            Returns dictionary with fields 'data' and 'labels'.\n",
    "    \"\"\"\n",
    "    with open(os.path.join(path, file), 'rb') as fo:\n",
    "        dict = cPickle.load(fo)\n",
    "    return dict\n",
    "\n",
    "def one_hot(vec, vals = 10):\n",
    "    \"\"\"\n",
    "    Info:\n",
    "        Description:\n",
    "            Recodes the labels from integer in rnage 0 to 9 into\n",
    "            vectors of length 10, contains 0's except for a 1 at the\n",
    "            position of the label.\n",
    "    \"\"\"\n",
    "    n = len(vec)\n",
    "    out = np.zeros((n, vals))\n",
    "    out[range(n), vec] = 1\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "class CifarDataManager():\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.train = CifarLoader(['data_batch_{}'.format(i) for i in range(1,6)]).load()\n",
    "        self.test = CifarLoader('test_batch').load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "def display_cifar(images, size):\n",
    "    n = len(images)\n",
    "    plt.figure()\n",
    "    plt.gca().set_axis_off()\n",
    "    im = np.vstack([np.hstack([images[np.random.choice(n)] for i in range(size)]) for i in range(size)])\n",
    "    plt.imshow(im)\n",
    "    plt.show()\n",
    "    \n",
    "d = CifarDataManager()\n",
    "print('Number of train images: {}'.format(len(d.train.images)))\n",
    "print('Number of train images: {}'.format(len(d.train.labels)))\n",
    "print('Number of test images: {}'.format(len(d.test.images)))\n",
    "print('Number of test images: {}'.format(len(d.test.labels)))\n",
    "\n",
    "images = d.train.images\n",
    "display_cifar(images, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Simple-model'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-bf51d8c471d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcifar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCifarDataManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-1610d3492a9e>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCifarLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data_batch_{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCifarLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test_batch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-1bea10325e63>\u001b[0m in \u001b[0;36mload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0munpickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_source\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-1bea10325e63>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0munpickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_source\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-1bea10325e63>\u001b[0m in \u001b[0;36munpickle\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0munpickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[0mdict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcPickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "#\n",
    "\n",
    "cifar = CifarDataManager()\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape = [None, 32, 32, 3])\n",
    "y_ = tf.placeholder(tf.float32, shape = [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "conv1 = conv_layer(x, shape = [5, 5, 3, 32])\n",
    "conv1_pool = max_pool_2x2(conv)\n",
    "\n",
    "conv2 = conv_layer(conv1_pool, shape = [5, 5, 32, 64])\n",
    "conv2_pool = max_pool_2x2(conv2)\n",
    "conv2_flat = tf.reshape(conv2_pool, [-1, 8 * 8 * 64])\n",
    "\n",
    "full_1 = tf.nn.relu(full_layer(conv2_flat, 1024))\n",
    "full1_drop = tf.nn.dropout(full_1, keep_prob = keep_prob)\n",
    "\n",
    "y_conv = full_layer(full1_drop, 10)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_entropy_with_logits(y_conv, y_))\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(1e-2).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, float32))\n",
    "\n",
    "def test(sess):\n",
    "    X = cifarar.test.images.reshape(10, 1000, 32, 32, 3)\n",
    "    Y = cifarar.test.labels.reshape(10, 1000, 10)\n",
    "    acc = np.mean([sessss.run(accuracyy, feed_dict = {x : X[i], y_ : Y[i]\n",
    "                                                    ,keep_prob_prob : 1.0})\n",
    "                  for i in range(10)])\n",
    "    print('Accuracy: {:.4}'.format(acc * 100))\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in rangenge(STEPS):\n",
    "        batch = cifar.train.next_batch(BATCH_SIZE)\n",
    "        sess.run(train_step, feed_dict = {x : batch[0], y_ : batch[1]\n",
    "                                         ,keep_prob : 0.5})\n",
    "    test(sess)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Remarks - A key difference between this model and the MNIST model:\n",
    "```python\n",
    "x = tf.placeholder(tf.float32, shape = [None, 32, 32, 3])\n",
    "```\n",
    "The '3' in the final position of the list defining the placeholder's shape corresponds to the 3 color channels available in the color CIFAR image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Better-model'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better model\n",
    "\n",
    "We can also add a third convolution layer with 128 feature maps and dropout. We also reduce the number of units in the fully connected layer from 1,024 to 512\n",
    "\n",
    "This model will take longer to train but will increase the accuracy to around 75%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape = [None, 32, 32, 3])\n",
    "y_ = tf.placeholder(tf.float32, shape = [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "conv1 = conv_layer(x, shape = [5, 5, 3, 32])\n",
    "conv1_pool = max_pool_2x2(conv1)\n",
    "\n",
    "conv2 = conv_layer(conv1_pool, shape = [5, 5, 32, 64])\n",
    "conv2_pool = max_pool_2x2(conv2)\n",
    "\n",
    "conv3 = conv_layer(conv2_pool, shape = [5, 5, 64, 128])\n",
    "conv3_pool = max_pool_2x2(conv3)\n",
    "conv3_flat = tf.reshape(conv3_pool, [-1, 4 * 4 * 128])\n",
    "conv3_drop = tf.nn.dropout(conv3_flat, keep_prob = keep_prob)\n",
    "\n",
    "full_1 = tf.nn.relu(full_layer(conv3_drop, 512))\n",
    "full1_drop = tf.nn.dropout(full_1, keep_prob = keep_prob)\n",
    "\n",
    "y_conv = full_layer(full1_drop, 10)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_entropy_with_logits(y_conv, y_))\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(1e-2).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, float32))\n",
    "\n",
    "def test(sess):\n",
    "    X = cifarar.test.images.reshape(10, 1000, 32, 32, 3)\n",
    "    Y = cifarar.test.labels.reshape(10, 1000, 10)\n",
    "    acc = np.mean([sessss.run(accuracyy, feed_dict = {x : X[i], y_ : Y[i]\n",
    "                                                    ,keep_prob_prob : 1.0})\n",
    "                  for i in range(10)])\n",
    "    print('Accuracy: {:.4}'.format(acc * 100))\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in rangenge(STEPS):\n",
    "        batch = cifar.train.next_batch(BATCH_SIZE)\n",
    "        sess.run(train_step, feed_dict = {x : batch[0], y_ : batch[1]\n",
    "                                         ,keep_prob : 0.5})\n",
    "    test(sess)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Remarks - Further improvement\n",
    "- Model size\n",
    "    - Deeper network with mmany more adjustable parameters\n",
    "- Additional types of layers and methods\n",
    "    - Additional types of layers, such as local response normalization, can be incorprated into the existing structure.\n",
    "- Optimization tricks\n",
    "    - (More later)\n",
    "- Domain knowledge \n",
    "    - Pre-processing data utilizing domain knowledge\n",
    "- Data augmentation\n",
    "   - Adding training data based on the existing data set. Rotating an image any number of ways effectively inrroduces a new training sample.\n",
    "- Reusing successful methods and architectures\n",
    "    - Find a time-proven method and adapt to the needs of the current problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Even-better-model'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Even better model\n",
    "\n",
    "This model includes three convolutional layers, followed by the same fully connected and output layers. Each block of convolutional layers contains three consecutive convolutional layers, follwed by a single pool and dropout layer.\n",
    "\n",
    "The constants C1, C2 and C3 control the number of feature maps in each layer of each of the convolutional blocks, and the constant F1 controls the number of units in the fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "C1, C2, C3 = 30, 50, 80\n",
    "F1 = 500\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape = [None, 32, 32, 3])\n",
    "y_ = tf.placeholder(tf.float32, shape = [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "conv1_1 = conv_layer(, shape = [3, 3, 3, C1])\n",
    "conv1_2 = conv_layer(conv1_1,shape = [3, 3 C1, C1])\n",
    "conv1_3 = conv_layer(conv1_2, shape = [3, 3, C1, C1])\n",
    "conv1_pool = max_pool_2x2(conv1_3)\n",
    "conv1_drop = tf.nn.dropout(conv1_pool, keep_prob = keep_prob)\n",
    "\n",
    "conv2_1 = conv_layer(conv1_drop, shape = [3, 3, C1, C2])\n",
    "conv2_2 = conv_layer(conv2_1,shapepe = [3, 3 C2, C2])\n",
    "conv2_3 = conv_layer(conv2_2, shapepe = [3, 3, C2, C2])\n",
    "conv2_pool = max_pool_2x2(conv2_3)\n",
    "conv2_drop = tf.nn.dropout(conv2_pool, keep_prob = keep_prob)\n",
    "\n",
    "conv3_1 = conv_layer(conv2_drop, shape = [3, 3, C2, C3])\n",
    "conv3_2 = conv_layer(conv3_1, shape = [3, 3 C3, C3])\n",
    "conv3_3 = conv_layer(conv3_2, shape = [3, 3, C3, C3])\n",
    "conv3_pool = tf.nn.max_pool(conv3_3, ksize = [1, 8, 8, 1], strides = [1, 8, 8, 1\n",
    "                                                ,padding = 'SAME'])\n",
    "conv3_flat = tf.reshape(conv3_pool, [-1, 3])\n",
    "conv3_drop = tf.nn.dropout(conv3_flat, keep_prob = keep_prob)\n",
    "\n",
    "full1 = tf.nn.relu(full_layer(conv3_drop, F1))\n",
    "full1_drop = tf.nn.dropout(full1, keep_prob = keep_prob)\n",
    "\n",
    "y_conv = full_layer(full1_drop, 10)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_entropy_with_logits(y_conv, y_))\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(1e-2).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, float32))\n",
    "\n",
    "def test(sess):\n",
    "    X = cifarar.test.images.reshape(10, 1000, 32, 32, 3)\n",
    "    Y = cifarar.test.labels.reshape(10, 1000, 10)\n",
    "    acc = np.mean([sessss.run(accuracyy, feed_dict = {x : X[i], y_ : Y[i]\n",
    "                                                    ,keep_prob_prob : 1.0})\n",
    "                  for i in range(10)])\n",
    "    print('Accuracy: {:.4}'.format(acc * 100))\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in rangenge(STEPS):\n",
    "        batch = cifar.train.next_batch(BATCH_SIZE)\n",
    "        sess.run(train_step, feed_dict = {x : batch[0], y_ : batch[1]\n",
    "                                         ,keep_prob : 0.5})\n",
    "    test(sess)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Remarks - Prior to the dropout step of the third convolutional layer, there is an 8x8 max pool layer\n",
    "```python\n",
    "conv3_pool = tf.nn.max_pool(conv3_3, ksize = [1, 8, 8, 1]\n",
    "                            ,strides = [1, 8, 8, 1], padding = 'SAME')\n",
    "```\n",
    "By this point, the feature maps are of size 8 x 8 (following the first two poolings that each reduced the 32 x 32 pictures by half on each axis), this globally pools each of the feature maps to keep only the maximal value. The number of feature maps at the third block was set to 80, so, after the max pooling, the representation is reduced to only 80 numbers. This keeps the size of the model small - the number of parameters in the transition to the full connected layer is only 80 x 500."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
