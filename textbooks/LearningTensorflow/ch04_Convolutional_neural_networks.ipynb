{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Chapter 4 - Convolutional neural networks__\n",
    "\n",
    "1. [Import](#Import)\n",
    "1. [Introduction to CNNs](#Introduction-to-CNNs)\n",
    "1. [MNIST - Take 2](#MNIST)\n",
    "    1. [Convolution](#Convolution)\n",
    "    1. [Pooling](#Pooling)\n",
    "    1. [Dropout](#Dropout)\n",
    "    1. [Model](#Model)\n",
    "1. [CIFAR10](#CIFAR10)\n",
    "    1. [](#)\n",
    "    1. [](#)\n",
    "    1. [](#)\n",
    "    1. [](#)\n",
    "1. [](#)\n",
    "1. [](#)\n",
    "1. [](#)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Import'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Standard libary and settings\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import itertools\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "modulePath = os.path.abspath(os.path.join('../../CustomModules'))\n",
    "sys.path.append(modulePath) if modulePath not in sys.path else None\n",
    "from IPython.core.display import display, HTML; display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "\n",
    "# Data extensions and settings\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold = np.inf, suppress = True)\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.options.display.float_format = '{:,.6f}'.format\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Visualization extensions and settings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Custom extensions and settings\n",
    "# import mlmachine as mlm\n",
    "\n",
    "\n",
    "# Magic functions\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Introduction-to-CNNs'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to CNNs\n",
    "\n",
    "Contrasting with fully connected neural networks, units in CNNs are connected to a (typically  small) number of nearby units in the previous layer. Further, all units are connected to the previous layer in the same way, with the exact same weights and structure. This facilitates an operation know as convolution, which can be thought as the application of a 'window' of weights. This windows slides along the surface of the image. This helps to address the fact that an object can appear in many different locations in a picture, and the perspective of an object will certainly differ from image to image. The is known as 'invariance'. The convolutional approach to learning weights addressse this by performing the same exact computation on different parts of the image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'MNIST'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST - Take 2\n",
    "\n",
    "Modeling using the MNIST dataset, this time with a small CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Convolution'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution\n",
    "\n",
    "The convolutation operation is the fundamental means by which layers are connected in CNNs. TensorFlow has a build in operation conv2d()\n",
    "\n",
    "```python\n",
    "tf.nn.conv2d(x, W, strides = [1,1,1,1], padding = 'SAME'\n",
    "```\n",
    "\n",
    "Here, 'x' is the data - which is either the input image or a downstream feature map obtained further along in the network following previous convolutional layers. A feature map is the output of each layer. The output of each layer can also be thought of as a 'processed' image, the result of applying a filter and perhaps some other operations. \n",
    "\n",
    "The filter is parameterized by W, which is comprised of the learned weights of our network. This convolutional filter is the small 'sliding window' that slides across the face of the image.\n",
    "\n",
    "The output of this operation will depend on the shape of X and W. In this case, the output is four-dimensional. The image data X is of shape: [None, 28, 28, 1], meaning we have an unknown number of images, each has 28 x 28 pixels, with one color channel (grayscale). The weights W is of shape: [5, 5, 1, 32], where the initial 5 x 5 x 1 represents the size of the 'window' in the image to be convolved, which in this is a 5 by 5 region. The 32 represents the number of feature maps. In other words, we have multiple sets of weights for the convolutional layer. The idea of a convolutional layer is to compute the same feature along the image - we would like to compute many such features and thus use multiple sets of convolutional filters.\n",
    "\n",
    "The 'strides' argument controls the spatial movement of the filter window W across the image (or feature map) x. The value [1,1,1,1] means that the filter is applied to the input in 1-ixel intervals, which can be thought of as a full convolution. Increasing the stride will result in a smaller feature map.\n",
    "\n",
    "Lastly, the padding argument is set to 'SAME', which means that the border of x are padded such that the size of the result of the operation is the same as the size of x. This allows the window to give similar attention to the pixels on the border of the image and the pixels in the middle of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Pooling'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling\n",
    "\n",
    "Pooling means reducing the size of the data with some local aggregation function, typically within each feature map. The technical aspect of this operation is that pooling reduces the size of the data processed downstream. This drastically reduces the number of parameters in the model, particularly if we use fully connected layers after the convolutional layer. The theoretical aspect of pooling is that we would like our features to not care too much about small changes in position in an image. This allows the process to over spatial variability between images.\n",
    "\n",
    "```python\n",
    "tf.nn.max_pool(x, ksize = [1,2,2,1], stides = [1,2,2,1], padding = 'SAME')\n",
    "```\n",
    "\n",
    "The ksize argument controls the size of the pooling and strides controls how much the pooling grid slides across x, just as it does in the convolution layer. Setting strides to a 2x2 grid means the output of the pooling will be exactly one-half of the height and width of the original - one-quarter of the original size overall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Dropout'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "\n",
    "Dropout is a regularization trick used to force the network to distribute the learned representation across all nuerons. Dropout 'turns off a random preset fraction of units in a layer by setting their values to zero during training. These dropped neurons are random, and different for each computation, which forces the network to learn a representation that will work despite the dropout. This process can be thought of training an 'ensemble of multiple network that have a different understanding of the training data, which tends to increase generalization. Dropout is not used in the test phase.\n",
    "\n",
    "```python\n",
    "tf.nn.dropout(layer, keep_prob = 0.1)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Model'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def weight_variable(shape):\n",
    "    \"\"\"\n",
    "    Info:\n",
    "        Description:\n",
    "            Specifies weights for either a fully connected layer or convolutional layer. \n",
    "            Randomized initially using a truncated normal distribution with a SD of 0.1. \n",
    "            This is a pretty typical randomization method.\n",
    "    \"\"\"\n",
    "    initial = tf.truncated_normal(shape, stddev = 0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    \"\"\"\n",
    "    Info:\n",
    "        Description:\n",
    "            Defines bias elements in either a fully connected layer or convolutional layer.\n",
    "            Initialized with the constant value of 0.1\n",
    "    \"\"\"\n",
    "    initial = tf.constant(0.1, shape = shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    \"\"\"\n",
    "    Info:\n",
    "        Description:\n",
    "            Specifies the convolution that will typically be used.\n",
    "            This represents a full convolution (no skipping) with padding \n",
    "            that creates an output that is the same size as the input.\n",
    "    \"\"\"\n",
    "    return tf.nn.conv2d(x, W, strides = [1,1,1,1], padding = 'SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    \"\"\"\n",
    "    Info:\n",
    "        Description:\n",
    "            Sets the max pool to half the size across both the height and width.\n",
    "            In total, the output is one quarter of the size of the input feature map.\n",
    "    \"\"\"\n",
    "    return tf.nn.max_pool(x, ksize = [1,2,2,1]\n",
    "                          ,strides = [1,2,2,1], padding = 'SAME')\n",
    "\n",
    "def conv_layer(input, shape):\n",
    "    \"\"\"\n",
    "    Info:\n",
    "        Description:\n",
    "            The convolutional layer, linear convolution as defined in conv2d, with a\n",
    "            bias followed by the ReLU activation function.\n",
    "    \"\"\"\n",
    "    W = weight_variable(shape)\n",
    "    b = bias_variable([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input, W) + b)\n",
    "\n",
    "def full_layer(input, size):\n",
    "    \"\"\"\n",
    "    Info:\n",
    "        Description:\n",
    "            A standard full layer with a bias. To be used for the final output.\n",
    "    \"\"\"\n",
    "    in_size = int(input.get_shape()[1])\n",
    "    W = weight_variable([in_size, size])\n",
    "    b = bias_variable([size])\n",
    "    return tf.matmul(input, W) + b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Remarks - Random initialization, as opposed to constant initialization, helps break the symmetry between learned features which allows the modle to learn a diverse and rich representation. Using a bound (truncated) distribution helps control the magnitude of the gradients, allowing the network to ocnverge more efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup model\n",
    "\n",
    "# 28 x 28 pixel input\n",
    "x = tf.placeholder(tf.float32, shape = [None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape = [None, 10])\n",
    "\n",
    "x_image = tf.reshape(x, [-1,28,28,1])\n",
    "\n",
    "# 5 x 5 x 32 feature map. Creates 28 x 28 x 32 feature map\n",
    "# Followed by 2x2 max pooling\n",
    "conv1 = conv_layer(x_image, shape = [5,5,1,32])\n",
    "conv1_pool = max_pool_2x2(conv1)\n",
    "\n",
    "# 5 x 5 x 32 x 64 (5 by 5 tiles, 32 deep, 64 sets)\n",
    "# Creates 14 x 14 x 64 feature map\n",
    "# Followed by 2x2 max pooling\n",
    "conv2 = conv_layer(conv1_pool, shape = [5,5,32,64])\n",
    "conv2_pool = max_pool_2x2(conv2)\n",
    "\n",
    "# 7 x 7 x 64 fully connected layer\n",
    "conv2_flat = tf.reshape(conv2_pool, [-1,7*7*64])\n",
    "full_1 = tf.nn.relu(full_layer(conv2_flat, 1024))\n",
    "\n",
    "# dropouts\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "full1_drop = tf.nn.dropout(full_1, keep_prob = keep_prob)\n",
    "\n",
    "y_conv = full_layer(full1_drop, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Remarks - First placeholders are defined for the input images and correct labels. Next the input image is reshaped into the @D image format of size 28 x 28 x 1. In the basic logistic regression implemented earlier, since all pixels were treated independently. With a CNN, however, its power comes from the utilization of spatial meaning pixels and nearby pixels.\n",
    "\n",
    "> Next, two consecutive convolutional layers and pools, each with 5 x 5 convolutions and 32 feature maps. These are followed by a single fully connected layer with 1,024 units. Prior to the image arriving at this fully connected layer, we flatten the image back to a single vector form since the fully connected layer derives no benefit from the spatial relationships of between pixels.\n",
    "\n",
    "> After the second convolution/pooling layer, the size of the image is 7 x 7 x 64. the original 28 x 28 pixel image is reduced to 14 x 14 by the first pooling operation, and then to 7 x 7 by the second pooling operation. The '64' in 7 x 7 x 64 is the number of feature maps creates in the second convolutional layer.\n",
    "\n",
    "> One interesting thing to note is that the number of parameters between the 7 x 7 x 64 layer and the fully connected 1 x 1 x 1,024 layer is 3.2 million. Without max pooling, which would give us a 28 x 28 x 64 feature map, would yield 51 million parameters.\n",
    "\n",
    "> Lastly, the output is a fully connected layer with 10 units, one unit for each handwritten digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-8c2f33962f2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Execute model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmnist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_data_sets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mone_hot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
      "\u001b[1;31mNameError\u001b[0m: name 'input_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Execute model\n",
    "\n",
    "mnist = input_data.read_data_sets(DATA_DIR, one_hot = True)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "                               logits = y_conv, labels = y))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in rnage(STEPS):\n",
    "        batch = mnist.train.next_batch(50)\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            train_accuracy = sess.run(accuracy, feed_dict = {x : batch[0]\n",
    "                                                             ,y_ : batch[1]\n",
    "                                                             ,keep_prob : 1.0})\n",
    "            print('step {}, training accuracy {}'.format(i, train_accuracy))\n",
    "            \n",
    "        sess.run(train_step, feed_dict = {x : batch[0]\n",
    "                                         ,y_ : batch[1]\n",
    "                                         ,keep_prob : 0.5})\n",
    "    \n",
    "    X = mnist.test.images.reshape(10, 1000, 784)\n",
    "    Y = mnist.test.labels.reshape(10, 1000, 10)\n",
    "    test_accuracy = np.mean([sess.run(accuracy\n",
    "                            ,feed_dict = {x : X[i]\n",
    "                                         ,y_ : Y[i]\n",
    "                                         ,keep_prob : 1.0})\n",
    "                                for i in rnage(10)])\n",
    "\n",
    "print('test accuracy: {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'CIFAR10'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = ''></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = ''></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = ''></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = ''></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = ''></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = ''></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = ''></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
