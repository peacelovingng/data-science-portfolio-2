{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Chapter 3 - Understanding TensorFlow Basics__\n",
    "\n",
    "1. [Import](#Import)\n",
    "1. [Graphs, sessions, and fetches](#Graphs-Sessions-and-Fetches)\n",
    "    1. [Creating a graph](#Creating-a-graph)\n",
    "    1. [Creating a session and running it](02#Creating-a-Session-and-Running-It)\n",
    "    1. [Constructing and managing our graph](#Constructing-and-Managing-Our-Graph)\n",
    "    1. [Fetches](#Fetches)\n",
    "1. [Flowing tensors](#Flowing-Tensors)\n",
    "    1. [Tensor arrays and shapes](#Tensor-Arrays-and-Shapes)\n",
    "    1. [Matrix multiplication](#Matrix-multiplication)\n",
    "    1. [Names](#names)\n",
    "    1. [Name scopes](#Name-scopes)\n",
    "1. [Variables, placeholders, and simple optimization](#Variables-placeholders-and-simple-optimization)\n",
    "    1. [Variables](#Variables)\n",
    "    1. [Placeholders](#Placeholders)\n",
    "    1. [Optimization](#Optimization)\n",
    "        1. [Linear regression](#Linear-regression)\n",
    "        1. [Logistic regression](#Logistic-regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Import'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T04:19:26.674586Z",
     "start_time": "2019-02-27T04:19:26.654391Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# standard libary and settings\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import itertools\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "# data extensions and settings\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(threshold=np.inf, suppress=True)\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.options.display.float_format = \"{:,.6f}\".format\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "# visualization extensions and settings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# custom extensions and settings\n",
    "sys.path.append(\"/main\") if \"/main\" not in sys.path else None\n",
    "import mlmachine as mlm\n",
    "import quickplot as qp\n",
    "\n",
    "# magic functions\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs, sessions, and fetches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Graphs-Sessions-and-Fetches'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Creating-a-graph'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T04:19:39.053661Z",
     "start_time": "2019-02-27T04:19:39.027327Z"
    }
   },
   "outputs": [],
   "source": [
    "# create six nodes, which will be automatically associated with the default graph\n",
    "# define 3 constants\n",
    "a = tf.constant(5)\n",
    "b = tf.constant(2)\n",
    "c = tf.constant(3)\n",
    "\n",
    "# define 2 nodes that perform simple arithmetic operations the constants defined above\n",
    "\n",
    "d = tf.multiply(a, b)\n",
    "e = tf.add(c, b)\n",
    "\n",
    "# define 1 last node that performs arithmetic operations on the two operation nodes above\n",
    "f = tf.subtract(d, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Remarks - In graph form, \n",
    "- c & b are connected to e\n",
    "- b & a are connected to d\n",
    "- e & d are connected to f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a session and running It"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Creating-a-Session-and-Running-It'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T04:19:43.341760Z",
     "start_time": "2019-02-27T04:19:43.293682Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outs = 5\n"
     ]
    }
   ],
   "source": [
    "# create a session and run, then print output\n",
    "sess = tf.Session()\n",
    "outs = sess.run(f)\n",
    "sess.close()\n",
    "\n",
    "print(\"outs = {}\".format(outs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing and managing our graph\n",
    "\n",
    "In addition to the default graph that is automatically created upon import of TensorFlow, we can create additional graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Constructing-and-Managing-Our-Graph'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T04:19:45.483152Z",
     "start_time": "2019-02-27T04:19:45.477428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.framework.ops.Graph object at 0x7f356834e5f8>\n",
      "<tensorflow.python.framework.ops.Graph object at 0x7f3568354390>\n"
     ]
    }
   ],
   "source": [
    "# print default graph and create new empty graph\n",
    "print(tf.get_default_graph())\n",
    "\n",
    "g = tf.Graph()\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T04:19:50.439955Z",
     "start_time": "2019-02-27T04:19:50.433253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# display the graph which constant 'a' is associated with by using 'a.graph'\n",
    "\n",
    "g = tf.Graph()\n",
    "a = tf.constant(5)\n",
    "\n",
    "print(a.graph is g)\n",
    "print(a.graph is tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T04:19:54.440504Z",
     "start_time": "2019-02-27T04:19:54.434469Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# o associate nodes with a new graph, use the 'with' statement\n",
    "# note - a session doesn't need to be closed when using 'with'\n",
    "g1 = tf.get_default_graph()\n",
    "g2 = tf.Graph()\n",
    "\n",
    "print(g1 is tf.get_default_graph())\n",
    "\n",
    "with g2.as_default():\n",
    "    print(g1 is tf.get_default_graph())\n",
    "\n",
    "print(g1 is tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetches\n",
    "\n",
    "In section 3.2, we passed the node 'f' as an argument to sess.run(), which ran all essential nodes needed to complete the operation of 'f'. This argument used to complete the request to 'f' is called 'fetches', which communicate the elements of the graph we want to compute.\n",
    "\n",
    "We can also ask sess.run() to evaluate multiple nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Fetches'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T04:20:00.750943Z",
     "start_time": "2019-02-27T04:20:00.742341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outs = [5, 2, 3, 10, 5]\n",
      "<class 'numpy.int32'>\n"
     ]
    }
   ],
   "source": [
    "# basic fetch example\n",
    "with tf.Session() as sess:\n",
    "    fetches = [a, b, c, d, e]\n",
    "    outs = sess.run(fetches)\n",
    "\n",
    "print(\"outs = {}\".format(outs))\n",
    "print(type(outs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flowing tensors\n",
    "\n",
    "Data types and shapes of objects in TensorFlow are automatically selected by the TensorFlow API but can be explicitly declared as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Flowing-Tensors'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor arrays and shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Tensor-Arrays-and-Shapes'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T04:20:07.971674Z",
     "start_time": "2019-02-27T04:20:07.962987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python list input: (2, 3)\n",
      "3d NumPy array input: (2, 3, 4)\n"
     ]
    }
   ],
   "source": [
    "# convert python list to tensor\n",
    "c = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "print(\"Python list input: {}\".format(c.get_shape()))\n",
    "\n",
    "# convert numpy array to tensor\n",
    "c = tf.constant(\n",
    "    np.array(\n",
    "        [\n",
    "            [[1, 2, 3, 4], [5, 6, 7, 8], [9, 8, 7, 6]],\n",
    "            [[1, 1, 1, 1], [2, 2, 2, 2], [3, 3, 3, 3]],\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "print(\"3d NumPy array input: {}\".format(c.get_shape()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix multiplication\n",
    "\n",
    "tf.matmul(A,B) is an operator for performing matrix multiplicaiton between two TensorFlow objects A and B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Matrix multiplication'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T04:20:13.052114Z",
     "start_time": "2019-02-27T04:20:13.041881Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# create and print basic matrices\n",
    "A = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "print(A.get_shape())\n",
    "\n",
    "x = tf.constant([1, 0, 1])\n",
    "print(x.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T04:20:16.062774Z",
     "start_time": "2019-02-27T04:20:15.995742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n",
      "matmul result: \n",
      " [[ 4]\n",
      " [10]]\n"
     ]
    }
   ],
   "source": [
    "# transform 'x' into a 2D matrix to allow matrix multiplication\n",
    "x = tf.expand_dims(x, 1)\n",
    "print(x.get_shape())\n",
    "\n",
    "b = tf.matmul(A, x)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "print(\"matmul result: \\n {}\".format(b.eval()))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Names\n",
    "\n",
    "The name of a Tensor object is the name of it's corresponding operation (below, \"c\") concatenated with a semi-colon, followed by the index of that tensor in the ouputs of the operation that produced it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'names'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T04:20:20.810193Z",
     "start_time": "2019-02-27T04:20:20.799678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:0\n",
      "c_1:0\n"
     ]
    }
   ],
   "source": [
    "# name demonstration\n",
    "with tf.Graph().as_default():\n",
    "    c1 = tf.constant(4, dtype=tf.float64, name=\"c\")\n",
    "    c2 = tf.constant(4, dtype=tf.int32, name=\"c\")\n",
    "print(c1.name)\n",
    "print(c2.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name scopes\n",
    "\n",
    "In a large complicated graph, it can be helpful to create node groupings to make it easier to follow and manage the graph. Nodes can be grouped together by name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Name-scopes'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T04:20:23.514035Z",
     "start_time": "2019-02-27T04:20:23.498568Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:0\n",
      "my_prefix/c:0\n",
      "my_prefix/c_1:0\n"
     ]
    }
   ],
   "source": [
    "# scope assignment for named variables\n",
    "with tf.Graph().as_default():\n",
    "    c1 = tf.constant(4, dtype=tf.float64, name=\"c\")\n",
    "    with tf.name_scope(\"my_prefix\"):\n",
    "        c2 = tf.constant(4, dtype=tf.int32, name=\"c\")\n",
    "        c3 = tf.constant(4, dtype=tf.float64, name=\"c\")\n",
    "\n",
    "print(c1.name)\n",
    "print(c2.name)\n",
    "print(c3.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables placeholders and simple optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Variables-placeholders-and-simple-optimization'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Variables'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T04:20:31.729111Z",
     "start_time": "2019-02-27T04:20:31.704112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre run: \n",
      " <tf.Variable 'var_1:0' shape=(1, 5) dtype=float32_ref>\n",
      "post run: \n",
      "[[ 1.91401    1.1235803 -0.9982488  1.9636389  1.1689807]]\n"
     ]
    }
   ],
   "source": [
    "# demonstrating the need to initializer variables\n",
    "init_val = tf.random_normal((1, 5), 0, 1)\n",
    "var = tf.Variable(init_val, name=\"var\")\n",
    "print(\"pre run: \\n {}\".format(var))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    post_var = sess.run(var)\n",
    "\n",
    "print(\"post run: \\n{}\".format(post_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placeholders\n",
    "\n",
    "Placeholders are structures for feeding input values. They can be thought of as empty Variables that will be filled with data once the graph is executed.\n",
    "\n",
    "Placeholders have an option shape argument. If nothing passed, or None is passed, the placeholder can be fed with data of any size. None is commonly used for the dimension of a matrix that corresponds to the number of sample/rows, as this will vary, while the column are more commonly fixed.\n",
    "\n",
    "Data is passed to the placeholder via a dictionary, where each key corresponds to a placeholder variable name. The corresponding values are given in the form of a list or a numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Placeholders'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T04:20:38.834389Z",
     "start_time": "2019-02-27T04:20:38.806363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outs = 1.8971624374389648\n"
     ]
    }
   ],
   "source": [
    "# placeholder demonstration\n",
    "X_data = np.random.randn(5, 10)\n",
    "w_data = np.random.randn(10, 1)\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    x = tf.placeholder(tf.float32, shape=(5, 10))\n",
    "    w = tf.placeholder(tf.float32, shape=(10, 1))\n",
    "    b = tf.fill((5, 1), -1.0)\n",
    "    xw = tf.matmul(x, w)\n",
    "\n",
    "    xwb = xw + b\n",
    "    s = tf.reduce_max(xwb)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        outs = sess.run(s, feed_dict={x: X_data, w: w_data})\n",
    "\n",
    "    print(\"outs = {}\".format(outs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "\n",
    "Optimization illustrated with simple linear regression: $f(x_i) = \\hat{y}_i = w^tx_i + b$, where $y_i = f(x_i) + \\epsilon_i$ and we want to minimize the mean squared error.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Optimization'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Linear-regression'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T04:21:04.294873Z",
     "start_time": "2019-02-27T04:21:04.063432Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [array([[0.3015244 , 0.49586824, 0.10175166]], dtype=float32), -0.215378]\n",
      "2 [array([[0.29981044, 0.50398886, 0.0995269 ]], dtype=float32), -0.20045908]\n",
      "4 [array([[0.29978955, 0.50406104, 0.09946999]], dtype=float32), -0.20036498]\n",
      "6 [array([[0.29978946, 0.50406164, 0.09946943]], dtype=float32), -0.20036423]\n",
      "8 [array([[0.29978943, 0.50406164, 0.09946943]], dtype=float32), -0.20036422]\n",
      "10 [array([[0.29978943, 0.50406164, 0.09946943]], dtype=float32), -0.20036422]\n"
     ]
    }
   ],
   "source": [
    "# define placeholders and variables\n",
    "X_data = np.random.randn(2000, 3)\n",
    "w_real = [0.3, 0.5, 0.1]\n",
    "b_real = -0.2\n",
    "\n",
    "noise = np.random.randn(1, 2000) * 0.1\n",
    "y_data = np.matmul(w_real, X_data.T) + b_real + noise\n",
    "\n",
    "steps = 10\n",
    "\n",
    "g = tf.Graph()\n",
    "wb_ = []\n",
    "\n",
    "# create graph\n",
    "with g.as_default():\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "    y_true = tf.placeholder(tf.float32, shape=None)\n",
    "\n",
    "    with tf.name_scope(\"inference\") as scope:\n",
    "        w = tf.Variable([[0, 0, 0]], dtype=tf.float32, name=\"weights\")\n",
    "        b = tf.Variable(0, dtype=tf.float32, name=\"bias\")\n",
    "        y_pred = tf.matmul(w, tf.transpose(x)) + b\n",
    "\n",
    "    with tf.name_scope(\"loss\") as scope:\n",
    "        loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "    with tf.name_scope(\"train\") as scope:\n",
    "        learning_rate = 0.5\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "        train = optimizer.minimize(loss)\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # run session\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for step in range(steps):\n",
    "            sess.run(train, feed_dict={x: X_data, y_true: y_data})\n",
    "            if step % 2 == 0:\n",
    "                print(step, sess.run([w, b]))\n",
    "                wb_.append(sess.run([w, b]))\n",
    "        print(10, sess.run([w, b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Remarks - The weight are very close to the 'w_real' weights defined at the top of the cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Logistic-regression'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T04:21:19.098484Z",
     "start_time": "2019-02-27T04:21:18.679060Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [array([[0.03441676, 0.05773995, 0.01258209]], dtype=float32), -0.025224965]\n",
      "5 [array([[0.15201882, 0.25483793, 0.05599811]], dtype=float32), -0.111012876]\n",
      "10 [array([[0.21469587, 0.35958746, 0.07950159]], dtype=float32), -0.15622394]\n",
      "15 [array([[0.24967462, 0.41782314, 0.09278664]], dtype=float32), -0.18111035]\n",
      "20 [array([[0.26978803, 0.45117033, 0.10050852]], dtype=float32), -0.19521496]\n",
      "25 [array([[0.28155884, 0.47060493, 0.10507002]], dtype=float32), -0.20335329]\n",
      "30 [array([[0.288518  , 0.48204958, 0.10778928]], dtype=float32), -0.20810084]\n",
      "35 [array([[0.29265678, 0.4888307 , 0.10941843]], dtype=float32), -0.21088935]\n",
      "40 [array([[0.2951265 , 0.49286327, 0.11039708]], dtype=float32), -0.21253435]\n",
      "45 [array([[0.29660305, 0.49526668, 0.1109857 ]], dtype=float32), -0.21350756]\n",
      "50 [array([[0.29734427, 0.49647   , 0.11128268]], dtype=float32), -0.21399185]\n"
     ]
    }
   ],
   "source": [
    "# generate sample data\n",
    "n = 20000\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "X_data = np.random.randn(n, 3)\n",
    "w_real = [0.3, 0.5, 0.1]\n",
    "b = -0.2\n",
    "wxb = np.matmul(w_real, X_data.T) + b\n",
    "\n",
    "y_data_pre_noise = sigmoid(wxb)\n",
    "y_data = np.random.binomial(1, y_data_pre_noise)\n",
    "\n",
    "# y_pred = tf.sigmoid(y_pred)\n",
    "# loss = -y_true * tf.log(y_pred) - (1 - y_true) * tf.log(1 - y_pred)\n",
    "# loss = tf.reduce_mean(loss)\n",
    "\n",
    "steps = 50\n",
    "\n",
    "# create graph\n",
    "with g.as_default():\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "    y_true = tf.placeholder(tf.float32, shape=None)\n",
    "\n",
    "    with tf.name_scope(\"inference\") as scope:\n",
    "        w = tf.Variable([[0, 0, 0]], dtype=tf.float32, name=\"weights\")\n",
    "        b = tf.Variable(0, dtype=tf.float32, name=\"bias\")\n",
    "        y_pred = tf.matmul(w, tf.transpose(x)) + b\n",
    "\n",
    "    with tf.name_scope(\"loss\") as scope:\n",
    "        loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "\n",
    "    with tf.name_scope(\"train\") as scope:\n",
    "        learning_rate = 0.5\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "        train = optimizer.minimize(loss)\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # run session\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for step in range(steps):\n",
    "            sess.run(train, feed_dict={x: X_data, y_true: y_data})\n",
    "            if step % 5 == 0:\n",
    "                print(step, sess.run([w, b]))\n",
    "                wb_.append(sess.run([w, b]))\n",
    "        print(50, sess.run([w, b]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
