{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  __Chapter 3 - Part of speech tagging__\n",
    "\n",
    "1. [Import](#Import)\n",
    "    1. [Part of speech tagging](#Part-of-speech-tagging)\n",
    "    1. [Stanford tagger](#Stanford-tagger)\n",
    "    1. [N-gram-tagger](#N-gram-tagger)\n",
    "    1. [Regex tagger](#Regex-tagger)\n",
    "1. [Named entity recognition (NER)](#Named-entity-recognition-(NER))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Import'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Standard libary and settings\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import itertools\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "# Data extensions and settings\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(threshold=np.inf, suppress=True)\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.options.display.float_format = \"{:,.6f}\".format\n",
    "\n",
    "# Modeling extensions\n",
    "import nltk\n",
    "\n",
    "# Visualization extensions and settings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part of speech tagging\n",
    "\n",
    "Part of speech (POS) tagging is process of identifying words as nouns, adjectives, verbs, etc. Current algorithms can predict POS with 97 percent accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Part-of-speech-tagging'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP'), ('was', 'VBD'), ('watching', 'VBG'), ('TV', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# identify POS in a simple sentence\n",
    "from nltk import word_tokenize\n",
    "\n",
    "s = \"I was watching TV\"\n",
    "print(nltk.pos_tag(word_tokenize(s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TV']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return all nouns\n",
    "tagged = nltk.pos_tag(word_tokenize(s))\n",
    "allnoun = [word for word, pos in tagged if pos in [\"NN\", \"NNP\"]]\n",
    "allnoun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 218 samples and 100554 outcomes>\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "from nltk.corpus import brown\n",
    "\n",
    "tags = [tag for (word, tag) in brown.tagged_words(categories=\"news\")]\n",
    "print(nltk.FreqDist(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13089484257215028\n"
     ]
    }
   ],
   "source": [
    "# baseline prediction vs. brown corpus\n",
    "brown_tagged_sents = brown.tagged_sents(categories=\"news\")\n",
    "default_tagger = nltk.DefaultTagger(\"NN\")\n",
    "print(default_tagger.evaluate(brown_tagged_sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stanford tagger\n",
    "\n",
    "To use the above code, you need to download the Stanford tagger from http://nlp.stanford.edu/software/stanford-postagger-full-2014-08-27.zip. Extract both the jar and model into a folder, and give an absolute path in argument for the POSTagger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Stanford-tagger'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "from nltk.tag.stanford import POSTagger\n",
    "\n",
    "stanford = POSTagger(\n",
    "    \"models/english-bidirectional-distdim.tagger\", \"standford-postagger.jar\"\n",
    ")\n",
    "tokens = nltk.word_tokenize(s)\n",
    "print(stanford.tag(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram tagger\n",
    "\n",
    "UnigramTagger considers the conditional frequency of tags among each token and simply predicts the most frequent tag for each token.\n",
    "\n",
    "BigramTagger considers the tag of the focus word and the word previous to that word. Trigram taggers consideres the tags of the two previous words.\n",
    "\n",
    "Generally speaking, the trigram tagger will have higher accuracy but lower coverage. The opposite is true for unigram tagger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'N-gram-tagger'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8361407355726104\n",
      "0.8452108043456593\n",
      "0.843317053722715\n"
     ]
    }
   ],
   "source": [
    "# utilize unigram, bigram and trigram tagger\n",
    "from nltk.tag import UnigramTagger, DefaultTagger, BigramTagger, TrigramTagger\n",
    "\n",
    "train_data = brown_tagged_sents[: int(len(brown_tagged_sents) * 0.9)]\n",
    "test_data = brown_tagged_sents[int(len(brown_tagged_sents) * 0.9) :]\n",
    "\n",
    "# combine taggers > each tagger uses the previous tagger as its backoff, which is invokted when a tag cannot be predicted\n",
    "# this helps balance the tradeoff etween precision and recall\n",
    "unigram_tagger = UnigramTagger(train_data, backoff=default_tagger)\n",
    "print(unigram_tagger.evaluate(test_data))\n",
    "\n",
    "bigram_tagger = BigramTagger(train_data, backoff=unigram_tagger)\n",
    "print(bigram_tagger.evaluate(test_data))\n",
    "\n",
    "trigram_tagger = TrigramTagger(train_data, backoff=bigram_tagger)\n",
    "print(trigram_tagger.evaluate(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regex tagger\n",
    "\n",
    "The regex tagger can be useful when there are many domain-specific words that are not understood by the stock references used by NLTK's taggers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Regex-tagger'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0026911193062892453\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "from nltk.tag.sequential import RegexpTagger\n",
    "\n",
    "regex_tagger = RegexpTagger([(r\".*able\", \"JJ\"), (r\".*ness\", \"NN\")])  # adjectives\n",
    "print(regex_tagger.evaluate(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named entity recognition (NER)\n",
    "\n",
    "Named entities are typically people, locations and organizations, among others.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Named-entity-recognition-(NER)'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PERSON Mark/NNP)\n",
      "  is/VBZ\n",
      "  studying/VBG\n",
      "  at/IN\n",
      "  (ORGANIZATION Stanford/NNP University/NNP)\n",
      "  in/IN\n",
      "  (GPE California/NNP))\n"
     ]
    }
   ],
   "source": [
    "# Basic named entity tagging\n",
    "from nltk import ne_chunk\n",
    "\n",
    "sent = \"Mark is studying at Stanford University in California\"\n",
    "print(ne_chunk(nltk.pos_tag(word_tokenize(sent)), binary=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK / Stanford NER - needs to be downloaded to work.\n",
    "from nltk.tag.stanford import StanfordNERTagger\n",
    "\n",
    "st = StanfordNERTagger()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
