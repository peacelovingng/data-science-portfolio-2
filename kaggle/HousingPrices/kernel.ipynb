{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Kaggle competition - house prices__\n",
    "\n",
    "1. [Import](#Import)\n",
    "    1. [Tools](#Tools)\n",
    "    1. [Data](#Data)    \n",
    "1. [Initial EDA](#Initial-EDA)\n",
    "    1. [Categorical feature EDA](#Categorical-feature-EDA)\n",
    "        1. [Univariate & feature vs. target](#Univariate-&-feature-vs.-target)\n",
    "    1. [Continuous feature EDA](#Continuous-feature-EDA)\n",
    "        1. [Univariate & feature vs. target](#Univariate-&-feature-vs.-target2)\n",
    "        1. [Correlation](#Correlation)\n",
    "        1. [Pair plot](#Pair-plot)\n",
    "    1. [Faceting](#Faceting)\n",
    "    1. [Target variable evaluation](#Target-variable-evaluation)    \n",
    "1. [Data preparation](#Data-preparation)\n",
    "    1. [Outliers (preliminary)](#Outliers-preliminary)\n",
    "        1. [Evaluate](#Evaluate)\n",
    "        1. [Remove](#remove)\n",
    "    1. [Missing data](#Missing-data)\n",
    "        1. [Evaluate](#Evaluate1)\n",
    "        1. [Impute](#Impute)\n",
    "    1. [Engineering](#Engineering)\n",
    "        1. [Evaluate](#Evaluate3)\n",
    "        1. [Engineer](#Engineer)\n",
    "    1. [Encoding](#Encoding)\n",
    "        1. [Evaluate](#Evaluate2)\n",
    "        1. [Encode](#Encode)\n",
    "    1. [Transformation](#Transformation)\n",
    "        1. [Evaluate](#Evaluate4)\n",
    "        1. [Transform](#Transform)\n",
    "    1. [Outliers (final)](#Outliers-final)\n",
    "        1. [Evaluate](#Evaluate5)\n",
    "        1. [Remove](#remove1)\n",
    "1. [Data evaluation](#Data-evaluation)\n",
    "    1. [Feature importance](#Feature-importance)    \n",
    "    1. [Rationality](#Rationality)\n",
    "    1. [Value override](#Value-override)\n",
    "    1. [Continuous feature EDA](#Continuous-feature-EDA3)\n",
    "    1. [Correlation](#Correlation3)\n",
    "1. [Modeling](#Modeling)\n",
    "    1. [Data preparation](#Data-preparation-1)\n",
    "    1. [Bayesian hyper-parameter optimization](#Bayesian-hyper-parameter-optimization)\n",
    "        1. [Model loss by iteration](#Model-loss-by-iteration)\n",
    "        1. [Parameter selection by iteration](#Parameter-selection-by-iteration)\n",
    "    1. [Model performance evaluation](#Model-performance-evaluation)\n",
    "        1. [Residual plots](#Residual-plots)\n",
    "    1. [Model explanability](#Model-explanability)\n",
    "        1. [Permutation importance](#Permutation-importance)\n",
    "        1. [Partial plots](#Partial-plots)\n",
    "        1. [SHAP values](#SHAP-values)\n",
    "    1. [Stacking](#Stacking)\n",
    "        1. [Primary models](#Primary-models)\n",
    "        1. [Meta model](#Meta-model)                \n",
    "1. [Submission](#Submission)\n",
    "    1. [Standard](#Standard)\n",
    "    1. [Stack](#Stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Import'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Tools'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T20:12:47.475833Z",
     "start_time": "2019-07-20T20:12:47.251798Z"
    }
   },
   "outputs": [],
   "source": [
    "# standard libary and settings\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import itertools\n",
    "import csv\n",
    "import ast\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "global ITERATION\n",
    "import time\n",
    "from functools import reduce\n",
    "\n",
    "rundate = time.strftime(\"%Y%m%d\")\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "# data extensions and settings\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(threshold=np.inf, suppress=True)\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.options.display.float_format = \"{:,.6f}\".format\n",
    "\n",
    "# modeling extensions\n",
    "import sklearn.base as base\n",
    "import sklearn.cluster as cluster\n",
    "import sklearn.datasets as datasets\n",
    "import sklearn.decomposition as decomposition\n",
    "import sklearn.discriminant_analysis as discriminant_analysis\n",
    "import sklearn.ensemble as ensemble\n",
    "import sklearn.feature_extraction as feature_extraction\n",
    "import sklearn.feature_selection as feature_selection\n",
    "import sklearn.gaussian_process as gaussian_process\n",
    "import sklearn.linear_model as linear_model\n",
    "import sklearn.kernel_ridge as kernel_ridge\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.model_selection as model_selection\n",
    "import sklearn.naive_bayes as naive_bayes\n",
    "import sklearn.neighbors as neighbors\n",
    "import sklearn.pipeline as pipeline\n",
    "import sklearn.preprocessing as preprocessing\n",
    "import sklearn.svm as svm\n",
    "import sklearn.tree as tree\n",
    "import sklearn.utils as utils\n",
    "\n",
    "import eif\n",
    "import shap; shap.initjs()\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from pdpbox import pdp, get_dataset, info_plots\n",
    "\n",
    "from scipy import stats, special\n",
    "import xgboost\n",
    "import lightgbm\n",
    "import catboost\n",
    "\n",
    "from hyperopt import hp, tpe, Trials, fmin, STATUS_OK\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "\n",
    "# visualization extensions and settings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "try:\n",
    "    import mlmachine as mlm\n",
    "    from prettierplot.plotter import PrettierPlot\n",
    "    import prettierplot.style as style\n",
    "except ModuleNotFoundError:\n",
    "    sys.path.append(\"../../../mlmachine\") if \"../../../../mlmachine\" not in sys.path else None\n",
    "    sys.path.append(\"../../../prettierplot\") if \"../../../../prettierplot\" not in sys.path else None\n",
    "    \n",
    "    import mlmachine as mlm\n",
    "    from prettierplot.plotter import PrettierPlot\n",
    "    import prettierplot.style as style\n",
    "else:\n",
    "    print('This notebook relies on the libraries mlmachine and prettierplot. Please run:')\n",
    "    print('\\tpip install mlmachine')\n",
    "    print('\\tpip install prettierplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id = 'Data'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T19:37:45.418498Z",
     "start_time": "2019-07-20T19:37:45.330121Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load data and print dimensions\n",
    "dfTrain = pd.read_csv(\"../../data/kaggleHousingPrices/train.csv\")\n",
    "dfValid = pd.read_csv(\"../../data/kaggleHousingPrices/test.csv\")\n",
    "\n",
    "print(\"Training data dimensions: {}\".format(dfTrain.shape))\n",
    "print(\"Validation data dimensions: {}\".format(dfValid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:42:54.718153Z",
     "start_time": "2019-07-20T04:42:54.571238Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# display info and first 5 rows\n",
    "dfTrain.info()\n",
    "display(dfTrain[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:42:54.732880Z",
     "start_time": "2019-07-20T04:42:54.721445Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# review counts of different column types\n",
    "dfTrain.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:42:54.763797Z",
     "start_time": "2019-07-20T04:42:54.737660Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load training data into mlmachine\n",
    "train = mlm.Machine(\n",
    "    data=dfTrain,\n",
    "    target=\"SalePrice\",\n",
    "    removeFeatures=[\"Id\"],\n",
    "    overrideCat=[\n",
    "        \"MSSubClass\",\n",
    "        \"OverallQual\",\n",
    "        \"OverallCond\",\n",
    "        \"YearBuilt\",\n",
    "        \"YearRemodAdd\",\n",
    "        \"MoSold\",\n",
    "        \"YrSold\",\n",
    "    ],\n",
    "    targetType=\"continuous\",\n",
    ")\n",
    "print(train.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:42:54.783275Z",
     "start_time": "2019-07-20T04:42:54.767905Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load training data into mlmachine\n",
    "valid = mlm.Machine(\n",
    "    data=dfValid,\n",
    "    removeFeatures=[\"Id\"],\n",
    "    overrideCat=[\n",
    "        \"MSSubClass\",\n",
    "        \"OverallQual\",\n",
    "        \"OverallCond\",\n",
    "        \"YearBuilt\",\n",
    "        \"YearRemodAdd\",\n",
    "        \"MoSold\",\n",
    "        \"YrSold\",\n",
    "    ],\n",
    ")\n",
    "print(valid.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Initial EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id = 'Initial-EDA'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Categorical feature EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id = 'Categorical-feature-EDA'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Univariate & feature vs. target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id = 'Univariate-&-feature-vs.-target'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:43:35.272607Z",
     "start_time": "2019-07-20T04:42:54.786583Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# categorical features\n",
    "for feature in train.featureByDtype_[\"categorical\"]:\n",
    "    train.edaNumTargetCatFeat(feature=feature, levelCountCap=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Continuous feature EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id = 'Continuous-feature-EDA'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Univariate & feature vs. target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id = 'Univariate-&-feature-vs.-target2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:44:07.788088Z",
     "start_time": "2019-07-20T04:43:35.278519Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# continuous features\n",
    "for feature in train.featureByDtype_[\"continuous\"]:\n",
    "    print(feature)\n",
    "    train.edaNumTargetNumFeat(feature=feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id = 'Correlation'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Correlation (all samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:44:10.123435Z",
     "start_time": "2019-07-20T04:44:07.812855Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# correlation heat map\n",
    "p = PrettierPlot(chartProp=25)\n",
    "ax = p.makeCanvas()\n",
    "p.prettyCorrHeatmap(df=train.data, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Correlation (top vs. target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:44:10.614921Z",
     "start_time": "2019-07-20T04:44:10.129731Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# correlation heat map with most highly correlated features relative to the target\n",
    "p = PrettierPlot(plotOrientation='tall',chartProp=15)\n",
    "ax = p.makeCanvas()\n",
    "p.prettyCorrHeatmapTarget(df=train.data, target=train.target, thresh=0.6, annot = True, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Remarks - There are three pairs of highly correlated features:\n",
    "    - 'GarageArea' and 'GarageCars'\n",
    "    - 'TotRmsAbvGrd' and 'GrLivArea'\n",
    "    - '1stFlrSF' and 'TotalBsmtSF\n",
    "This makes sense, given what each feature represents and how each pair items relate to each other. We likely only need one feature from each pair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Pair plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id = 'Pair-plot'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:45:46.386025Z",
     "start_time": "2019-07-20T04:44:10.617963Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pair plot\n",
    "p = PrettierPlot(chartProp=10)\n",
    "p.prettyPairPlot(\n",
    "    df=train.data,\n",
    "    cols=[\n",
    "        \"LotFrontage\",\n",
    "        \"LotArea\",\n",
    "        \"MasVnrArea\",\n",
    "        \"BsmtFinSF1\",\n",
    "        \"BsmtFinSF2\",\n",
    "        \"BsmtUnfSF\",\n",
    "        \"TotalBsmtSF\",\n",
    "        \"1stFlrSF\",\n",
    "        \"2ndFlrSF\",\n",
    "        \"GrLivArea\",\n",
    "        \"TotRmsAbvGrd\",\n",
    "        \"GarageYrBlt\",\n",
    "        \"GarageArea\",\n",
    "        \"WoodDeckSF\",\n",
    "        \"OpenPorchSF\",\n",
    "    ],\n",
    "    diag_kind=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Faceting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id = 'Faceting'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Categorical by categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Categorical by continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Target variable evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id = 'Target-variable-evaluation'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:45:47.515789Z",
     "start_time": "2019-07-20T04:45:46.388615Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# evaluate distribution of target variable\n",
    "train.edaTransformInitial(data=train.target, name=train.target.name)\n",
    "train.edaTransformLog1(data=train.target, name=train.target.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:45:47.584359Z",
     "start_time": "2019-07-20T04:45:47.519156Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# log + 1 transform target\n",
    "train.target = np.log1p(train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id = 'Data-preparation'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Outliers (preliminary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id = 'Outliers-preliminary'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id = 'Evaluate'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Training outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:45:47.648772Z",
     "start_time": "2019-07-20T04:45:47.594360Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# identify columns that have zero missing values\n",
    "nonNull = train.data.columns[train.data.isnull().sum() == 0].values.tolist()\n",
    "\n",
    "# identify intersection between non-null columns and continuous columns\n",
    "nonNullNumCol = list(set(nonNull).intersection(train.featureByDtype_[\"continuous\"]))\n",
    "print(nonNullNumCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# identify outliers using IQR\n",
    "trainPipe = pipeline.Pipeline([\n",
    "    (\"outlier\",train.OutlierIQR(\n",
    "                outlierCount=5,\n",
    "                iqrStep=1.5,\n",
    "                features=nonNullNumCol,\n",
    "                dropOutliers=False,))\n",
    "    ])\n",
    "train.data = trainPipe.transform(train.data)\n",
    "\n",
    "# capture outliers\n",
    "iqrOutliers = np.array(sorted(trainPipe.named_steps[\"outlier\"].outliers_))\n",
    "print(iqrOutliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:45:48.988467Z",
     "start_time": "2019-07-20T04:45:47.969041Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# identify outliers using Isolation Forest\n",
    "clf = ensemble.IsolationForest(\n",
    "    behaviour=\"new\", max_samples=train.data.shape[0], random_state=0, contamination=0.02\n",
    ")\n",
    "clf.fit(train.data[nonNullNumCol])\n",
    "preds = clf.predict(train.data[nonNullNumCol])\n",
    "\n",
    "# evaluate index values\n",
    "mask = np.isin(preds, -1)\n",
    "ifOutliers = np.array(train.data[mask].index)\n",
    "print(ifOutliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:45:57.873093Z",
     "start_time": "2019-07-20T04:45:49.000586Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# identify outliers using extended isolation forest\n",
    "trainPipe = pipeline.Pipeline([\n",
    "    (\"outlier\",train.ExtendedIsoForest(\n",
    "                cols=nonNullNumCol,\n",
    "                nTrees=100,\n",
    "                sampleSize=256,\n",
    "                ExtensionLevel=1,\n",
    "                anomaliesRatio=0.009,\n",
    "                dropOutliers=False,))\n",
    "    ])\n",
    "train.data = trainPipe.transform(train.data)\n",
    "\n",
    "# capture outliers\n",
    "eifOutliers = np.array(sorted(trainPipe.named_steps[\"outlier\"].outliers_))\n",
    "print(eifOutliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:46:06.049242Z",
     "start_time": "2019-07-20T04:46:06.045179Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# identify outliers that are identified in multiple algorithms\n",
    "# reduce(np.intersect1d, (iqrOutliers, ifOutliers, eifOutliers))\n",
    "outliers = reduce(np.intersect1d, (ifOutliers, eifOutliers))\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# review outlier identification summary\n",
    "outlierSummary = train.outlierSummary(iqrOutliers=iqrOutliers,\n",
    "                                      ifOutliers=ifOutliers,\n",
    "                                      eifOutliers=eifOutliers)\n",
    "outlierSummary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Validation outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Remove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id = 'remove'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:46:06.064635Z",
     "start_time": "2019-07-20T04:46:06.051539Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# capture index values of known outliers\n",
    "knownOutliers = (\n",
    "    train.data[train.data[\"LotArea\"] > 60000].index.values.tolist()\n",
    "    + train.data[train.data[\"LotFrontage\"] > 300].index.values.tolist()\n",
    "    + train.data[train.data[\"GrLivArea\"] > 4000].index.values.tolist()\n",
    ")\n",
    "knownOutliers = sorted(set(knownOutliers))\n",
    "print(knownOutliers)\n",
    "\n",
    "# train.data = train.data.drop(train.data.index[outliers])\n",
    "# train.target = np.delete(train.target, outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:46:06.072907Z",
     "start_time": "2019-07-20T04:46:06.067849Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# index of known outliers and outliers identified with the known outliers removed\n",
    "outliers = [\n",
    "    53,\n",
    "    185,\n",
    "    197,\n",
    "    437,\n",
    "    492,\n",
    "    762,\n",
    "    796,\n",
    "    821,\n",
    "    847,\n",
    "    1161,\n",
    "    1221,\n",
    "    1318,\n",
    "    1376,\n",
    "    249,\n",
    "    313,\n",
    "    335,\n",
    "    451,\n",
    "    523,\n",
    "    691,\n",
    "    706,\n",
    "    934,\n",
    "    1182,\n",
    "    1298,\n",
    "]\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:46:06.180708Z",
     "start_time": "2019-07-20T04:46:06.074983Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# remove outlers from predictors and response\n",
    "train.data = train.data.drop(outliers)\n",
    "train.target = train.target.drop(index=outliers)\n",
    "print(train.data.shape)\n",
    "print(train.target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Missing data\n",
    "\n",
    "-__MCAR__ - Completely unsystematic missingness, completely unralted to any of the other variables. simple imputation of mean, median or mode is most acceptable for this type of missingness.\n",
    "\n",
    "-__MAR__ - The nature of the missing data is related to observed data in other variables, not the missing data. The missing data is conditional on some other variable.  For example, men are more likely to tell you their weight than woemn. The missingness of weight has to do with gender.\n",
    "\n",
    "-__MNAR__ - There is a relationship between the propensity of a value to be missing and its values. For example, the wealthiest people choosing not to state their income.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id = 'Missing-data'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Evaluate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id = 'Evaluate1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Training missingness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:46:06.623767Z",
     "start_time": "2019-07-20T04:46:06.182662Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate missing data\n",
    "train.edaMissingSummary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:46:08.004752Z",
     "start_time": "2019-07-20T04:46:06.630193Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# missingno matrix\n",
    "msno.matrix(train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:46:21.653998Z",
     "start_time": "2019-07-20T04:46:08.013522Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# missingno bar\n",
    "msno.bar(train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:46:23.059286Z",
     "start_time": "2019-07-20T04:46:21.658876Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# missingno heatmap\n",
    "msno.heatmap(train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:46:25.866533Z",
     "start_time": "2019-07-20T04:46:23.065019Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# missingno dendrogram\n",
    "msno.dendrogram(train.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "##### Validation missingness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:46:26.952168Z",
     "start_time": "2019-07-20T04:46:25.869002Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate missing data\n",
    "valid.edaMissingSummary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:46:28.188266Z",
     "start_time": "2019-07-20T04:46:26.954092Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# missingno matrix\n",
    "msno.matrix(valid.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:46:43.663550Z",
     "start_time": "2019-07-20T04:46:28.198823Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# missingno bar\n",
    "msno.bar(valid.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:46:46.318169Z",
     "start_time": "2019-07-20T04:46:43.668894Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# missingno heatmap\n",
    "msno.heatmap(valid.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:46:49.010709Z",
     "start_time": "2019-07-20T04:46:46.328966Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# missingno dendrogram\n",
    "msno.dendrogram(valid.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "##### Training vs. validation missingness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:46:49.056555Z",
     "start_time": "2019-07-20T04:46:49.016133Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# compare feature with missing data\n",
    "train.missingColCompare(train.data, valid.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Impute\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id = 'Impute'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Impute training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:46:49.282072Z",
     "start_time": "2019-07-20T04:46:49.062816Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# apply imputations to missing data in training dataset\n",
    "trainPipe = pipeline.Pipeline([\n",
    "        (\"imputeConstantCat\",train.ConstantImputer(\n",
    "                cols=[\n",
    "                    \"PoolQC\",\n",
    "                    \"Alley\",\n",
    "                    \"Fence\",\n",
    "                    \"FireplaceQu\",\n",
    "                    \"GarageType\",\n",
    "                    \"GarageFinish\",\n",
    "                    \"GarageQual\",\n",
    "                    \"MiscFeature\",\n",
    "                    \"GarageCond\",\n",
    "                    \"BsmtQual\",\n",
    "                    \"BsmtCond\",\n",
    "                    \"BsmtExposure\",\n",
    "                    \"BsmtFinType1\",\n",
    "                    \"BsmtFinType2\",\n",
    "                    \"MasVnrType\",\n",
    "                ],\n",
    "                fill=\"Nonexistent\",)),\n",
    "        (\"imputeConstantNum\",train.ConstantImputer(cols=[\"GarageYrBlt\", \"MasVnrArea\"], fill=0)),\n",
    "        (\"imputeMode\", train.ModeImputer(cols=[\"Electrical\"])),\n",
    "        (\"imputeContext\",train.ContextImputer(nullCol=\"LotFrontage\", contextCol=\"Neighborhood\", strategy=\"mean\")),\n",
    "    ])\n",
    "train.data = trainPipe.transform(train.data)\n",
    "train.edaMissingSummary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Impute validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:46:49.619278Z",
     "start_time": "2019-07-20T04:46:49.286182Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# apply imputations to missing data in validation dataset\n",
    "validPipe = pipeline.Pipeline([\n",
    "        (\"imputeConstantCat\",valid.ConstantImputer(\n",
    "                cols=[\n",
    "                    \"PoolQC\",\n",
    "                    \"Alley\",\n",
    "                    \"Fence\",\n",
    "                    \"FireplaceQu\",\n",
    "                    \"GarageType\",\n",
    "                    \"GarageFinish\",\n",
    "                    \"GarageQual\",\n",
    "                    \"MiscFeature\",\n",
    "                    \"GarageCond\",\n",
    "                    \"BsmtQual\",\n",
    "                    \"BsmtCond\",\n",
    "                    \"BsmtExposure\",\n",
    "                    \"BsmtFinType1\",\n",
    "                    \"BsmtFinType2\",\n",
    "                    \"MasVnrType\",\n",
    "                ],\n",
    "                fill=\"Nonexistent\",)),\n",
    "        (\"imputeConstantNum\",valid.ConstantImputer(cols=[\"GarageYrBlt\",\"MasVnrArea\",\"BsmtUnfSF\",\"GarageArea\",\"BsmtFinSF1\",\"TotalBsmtSF\",\"BsmtFinSF2\",],fill=0,)),\n",
    "        (\"imputeModeCat\",valid.ModeImputer(cols=[\"Functional\",\"SaleType\",\"Exterior1st\",\"MSZoning\",\"Exterior2nd\",\"KitchenQual\",\"Utilities\",])),\n",
    "        (\"imputeModeNum\",valid.NumericalImputer(cols=[\"BsmtHalfBath\", \"GarageCars\", \"BsmtFullBath\"],strategy=\"most_frequent\",)),\n",
    "        (\"imputeContext\",valid.ContextImputer(nullCol=\"LotFrontage\",contextCol=\"Neighborhood\",strategy=\"mean\",train=False,\n",
    "                trainValue=trainPipe.named_steps[\"imputeContext\"].trainValue_,)),\n",
    "    ])\n",
    "valid.data = validPipe.transform(valid.data)\n",
    "valid.edaMissingSummary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id = 'Engineering'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Evaluate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id = 'Evaluate3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Engineer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id = 'Engineer'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Engineer training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:46:49.631672Z",
     "start_time": "2019-07-20T04:46:49.623399Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# additional features\n",
    "train.data[\"BsmtFinSF\"] = train.data[\"BsmtFinSF1\"] + train.data[\"BsmtFinSF2\"]\n",
    "train.data[\"TotalSF\"] = (\n",
    "    train.data[\"TotalBsmtSF\"] + train.data[\"1stFlrSF\"] + train.data[\"2ndFlrSF\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Engineer validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:46:49.647377Z",
     "start_time": "2019-07-20T04:46:49.634946Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# additional features\n",
    "valid.data[\"BsmtFinSF\"] = valid.data[\"BsmtFinSF1\"] + valid.data[\"BsmtFinSF2\"]\n",
    "valid.data[\"TotalSF\"] = (\n",
    "    valid.data[\"TotalBsmtSF\"] + valid.data[\"1stFlrSF\"] + valid.data[\"2ndFlrSF\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id = 'Encoding'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Evaluate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id = 'Evaluate2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Training feature evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:46:49.722363Z",
     "start_time": "2019-07-20T04:46:49.650256Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# counts of unique values in training data categorical columns\n",
    "train.data[train.featureByDtype_[\"categorical\"]].apply(pd.Series.nunique, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:46:49.802569Z",
     "start_time": "2019-07-20T04:46:49.729924Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print unique values in each categorical columns\n",
    "for col in train.data[train.featureByDtype_[\"categorical\"]]:\n",
    "    print(col, np.unique(train.data[col]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Validation feature evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:46:49.885991Z",
     "start_time": "2019-07-20T04:46:49.805626Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# counts of unique values in validation data string columns\n",
    "valid.data[valid.featureByDtype_[\"categorical\"]].apply(pd.Series.nunique, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:46:50.062824Z",
     "start_time": "2019-07-20T04:46:49.888584Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print unique values in each categorical columns\n",
    "for col in valid.data[valid.featureByDtype_[\"categorical\"]]:\n",
    "    if col not in [\"Name\", \"Cabin\"]:\n",
    "        print(col, np.unique(valid.data[col]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Training vs. validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:46:50.205466Z",
     "start_time": "2019-07-20T04:46:50.083254Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# identify values that are present in the training data but not the validation data, and vice versa\n",
    "for col in train.featureByDtype_[\"categorical\"]:\n",
    "    trainValues = train.data[col].unique()\n",
    "    validValues = valid.data[col].unique()\n",
    "\n",
    "    trainDiff = set(trainValues) - set(validValues)\n",
    "    validDiff = set(validValues) - set(trainValues)\n",
    "\n",
    "    if len(trainDiff) > 0 or len(validDiff) > 0:\n",
    "        print(\"\\n\\n*** \" + col)\n",
    "        print(\"Value present in training data, not in validation data\")\n",
    "        print(trainDiff)\n",
    "        print(\"Value present in validation data, not in training data\")\n",
    "        print(validDiff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Encode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id = 'Encode'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Encode training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:46:50.415036Z",
     "start_time": "2019-07-20T04:46:50.214068Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ordinal column encoding instructions\n",
    "ordinalEncodings = {\n",
    "    \"Street\": {\"Grvl\": 0, \"Pave\": 1},\n",
    "    \"Alley\": {\"Nonexistent\": 0, \"Grvl\": 1, \"Pave\": 2},\n",
    "    \"LotShape\": {\"IR3\": 0, \"IR2\": 1, \"IR1\": 2, \"Reg\": 3},\n",
    "    \"Utilities\": {\"ELO\": 0, \"NoSeWa\": 1, \"NoSewr\": 2, \"AllPub\": 3},\n",
    "    \"LotConfig\": {\"FR3\": 0, \"FR2\": 1, \"Corner\": 2, \"Inside\": 3, \"CulDSac\": 4},\n",
    "    \"LandSlope\": {\"Sev\": 0, \"Mod\": 1, \"Gtl\": 2},\n",
    "    \"ExterQual\": {\"Po\": 0, \"Fa\": 1, \"TA\": 2, \"Gd\": 3, \"Ex\": 4},\n",
    "    \"ExterCond\": {\"Po\": 0, \"Fa\": 1, \"TA\": 2, \"Gd\": 3, \"Ex\": 4},\n",
    "    \"BsmtQual\": {\"Nonexistent\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n",
    "    \"BsmtCond\": {\"Nonexistent\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n",
    "    \"BsmtExposure\": {\"Nonexistent\": 0, \"No\": 1, \"Mn\": 2, \"Av\": 3, \"Gd\": 4},\n",
    "    \"BsmtFinType1\": {\n",
    "        \"Nonexistent\": 0,\n",
    "        \"Unf\": 1,\n",
    "        \"LwQ\": 2,\n",
    "        \"BLQ\": 3,\n",
    "        \"Rec\": 4,\n",
    "        \"ALQ\": 5,\n",
    "        \"GLQ\": 6,\n",
    "    },  # split?\n",
    "    \"BsmtFinType2\": {\n",
    "        \"Nonexistent\": 0,\n",
    "        \"Unf\": 1,\n",
    "        \"LwQ\": 2,\n",
    "        \"BLQ\": 3,\n",
    "        \"Rec\": 4,\n",
    "        \"ALQ\": 5,\n",
    "        \"GLQ\": 6,\n",
    "    },  # split?\n",
    "    \"HeatingQC\": {\"Po\": 0, \"Fa\": 1, \"TA\": 2, \"Gd\": 3, \"Ex\": 4},\n",
    "    \"CentralAir\": {\"N\": 0, \"Y\": 1},\n",
    "    \"Electrical\": {\"FuseP\": 0, \"FuseF\": 1, \"FuseA\": 2, \"Mix\": 3, \"SBrkr\": 4},\n",
    "    \"KitchenQual\": {\"Po\": 0, \"Fa\": 1, \"TA\": 2, \"Gd\": 3, \"Ex\": 4},\n",
    "    \"Functional\": {\n",
    "        \"Sal\": 0,\n",
    "        \"Sev\": 1,\n",
    "        \"Maj2\": 2,\n",
    "        \"Maj1\": 3,\n",
    "        \"Mod\": 4,\n",
    "        \"Min2\": 5,\n",
    "        \"Min1\": 6,\n",
    "        \"Typ\": 7,\n",
    "    },\n",
    "    \"FireplaceQu\": {\"Nonexistent\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n",
    "    \"GarageFinish\": {\"Nonexistent\": 0, \"Unf\": 1, \"RFn\": 2, \"Fin\": 3},\n",
    "    \"GarageQual\": {\"Nonexistent\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n",
    "    \"GarageCond\": {\"Nonexistent\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n",
    "    \"PavedDrive\": {\"N\": 0, \"P\": 1, \"Y\": 2},\n",
    "    \"PoolQC\": {\"Nonexistent\": 0, \"Fa\": 1, \"TA\": 2, \"Gd\": 3, \"Ex\": 4},\n",
    "}\n",
    "\n",
    "# nominal columns\n",
    "nomCatCols = [\n",
    "    \"MSSubClass\",\n",
    "    \"MSZoning\",\n",
    "    \"LandContour\",\n",
    "    \"Neighborhood\",\n",
    "    \"Condition1\",\n",
    "    \"Condition2\",\n",
    "    \"BldgType\",\n",
    "    \"HouseStyle\",\n",
    "    \"RoofStyle\",\n",
    "    \"RoofMatl\",\n",
    "    \"Exterior1st\",\n",
    "    \"Exterior2nd\",\n",
    "    \"MasVnrType\",\n",
    "    \"Foundation\",\n",
    "    \"Heating\",\n",
    "    \"GarageType\",\n",
    "    \"Fence\",\n",
    "    \"SaleType\",\n",
    "    \"SaleCondition\",\n",
    "    \"MiscFeature\",\n",
    "]\n",
    "\n",
    "# apply encodings to training data\n",
    "trainPipe = pipeline.Pipeline(\n",
    "    [\n",
    "        (\"encodeOrdinal\", train.CustomOrdinalEncoder(encodings=ordinalEncodings)),\n",
    "        (\"dummyNominal\", train.Dummies(cols=nomCatCols, dropFirst=False)),\n",
    "    ]\n",
    ")\n",
    "train.data = trainPipe.transform(train.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Encode validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:46:50.612824Z",
     "start_time": "2019-07-20T04:46:50.423362Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# apply encodings to validation data\n",
    "validPipe = pipeline.Pipeline(\n",
    "    [\n",
    "        (\"encodeOrdinal\", valid.CustomOrdinalEncoder(encodings=ordinalEncodings)),\n",
    "        (\"dummyNominal\", valid.Dummies(cols=nomCatCols, dropFirst=False)),\n",
    "        (\"levels\", valid.MissingDummies(trainCols=train.data.columns)),\n",
    "    ]\n",
    ")\n",
    "valid.data = validPipe.transform(valid.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id = 'Transformation'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Evaluate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id = 'Evaluate4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Training feature transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:46:50.927623Z",
     "start_time": "2019-07-20T04:46:50.622845Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate skew of continuous features - validation data\n",
    "train.skewSummary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Validation feature transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:46:51.142315Z",
     "start_time": "2019-07-20T04:46:50.935765Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate skew of continuous features - training data\n",
    "valid.skewSummary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Transform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id = 'Transform'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Transform training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:46:51.809101Z",
     "start_time": "2019-07-20T04:46:51.146403Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# skew correct in training dataset, which also learns te best lambda value for each columns\n",
    "trainPipe = pipeline.Pipeline([\n",
    "        (\"skew\",train.SkewTransform(cols=train.featureByDtype_[\"continuous\"], skewMin=0.75, pctZeroMax=1.0, verbose = True))\n",
    "    ])\n",
    "train.data = trainPipe.transform(train.data)\n",
    "train.skewSummary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Transform validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:46:52.200949Z",
     "start_time": "2019-07-20T04:46:51.815040Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# skew correction in validation dataset using lambdas learned on training data\n",
    "validPipe = pipeline.Pipeline([\n",
    "        (\"skew\",valid.SkewTransform(train=False, trainValue=trainPipe.named_steps[\"skew\"].trainValue_))\n",
    "    ])\n",
    "valid.data = validPipe.transform(valid.data)\n",
    "valid.skewSummary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Outliers (final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id = 'Outliers-final'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id = 'Evaluate5'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:46:52.319612Z",
     "start_time": "2019-07-20T04:46:52.203155Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# identify outliers using IQR\n",
    "trainPipe = pipeline.Pipeline([\n",
    "    (\"outlier\",train.OutlierIQR(\n",
    "                outlierCount=20,\n",
    "                iqrStep=1.5,\n",
    "                features=train.data.columns,\n",
    "                dropOutliers=False,))\n",
    "    ])\n",
    "train.data = trainPipe.transform(train.data)\n",
    "\n",
    "# capture outliers\n",
    "iqrOutliers = np.array(sorted(trainPipe.named_steps[\"outlier\"].outliers_))\n",
    "print(iqrOutliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:46:52.763195Z",
     "start_time": "2019-07-20T04:46:52.322439Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# identify outliers using Isolation Forest\n",
    "clf = ensemble.IsolationForest(\n",
    "    behaviour=\"new\", max_samples=train.data.shape[0], random_state=0, contamination=0.02\n",
    ")\n",
    "clf.fit(train.data[train.data.columns])\n",
    "preds = clf.predict(train.data[train.data.columns])\n",
    "# np.unique(preds, return_counts = True)\n",
    "\n",
    "# evaluate index values\n",
    "mask = np.isin(preds, -1)  # np.in1d if np.isin is not available\n",
    "ifOutliers = np.array(train.data[mask].index)\n",
    "print(ifOutliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:47:02.233485Z",
     "start_time": "2019-07-20T04:46:52.767126Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# identify outliers using extended isolation forest\n",
    "trainPipe = pipeline.Pipeline([\n",
    "    (\"outlier\",train.ExtendedIsoForest(\n",
    "                cols=train.data.select_dtypes(exclude=['object']).columns,\n",
    "                nTrees=100,\n",
    "                sampleSize=100,\n",
    "                ExtensionLevel=1,\n",
    "                anomaliesRatio=0.009,\n",
    "                dropOutliers=False,))\n",
    "    ])\n",
    "train.data = trainPipe.transform(train.data)\n",
    "\n",
    "# capture outliers\n",
    "eifOutliers = np.array(sorted(trainPipe.named_steps[\"outlier\"].outliers_))\n",
    "print(eifOutliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:47:02.248576Z",
     "start_time": "2019-07-20T04:47:02.238402Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# identify outliers that are identified in multiple algorithms\n",
    "# reduce(np.intersect1d, (iqrOutliers, ifOutliers, eifOutliers))\n",
    "reduce(np.intersect1d, (ifOutliers, eifOutliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# review outlier identification summary\n",
    "outlierSummary = train.outlierSummary(iqrOutliers=iqrOutliers,\n",
    "                                      ifOutliers=ifOutliers,\n",
    "                                      eifOutliers=eifOutliers)\n",
    "outlierSummary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Remove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id = 'remove1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # remove outlers from predictors and response\n",
    "# outliers = np.array([59,121])\n",
    "# train.data = train.data.drop(outliers)\n",
    "# train.target = train.target.drop(index=outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id = 'Data evaluation'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id = 'Feature-importance'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:47:02.414899Z",
     "start_time": "2019-07-20T04:47:02.251981Z"
    },
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# feature importance summary table\n",
    "featureImp = train.featureImportanceSummary()\n",
    "featureImp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Rationality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id = 'Rationality'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:47:08.943153Z",
     "start_time": "2019-07-20T04:47:02.418157Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# percent difference summary\n",
    "dfDiff = abs(\n",
    "    (\n",
    "        ((valid.data.describe() + 1) - (train.data.describe() + 1))\n",
    "        / (train.data.describe() + 1)\n",
    "    )\n",
    "    * 100\n",
    ")\n",
    "dfDiff = dfDiff[dfDiff.columns].replace({0: np.nan})\n",
    "dfDiff[dfDiff < 0] = np.nan\n",
    "dfDiff = dfDiff.fillna(\"\")\n",
    "display(dfDiff)\n",
    "display(train.data[dfDiff.columns].describe())\n",
    "display(valid.data[dfDiff.columns].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Value override"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id = 'Value override'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:47:08.980776Z",
     "start_time": "2019-07-20T04:47:08.946882Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# change clearly erroneous value to what it probably was\n",
    "valid.data[\"GarageYrBlt\"].replace({2207: 2007}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id = 'Correlation3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:47:10.008111Z",
     "start_time": "2019-07-20T04:47:08.983376Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# correlation heat map with most highly correlated features relative to the target\n",
    "p = PrettierPlot(chartProp=15)\n",
    "ax = p.makeCanvas()\n",
    "p.prettyCorrHeatmapTarget(df=train.data, target=train.target, thresh=0.6, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Remarks - There are three pairs of highly correlated features:\n",
    "    - 'GarageArea' and 'GarageCars'\n",
    "    - 'TotRmsAbvGrd' and 'GrLivArea'\n",
    "    - '1stFlrSF' and 'TotalBsmtSF\n",
    "This makes sense, given what each feature represents and how each pair items relate to each other. We likely only need one feature from each pair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Modeling'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Data-preparation-1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T20:13:01.084913Z",
     "start_time": "2019-07-20T20:13:00.110370Z"
    },
    "code_folding": [
     20,
     73,
     103
    ]
   },
   "outputs": [],
   "source": [
    "# import training data\n",
    "dfTrain = pd.read_csv(\"../../data/kaggleHousingPrices/train.csv\")\n",
    "train = mlm.Machine(\n",
    "    data=dfTrain,\n",
    "    target=[\"SalePrice\"],\n",
    "    removeFeatures=[\"Id\", \"MiscVal\"],\n",
    "    overrideCat=[\n",
    "        \"MSSubClass\",\n",
    "        \"OverallQual\",\n",
    "        \"OverallCond\",\n",
    "        \"YearBuilt\",\n",
    "        \"YearRemodAdd\",\n",
    "        \"MoSold\",\n",
    "        \"YrSold\",\n",
    "    ],\n",
    "    targetType=\"continuous\",\n",
    ")\n",
    "\n",
    "### training data transformation pipeline\n",
    "### ordinal columns\n",
    "ordinalEncodings = {\n",
    "    \"Street\": {\"Grvl\": 0, \"Pave\": 1},\n",
    "    \"Alley\": {\"Nonexistent\": 0, \"Grvl\": 1, \"Pave\": 2},\n",
    "    \"LotShape\": {\"IR3\": 0, \"IR2\": 1, \"IR1\": 2, \"Reg\": 3},\n",
    "    \"Utilities\": {\"ELO\": 0, \"NoSeWa\": 1, \"NoSewr\": 2, \"AllPub\": 3},\n",
    "    \"LotConfig\": {\"FR3\": 0, \"FR2\": 1, \"Corner\": 2, \"Inside\": 3, \"CulDSac\": 4},\n",
    "    \"LandSlope\": {\"Sev\": 0, \"Mod\": 1, \"Gtl\": 2},\n",
    "    \"ExterQual\": {\"Po\": 0, \"Fa\": 1, \"TA\": 2, \"Gd\": 3, \"Ex\": 4},\n",
    "    \"ExterCond\": {\"Po\": 0, \"Fa\": 1, \"TA\": 2, \"Gd\": 3, \"Ex\": 4},\n",
    "    \"BsmtQual\": {\"Nonexistent\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n",
    "    \"BsmtCond\": {\"Nonexistent\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n",
    "    \"BsmtExposure\": {\"Nonexistent\": 0, \"No\": 1, \"Mn\": 2, \"Av\": 3, \"Gd\": 4},\n",
    "    \"BsmtFinType1\": {\n",
    "        \"Nonexistent\": 0,\n",
    "        \"Unf\": 1,\n",
    "        \"LwQ\": 2,\n",
    "        \"BLQ\": 3,\n",
    "        \"Rec\": 4,\n",
    "        \"ALQ\": 5,\n",
    "        \"GLQ\": 6,\n",
    "    },  # split?\n",
    "    \"BsmtFinType2\": {\n",
    "        \"Nonexistent\": 0,\n",
    "        \"Unf\": 1,\n",
    "        \"LwQ\": 2,\n",
    "        \"BLQ\": 3,\n",
    "        \"Rec\": 4,\n",
    "        \"ALQ\": 5,\n",
    "        \"GLQ\": 6,\n",
    "    },  # split?\n",
    "    \"HeatingQC\": {\"Po\": 0, \"Fa\": 1, \"TA\": 2, \"Gd\": 3, \"Ex\": 4},\n",
    "    \"CentralAir\": {\"N\": 0, \"Y\": 1},\n",
    "    \"Electrical\": {\"FuseP\": 0, \"FuseF\": 1, \"FuseA\": 2, \"Mix\": 3, \"SBrkr\": 4},\n",
    "    \"KitchenQual\": {\"Po\": 0, \"Fa\": 1, \"TA\": 2, \"Gd\": 3, \"Ex\": 4},\n",
    "    \"Functional\": {\n",
    "        \"Sal\": 0,\n",
    "        \"Sev\": 1,\n",
    "        \"Maj2\": 2,\n",
    "        \"Maj1\": 3,\n",
    "        \"Mod\": 4,\n",
    "        \"Min2\": 5,\n",
    "        \"Min1\": 6,\n",
    "        \"Typ\": 7,\n",
    "    },\n",
    "    \"FireplaceQu\": {\"Nonexistent\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n",
    "    \"GarageFinish\": {\"Nonexistent\": 0, \"Unf\": 1, \"RFn\": 2, \"Fin\": 3},\n",
    "    \"GarageQual\": {\"Nonexistent\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n",
    "    \"GarageCond\": {\"Nonexistent\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n",
    "    \"PavedDrive\": {\"N\": 0, \"P\": 1, \"Y\": 2},\n",
    "    \"PoolQC\": {\"Nonexistent\": 0, \"Fa\": 1, \"TA\": 2, \"Gd\": 3, \"Ex\": 4},\n",
    "}\n",
    "\n",
    "### nominal columns\n",
    "nomCatCols = [\n",
    "    \"MSSubClass\",\n",
    "    \"MSZoning\",\n",
    "    \"LandContour\",\n",
    "    \"Neighborhood\",\n",
    "    \"Condition1\",\n",
    "    \"Condition2\",\n",
    "    \"BldgType\",\n",
    "    \"HouseStyle\",\n",
    "    \"RoofStyle\",\n",
    "    \"RoofMatl\",\n",
    "    \"Exterior1st\",\n",
    "    \"Exterior2nd\",\n",
    "    \"MasVnrType\",\n",
    "    \"Foundation\",\n",
    "    \"Heating\",\n",
    "    \"GarageType\",\n",
    "    \"Fence\",\n",
    "    \"SaleType\",\n",
    "    \"SaleCondition\",\n",
    "    \"MiscFeature\",\n",
    "]\n",
    "\n",
    "### additional features\n",
    "train.data[\"BsmtFinSF\"] = train.data[\"BsmtFinSF1\"] + train.data[\"BsmtFinSF2\"]\n",
    "train.data[\"TotalSF\"] = (\n",
    "    train.data[\"TotalBsmtSF\"] + train.data[\"1stFlrSF\"] + train.data[\"2ndFlrSF\"]\n",
    ")\n",
    "\n",
    "### observation removal\n",
    "outliers = [\n",
    "    53,\n",
    "    185,\n",
    "    197,\n",
    "    437,\n",
    "    492,\n",
    "    762,\n",
    "    796,\n",
    "    821,\n",
    "    847,\n",
    "    1161,\n",
    "    1221,\n",
    "    1318,\n",
    "    1376,\n",
    "    249,\n",
    "    313,\n",
    "    335,\n",
    "    451,\n",
    "    523,\n",
    "    691,\n",
    "    706,\n",
    "    934,\n",
    "    1182,\n",
    "    1298,\n",
    "]\n",
    "train.data = train.data.drop(outliers)\n",
    "train.target = train.target.drop(index=outliers)\n",
    "\n",
    "### pre-processing pipeline\n",
    "trainPipe = pipeline.Pipeline([\n",
    "        (\"imputeConstantCat\",train.ConstantImputer(cols=[\"PoolQC\",\"Alley\",\"Fence\",\"FireplaceQu\",\"GarageType\",\"GarageFinish\",\"GarageQual\",\"MiscFeature\",\"GarageCond\",\"BsmtQual\",\n",
    "                    \"BsmtCond\",\"BsmtExposure\",\"BsmtFinType1\",\"BsmtFinType2\",\"MasVnrType\",],fill=\"Nonexistent\")),\n",
    "        (\"imputeConstantNum\",train.ConstantImputer(cols=[\"GarageYrBlt\", \"MasVnrArea\"], fill=0)),\n",
    "        (\"imputeMode\", train.ModeImputer(cols=[\"Electrical\"])),\n",
    "        (\"imputeContext\", train.ContextImputer(nullCol=\"LotFrontage\", contextCol=\"Neighborhood\", strategy=\"most_frequent\")),\n",
    "        (\"encodeOrdinal\", train.CustomOrdinalEncoder(encodings=ordinalEncodings)),\n",
    "        (\"dummyNominal\", train.Dummies(cols=nomCatCols, dropFirst=True)),\n",
    "        (\"skew\", train.SkewTransform(cols=train.featureByDtype_[\"continuous\"], skewMin=0.05, pctZeroMax=1.0)),\n",
    "        (\"scale\", train.Robust(cols=\"non-binary\")),\n",
    "    ])\n",
    "train.data = trainPipe.transform(train.data)\n",
    "\n",
    "train.target = np.log1p(train.target)\n",
    "print('completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T20:13:05.932996Z",
     "start_time": "2019-07-20T20:13:05.335832Z"
    }
   },
   "outputs": [],
   "source": [
    "# import valid data\n",
    "dfValid = pd.read_csv(\"../../data/kaggleHousingPrices/test.csv\")\n",
    "valid = mlm.Machine(\n",
    "    data=dfValid,\n",
    "    removeFeatures=[\"Id\", \"MiscVal\"],\n",
    "    overrideCat=[\n",
    "        \"MSSubClass\",\n",
    "        \"OverallQual\",\n",
    "        \"OverallCond\",\n",
    "        \"YearBuilt\",\n",
    "        \"YearRemodAdd\",\n",
    "        \"MoSold\",\n",
    "        \"YrSold\",\n",
    "    ],\n",
    "    targetType=\"continuous\",\n",
    ")\n",
    "\n",
    "### additional features\n",
    "valid.data[\"BsmtFinSF\"] = valid.data[\"BsmtFinSF1\"] + valid.data[\"BsmtFinSF2\"]\n",
    "valid.data[\"TotalSF\"] = (\n",
    "    valid.data[\"TotalBsmtSF\"] + valid.data[\"1stFlrSF\"] + valid.data[\"2ndFlrSF\"]\n",
    ")\n",
    "valid.data.loc[valid.data[\"TotalSF\"].isnull(), \"TotalSF\"] = (\n",
    "    valid.data[\"1stFlrSF\"] + valid.data[\"2ndFlrSF\"]\n",
    ")\n",
    "\n",
    "### pre-processing pipeline\n",
    "validPipe = pipeline.Pipeline([\n",
    "        (\"imputeConstantCat\",valid.ConstantImputer(cols=[\"PoolQC\",\"Alley\",\"Fence\",\"FireplaceQu\",\"GarageType\",\"GarageFinish\",\"GarageQual\",\"MiscFeature\",\"GarageCond\",\n",
    "                    \"BsmtQual\",\"BsmtCond\",\"BsmtExposure\",\"BsmtFinType1\",\"BsmtFinType2\",\"MasVnrType\",],fill=\"Nonexistent\")),\n",
    "        (\"imputeConstantNum\",valid.ConstantImputer(cols=[\"GarageYrBlt\",\"MasVnrArea\",\"BsmtUnfSF\",\"GarageArea\",\"BsmtFinSF1\",\"TotalBsmtSF\",\"BsmtFinSF2\",],fill=0)),\n",
    "        (\"imputeModeCat\",valid.ModeImputer(cols=[\"Functional\",\"SaleType\",\"Exterior1st\",\"MSZoning\",\"Exterior2nd\",\"KitchenQual\",\"Utilities\"],train=False,\n",
    "                                          trainValue=train.data.merge(trainPipe.named_steps[\"dummyNominal\"].originalCols_, right_index = True, left_index = True))),\n",
    "        (\"imputeModeNum\",valid.NumericalImputer(cols=[\"BsmtHalfBath\", \"GarageCars\", \"BsmtFullBath\"],strategy=\"most_frequent\")),\n",
    "        (\"imputeContext\",valid.ContextImputer(nullCol=\"LotFrontage\",contextCol=\"Neighborhood\",train=False,trainValue=trainPipe.named_steps[\"imputeContext\"].trainValue_)),\n",
    "        (\"encodeOrdinal\", valid.CustomOrdinalEncoder(encodings=ordinalEncodings)),\n",
    "        (\"dummyNominal\", valid.Dummies(cols=nomCatCols, dropFirst=True)),\n",
    "        (\"skew\",valid.SkewTransform(cols=valid.featureByDtype_[\"continuous\"],train=False,trainValue=trainPipe.named_steps[\"skew\"].trainValue_)),\n",
    "        (\"scale\",valid.Robust(cols=\"non-binary\",train=False,trainValue=trainPipe.named_steps[\"scale\"].trainValue_)),\n",
    "        (\"levels\", valid.MissingDummies(trainCols=train.data.columns)),\n",
    "    ])\n",
    "valid.data = validPipe.transform(valid.data)\n",
    "print('completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian hyper-parameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Bayesian-hyper-parameter-optimization'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T20:13:11.439851Z",
     "start_time": "2019-07-20T20:13:11.359222Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# model/parameter space\n",
    "allSpace = {\n",
    "    \"linear_model.Lasso\": {\"alpha\": hp.uniform(\"alpha\", 0.0000001, 20)},\n",
    "    \"linear_model.Ridge\": {\"alpha\": hp.uniform(\"alpha\", 0.0000001, 20)},\n",
    "    \"linear_model.ElasticNet\": {\n",
    "        \"alpha\": hp.uniform(\"alpha\", 0.0000001, 20),\n",
    "        \"l1_ratio\": hp.uniform(\"l1_ratio\", 0.0, 0.2),\n",
    "    },\n",
    "    \"kernel_ridge.KernelRidge\": {\n",
    "        \"alpha\": hp.uniform(\"alpha\", 0.000001, 15),\n",
    "        \"kernel\": hp.choice(\"kernel\", [\"linear\", \"polynomial\", \"rbf\"]),\n",
    "        \"degree\": hp.choice(\"degree\", [2, 3]),\n",
    "        \"gamma\": hp.uniform(\"gamma\", 0.0, 10),\n",
    "    },\n",
    "    \"lightgbm.LGBMRegressor\": {\n",
    "        \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"boosting_type\": hp.choice(\"boosting_type\", [\"gbdt\", \"dart\", \"goss\"])\n",
    "        # ,'boosting_type': hp.choice('boosting_type'\n",
    "        #                    ,[{'boosting_type': 'gbdt', 'subsample': hp.uniform('gdbt_subsample', 0.5, 1)}\n",
    "        #                    ,{'boosting_type': 'dart', 'subsample': hp.uniform('dart_subsample', 0.5, 1)}\n",
    "        #                    ,{'boosting_type': 'goss', 'subsample': 1.0}])\n",
    "        ,\n",
    "        \"learning_rate\": hp.uniform(\"learning_rate\", 0.000001, 0.2),\n",
    "        \"max_depth\": hp.choice(\"max_depth\", np.arange(2, 20, dtype=int)),\n",
    "        \"min_child_samples\": hp.uniform(\"min_child_samples\", 20, 500),\n",
    "        \"n_estimators\": hp.choice(\"n_estimators\", np.arange(100, 10000, 10, dtype=int)),\n",
    "        \"num_leaves\": hp.uniform(\"num_leaves\", 8, 150),\n",
    "        \"reg_alpha\": hp.uniform(\"reg_alpha\", 0.0, 1.0),\n",
    "        \"reg_lambda\": hp.uniform(\"reg_lambda\", 0.0, 1.0),\n",
    "        \"subsample_for_bin\": hp.uniform(\"subsample_for_bin\", 20000, 400000),\n",
    "    },\n",
    "    \"xgboost.XGBRegressor\": {\n",
    "        \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"gamma\": hp.uniform(\"gamma\", 0.0, 10),\n",
    "        \"reg_alpha\": hp.uniform(\"reg_alpha\", 0.0, 1.0),\n",
    "        \"reg_lambda\": hp.uniform(\"reg_lambda\", 0.0, 1.0),\n",
    "        \"learning_rate\": hp.uniform(\"learning_rate\", 0.000001, 0.2),\n",
    "        \"max_depth\": hp.choice(\"max_depth\", np.arange(2, 20, dtype=int)),\n",
    "        \"min_child_weight\": hp.uniform(\"min_child_weight\", 1, 20),\n",
    "        \"n_estimators\": hp.choice(\"n_estimators\", np.arange(100, 10000, 10, dtype=int)),\n",
    "        \"subsample\": hp.uniform(\"subsample\", 0.5, 1),\n",
    "    },\n",
    "    \"ensemble.RandomForestRegressor\": {\n",
    "        \"bootstrap\": hp.choice(\"bootstrap\", [True, False]),\n",
    "        \"max_depth\": hp.choice(\"max_depth\", np.arange(2, 20, dtype=int)),\n",
    "        \"n_estimators\": hp.choice(\"n_estimators\", np.arange(100, 10000, 10, dtype=int)),\n",
    "        \"max_features\": hp.choice(\"max_features\", [\"auto\", \"sqrt\"]),\n",
    "        \"min_samples_split\": hp.choice(\n",
    "            \"min_samples_split\", np.arange(2, 40, dtype=int)\n",
    "        ),\n",
    "        \"min_samples_leaf\": hp.choice(\"min_samples_leaf\", np.arange(2, 40, dtype=int)),\n",
    "    },\n",
    "    \"ensemble.GradientBoostingRegressor\": {\n",
    "        \"n_estimators\": hp.choice(\"n_estimators\", np.arange(100, 10000, 10, dtype=int)),\n",
    "        \"max_depth\": hp.choice(\"max_depth\", np.arange(2, 20, dtype=int)),\n",
    "        \"max_features\": hp.choice(\"max_features\", [\"auto\", \"sqrt\"]),\n",
    "        \"learning_rate\": hp.uniform(\"learning_rate\", 0.000001, 0.2),\n",
    "        \"loss\": hp.choice(\"loss\", [\"ls\", \"lad\", \"huber\", \"quantile\"]),\n",
    "        \"min_samples_split\": hp.choice(\n",
    "            \"min_samples_split\", np.arange(2, 40, dtype=int)\n",
    "        ),\n",
    "        \"min_samples_leaf\": hp.choice(\"min_samples_leaf\", np.arange(2, 40, dtype=int)),\n",
    "    },\n",
    "    \"ensemble.AdaBoostRegressor\": {\n",
    "        \"n_estimators\": hp.choice(\"n_estimators\", np.arange(100, 10000, 10, dtype=int)),\n",
    "        \"learning_rate\": hp.uniform(\"learning_rate\", 0.000001, 0.2),\n",
    "        \"loss\": hp.choice(\"loss\", [\"linear\", \"square\", \"exponential\"]),\n",
    "    },\n",
    "    \"ensemble.ExtraTreesRegressor\": {\n",
    "        \"n_estimators\": hp.choice(\"n_estimators\", np.arange(100, 10000, 10, dtype=int)),\n",
    "        \"max_depth\": hp.choice(\"max_depth\", np.arange(2, 20, dtype=int)),\n",
    "        \"min_samples_split\": hp.choice(\n",
    "            \"min_samples_split\", np.arange(2, 40, dtype=int)\n",
    "        ),\n",
    "        \"min_samples_leaf\": hp.choice(\"min_samples_leaf\", np.arange(2, 40, dtype=int)),\n",
    "        \"max_features\": hp.choice(\"max_features\", [\"auto\", \"sqrt\"]),\n",
    "    },\n",
    "    \"svm.SVR\": {\n",
    "        \"C\": hp.uniform(\"C\", 0.00001, 10),\n",
    "        \"kernel\": hp.choice(\"kernel\", [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]),\n",
    "        \"degree\": hp.choice(\"degree\", [2, 3]),\n",
    "        \"gamma\": hp.uniform(\"gamma\", 0.0001, 10),\n",
    "        \"epsilon\": hp.uniform(\"epsilon\", 0.001, 5),\n",
    "    },\n",
    "    \"neighbors.KNeighborsRegressor\": {\n",
    "        \"algorithm\": hp.choice(\"algorithm\", [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"]),\n",
    "        \"n_neighbors\": hp.choice(\"n_neighbors\", np.arange(1, 20, dtype=int)),\n",
    "        \"weights\": hp.choice(\"weights\", [\"distance\", \"uniform\"]),\n",
    "        \"p\": hp.choice(\"p\", [1, 2]),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T20:08:06.345694Z",
     "start_time": "2019-07-20T20:08:02.750572Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# execute bayesian optimization grid search\n",
    "analysis = \"housing\"\n",
    "train.execBayesOptimSearch(\n",
    "    allSpace=allSpace,\n",
    "    resultsDir=\"{}_hyperopt_{}.csv\".format(rundate, analysis),\n",
    "    X=train.data,\n",
    "    y=train.target,\n",
    "    scoring=\"rmsle\",\n",
    "    nFolds=2,\n",
    "    nJobs=4,\n",
    "    iters=8,\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model loss by iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Model-loss-by-iteration'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T20:13:21.836103Z",
     "start_time": "2019-07-20T20:13:20.943293Z"
    }
   },
   "outputs": [],
   "source": [
    "# read scores summary table\n",
    "analysis = 'housing'\n",
    "# rundate='20190730'\n",
    "bayesOptimSummary = pd.read_csv(\"{}_hyperopt_{}.csv\".format(rundate, analysis), na_values=\"nan\")\n",
    "bayesOptimSummary[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T20:13:32.856001Z",
     "start_time": "2019-07-20T20:13:24.355066Z"
    }
   },
   "outputs": [],
   "source": [
    "# model loss plot\n",
    "for estimator in np.unique(bayesOptimSummary[\"estimator\"]):\n",
    "    train.modelLossPlot(bayesOptimSummary=bayesOptimSummary, estimator=estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter selection by iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Parameter-selection-by-iteration'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T20:28:02.854397Z",
     "start_time": "2019-07-20T20:15:33.532394Z"
    }
   },
   "outputs": [],
   "source": [
    "# estimator parameter plots\n",
    "for estimator in np.unique(bayesOptimSummary['estimator']):\n",
    "    train.modelParamPlot(bayesOptimSummary = bayesOptimSummary,\n",
    "                         estimator=estimator,\n",
    "                         allSpace=allSpace,\n",
    "                         nIter=100,\n",
    "                         chartProp=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Model performance evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id = 'Model-performance-evaluation'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create model with full set of predictor variables\n",
    "linReg = linear_model.LinearRegression()\n",
    "linReg.fit(XTrain, yTrain)\n",
    "yPredsTrain = linReg.predict(XTrain)\n",
    "yPredsTest = linReg.predict(XTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# repeat value 1 X times (len of train then test array)\n",
    "yActual = np.vstack((yTrain, yTest))\n",
    "yPreds = np.vstack((yPredsTrain, yPredsTest))\n",
    "yType = np.hstack((np.repeat(0, yTrain.shape[0]), np.repeat(1, yTest.shape[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Residual plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a id = 'Residual-plots'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# visualize predictions using residual plot\n",
    "p = PrettierPlot()\n",
    "ax = p.makeCanvas(title=\"\", xLabel=\"Predicted values\", yLabel=\"Residuals\", yShift=0.8)\n",
    "p.pretty2dScatterHue(\n",
    "    x=yPreds,\n",
    "    y=yPreds - yActual,\n",
    "    target=yType,\n",
    "    label=[\"Training\", \"Test\"],\n",
    "    xUnits=\"f\",\n",
    "    yUnits=\"f\",\n",
    "    bbox=(1.2, 0.9),\n",
    "    ax=ax,\n",
    ")\n",
    "plt.hlines(y=0, xmin=-10, xmax=50, color=\"black\", lw=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model explanability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Feature-importance'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesOptimSummary[bayesOptimSummary['estimator'] == 'lightgbm.LGBMRegressor'].sort_values(['meanLoss'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topModels = train.topBayesOptimModels(bayesOptimSummary=bayesOptimSummary, numModels=1)\n",
    "topModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = \"ensemble.AdaBoostClassifier\"\n",
    "modelIter = 467\n",
    "\n",
    "modelA = train.BayesOptimModelBuilder(\n",
    "    bayesOptimSummary=bayesOptimSummary, estimator=estimator, modelIter=modelIter\n",
    ")\n",
    "\n",
    "modelA.fit(train.data.values, train.target.values)\n",
    "featureNames = train.data.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Permutation-importance'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# permutation importance - how much does performance decrease when shuffling a certain feature?\n",
    "perm = PermutationImportance(modelR.model, random_state=1).fit(train.data, train.target)\n",
    "eli5.show_weights(perm, feature_names=featureNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Partial-plots'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in featureNames:\n",
    "    pdpFeature = pdp.pdp_isolate(\n",
    "        model=modelR.model, dataset=train.data, model_features=featureNames, feature=feature\n",
    "    )\n",
    "\n",
    "    pdp.pdp_plot(pdpFeature, feature)\n",
    "    plt.rcParams[\"axes.facecolor\"] = \"white\"\n",
    "    plt.rcParams[\"figure.facecolor\"] = \"white\"\n",
    "\n",
    "    plt.grid(b=None)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'SHAP-values'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Force plots - single observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(0, 4):\n",
    "    train.singleShapVizTree(obsIx=i, model=modelR, data=train.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Force plots - multiple observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual = train.multiShapVizTree(obsIxs=np.arange(0, 800), model=modelR, data=train.data)\n",
    "visual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dependence plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsData, _, obsShapValues = train.multiShapValueTree(\n",
    "    obsIxs=np.arange(0, 800), model=modelR, data=train.data\n",
    ")\n",
    "train.shapDependencePlot(\n",
    "    obsData=obsData,\n",
    "    obsShapValues=obsShapValues,\n",
    "    scatterFeature=\"Fare\",\n",
    "    colorFeature=\"Age\",\n",
    "    featureNames=train.data.columns.tolist(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsData, _, obsShapValues = train.multiShapValueTree(\n",
    "    obsIxs=np.arange(0, 800), model=modelR, data=train.data\n",
    ")\n",
    "featureNames = train.data.columns.tolist()\n",
    "topShap = np.argsort(-np.sum(np.abs(obsShapValues), 0))\n",
    "\n",
    "# generate force plot\n",
    "for topIx in topShap:\n",
    "    train.shapDependencePlot(\n",
    "        obsData=obsData,\n",
    "        obsShapValues=obsShapValues,\n",
    "        scatterFeature=featureNames[topIx],\n",
    "        colorFeature=\"Age\",\n",
    "        featureNames=featureNames,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summary plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsData, _, obsShapValues = train.multiShapValueTree(\n",
    "    obsIxs=np.arange(0, 800), model=modelR, data=train.data\n",
    ")\n",
    "featureNames = train.data.columns.tolist()\n",
    "train.shapSummaryPlot(\n",
    "        obsData=obsData,\n",
    "        obsShapValues=obsShapValues,\n",
    "        featureNames=featureNames,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Stacking'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primary models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Primary-models'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T14:05:17.965746Z",
     "start_time": "2019-03-24T14:05:17.669308Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T14:11:12.912222Z",
     "start_time": "2019-03-24T14:09:44.583800Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T14:11:26.441649Z",
     "start_time": "2019-03-24T14:11:26.032435Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Meta-model'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T14:16:24.776352Z",
     "start_time": "2019-03-24T14:12:03.005790Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T14:16:24.983826Z",
     "start_time": "2019-03-24T14:16:24.779451Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Submission'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Standard'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T13:46:12.681655Z",
     "start_time": "2019-03-24T13:46:06.563199Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T13:46:14.138741Z",
     "start_time": "2019-03-24T13:46:14.106125Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate prediction submission file\n",
    "submit = pd.DataFrame({\"Id\": dfTest.Id, \"SalePrice\": np.expm1(yPred)})\n",
    "submit.to_csv(\"data/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Stack'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T14:17:12.332889Z",
     "start_time": "2019-03-24T14:17:11.732365Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T14:17:12.422440Z",
     "start_time": "2019-03-24T14:17:12.335453Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate prediction submission file\n",
    "submit = pd.DataFrame({\"Id\": dfTest.Id, \"SalePrice\": np.expm1(yPred)})\n",
    "submit.to_csv(\"data/submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
