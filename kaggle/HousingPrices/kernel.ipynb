{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Kaggle competition - house prices__\n",
    "\n",
    "1. [Import](#Import)\n",
    "    1. [Tools](#Tools)\n",
    "    1. [Data](#Data)    \n",
    "1. [Initial EDA](#Initial-EDA)\n",
    "    1. [Categorical feature EDA](#Categorical-feature-EDA)\n",
    "        1. [Univariate & feature vs. target](#Univariate-&-feature-vs.-target)\n",
    "    1. [Continuous feature EDA](#Continuous-feature-EDA)\n",
    "        1. [Univariate & feature vs. target](#Univariate-&-feature-vs.-target2)\n",
    "        1. [Correlation](#Correlation)\n",
    "        1. [Pair plot](#Pair-plot)\n",
    "    1. [Faceting](#Faceting)\n",
    "    1. [Target variable evaluation](#Target-variable-evaluation)    \n",
    "1. [Data preparation](#Data-preparation)\n",
    "    1. [Outliers (preliminary)](#Outliers-preliminary)\n",
    "        1. [Evaluate](#Evaluate)\n",
    "        1. [Remove](#remove)\n",
    "    1. [Missing data](#Missing-data)\n",
    "        1. [Evaluate](#Evaluate1)\n",
    "        1. [Impute](#Impute)\n",
    "    1. [Engineering](#Engineering)\n",
    "        1. [Evaluate](#Evaluate3)\n",
    "        1. [Engineer](#Engineer)\n",
    "    1. [Encoding](#Encoding)\n",
    "        1. [Evaluate](#Evaluate2)\n",
    "        1. [Encode](#Encode)\n",
    "    1. [Transformation](#Transformation)\n",
    "        1. [Evaluate](#Evaluate4)\n",
    "        1. [Transform](#Transform)\n",
    "    1. [Outliers (final)](#Outliers-final)\n",
    "        1. [Evaluate](#Evaluate5)\n",
    "        1. [Remove](#remove1)\n",
    "1. [Data evaluation](#Data-evaluation)\n",
    "    1. [Feature importance](#Feature-importance)    \n",
    "    1. [Rationality](#Rationality)\n",
    "    1. [Value override](#Value-override)\n",
    "    1. [Continuous feature EDA](#Continuous-feature-EDA3)\n",
    "    1. [Correlation](#Correlation3)\n",
    "1. [Modeling](#Modeling)\n",
    "    1. [Data preparation](#Data-preparation)\n",
    "    1. [Bayesian hyper-parameter optimization](#Bayesian-hyper-parameter-optimization)\n",
    "        1. [Model loss by iteration](#Model-loss-by-iteration)\n",
    "        1. [Parameter selection by iteration](#Parameter-selection-by-iteration)\n",
    "    1. [Model performance evaluation](#Model-performance-evaluation)\n",
    "        1. [Residual plots](#Residual-plots)\n",
    "    1. [Model explanability](#Model-explanability)\n",
    "        1. [Permutation importance](#Permutation-importance)\n",
    "        1. [Partial plots](#Partial-plots)\n",
    "        1. [SHAP values](#SHAP-values)\n",
    "    1. [Stacking](#Stacking)\n",
    "        1. [Primary models](#Primary-models)\n",
    "        1. [Meta model](#Meta-model)                \n",
    "1. [Submission](#Submission)\n",
    "    1. [Standard](#Standard)\n",
    "    1. [Stack](#Stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle competition - house prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Kaggle-competition-house-prices'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Import'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Tools'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:28:33.743863Z",
     "start_time": "2019-07-20T04:28:32.614522Z"
    }
   },
   "outputs": [],
   "source": [
    "# standard libary and settings\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import itertools\n",
    "import csv\n",
    "import ast\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "global ITERATION\n",
    "import time\n",
    "from functools import reduce\n",
    "\n",
    "rundate = time.strftime(\"%Y%m%d\")\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "# data extensions and settings\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(threshold=np.inf, suppress=True)\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.options.display.float_format = \"{:,.6f}\".format\n",
    "\n",
    "# modeling extensions\n",
    "import sklearn.base as base\n",
    "import sklearn.cluster as cluster\n",
    "import sklearn.datasets as datasets\n",
    "import sklearn.decomposition as decomposition\n",
    "import sklearn.discriminant_analysis as discriminant_analysis\n",
    "import sklearn.ensemble as ensemble\n",
    "import sklearn.feature_extraction as feature_extraction\n",
    "import sklearn.feature_selection as feature_selection\n",
    "import sklearn.gaussian_process as gaussian_process\n",
    "import sklearn.linear_model as linear_model\n",
    "import sklearn.kernel_ridge as kernel_ridge\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.model_selection as model_selection\n",
    "import sklearn.naive_bayes as naive_bayes\n",
    "import sklearn.neighbors as neighbors\n",
    "import sklearn.pipeline as pipeline\n",
    "import sklearn.preprocessing as preprocessing\n",
    "import sklearn.svm as svm\n",
    "import sklearn.tree as tree\n",
    "import sklearn.utils as utils\n",
    "\n",
    "import eif\n",
    "\n",
    "from scipy import stats, special\n",
    "import xgboost\n",
    "import lightgbm\n",
    "import catboost\n",
    "\n",
    "from hyperopt import hp, tpe, Trials, fmin, STATUS_OK\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "\n",
    "# visualization extensions and settings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# custom extensions and settings\n",
    "sys.path.append(\"/home/mlmachine\") if \"/home/mlmachine\" not in sys.path else None\n",
    "sys.path.append(\"/home/prettierplot\") if \"/home/prettierplot\" not in sys.path else None\n",
    "\n",
    "import mlmachine as mlm\n",
    "from prettierplot.plotter import PrettierPlot\n",
    "import prettierplot.style as style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Data'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:28:33.815004Z",
     "start_time": "2019-07-20T04:28:33.746263Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load data and print dimensions\n",
    "dfTrain = pd.read_csv(\"/home/data-science-portfolio/data/kaggleHousingPrices/train.csv\")\n",
    "dfValid = pd.read_csv(\"/home/data-science-portfolio/data/kaggleHousingPrices/test.csv\")\n",
    "\n",
    "print(\"Training data dimensions: {}\".format(dfTrain.shape))\n",
    "print(\"Validation data dimensions: {}\".format(dfValid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:28:33.905275Z",
     "start_time": "2019-07-20T04:28:33.819363Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# display info and first 5 rows\n",
    "dfTrain.info()\n",
    "display(dfTrain[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:28:33.919925Z",
     "start_time": "2019-07-20T04:28:33.908398Z"
    }
   },
   "outputs": [],
   "source": [
    "# review counts of different column types\n",
    "dfTrain.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:28:33.937150Z",
     "start_time": "2019-07-20T04:28:33.922381Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load training data into mlmachine\n",
    "train = mlm.Machine(\n",
    "    data=dfTrain,\n",
    "    target=[\"SalePrice\"],\n",
    "    removeFeatures=[\"Id\"],\n",
    "    overrideCat=[\n",
    "        \"MSSubClass\",\n",
    "        \"OverallQual\",\n",
    "        \"OverallCond\",\n",
    "        \"YearBuilt\",\n",
    "        \"YearRemodAdd\",\n",
    "        \"MoSold\",\n",
    "        \"YrSold\",\n",
    "    ],\n",
    "    targetType=\"continuous\",\n",
    ")\n",
    "print(train.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:28:33.950793Z",
     "start_time": "2019-07-20T04:28:33.939615Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load training data into mlmachine\n",
    "valid = mlm.Machine(\n",
    "    data=dfValid,\n",
    "    removeFeatures=[\"Id\"],\n",
    "    overrideCat=[\n",
    "        \"MSSubClass\",\n",
    "        \"OverallQual\",\n",
    "        \"OverallCond\",\n",
    "        \"YearBuilt\",\n",
    "        \"YearRemodAdd\",\n",
    "        \"MoSold\",\n",
    "        \"YrSold\",\n",
    "    ],\n",
    ")\n",
    "print(valid.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Initial-EDA'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical feature EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Categorical-feature-EDA'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate & feature vs. target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Univariate-&-feature-vs.-target'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:29:04.031874Z",
     "start_time": "2019-07-20T04:28:33.953670Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# categorical features\n",
    "train.edaNumTargetCatFeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous feature EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Continuous-feature-EDA'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate & feature vs. target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Univariate-&-feature-vs.-target2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:29:27.132025Z",
     "start_time": "2019-07-20T04:29:04.034990Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# continuous features\n",
    "train.edaNumTargetNumFeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Correlation'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Correlation (all samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:29:28.307121Z",
     "start_time": "2019-07-20T04:29:27.134736Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# correlation heat map\n",
    "p = PrettierPlot(chartProp=25)\n",
    "ax = p.makeCanvas()\n",
    "p.prettyCorrHeatmap(df=train.data, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Correlation (top vs. target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:30:38.653815Z",
     "start_time": "2019-07-20T04:30:38.323206Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# correlation heat map with most highly correlated features relative to the target\n",
    "p = PrettierPlot(plotOrientation='tall')\n",
    "ax = p.makeCanvas()\n",
    "p.prettyCorrHeatmapTarget(df=train.data, target=train.target, thresh=0.6, annot = True, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Remarks - There are three pairs of highly correlated features:\n",
    "    - 'GarageArea' and 'GarageCars'\n",
    "    - 'TotRmsAbvGrd' and 'GrLivArea'\n",
    "    - '1stFlrSF' and 'TotalBsmtSF\n",
    "This makes sense, given what each feature represents and how each pair items relate to each other. We likely only need one feature from each pair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pair plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Pair-plot'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:12:48.194152Z",
     "start_time": "2019-07-20T04:11:46.495948Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pair plot\n",
    "p = PrettierPlot(chartProp=10)\n",
    "p.prettyPairPlot(\n",
    "    df=train.data,\n",
    "    cols=[\n",
    "        \"LotFrontage\",\n",
    "        \"LotArea\",\n",
    "        \"MasVnrArea\",\n",
    "        \"BsmtFinSF1\",\n",
    "        \"BsmtFinSF2\",\n",
    "        \"BsmtUnfSF\",\n",
    "        \"TotalBsmtSF\",\n",
    "        \"1stFlrSF\",\n",
    "        \"2ndFlrSF\",\n",
    "        \"GrLivArea\",\n",
    "        \"TotRmsAbvGrd\",\n",
    "        \"GarageYrBlt\",\n",
    "        \"GarageArea\",\n",
    "        \"WoodDeckSF\",\n",
    "        \"OpenPorchSF\",\n",
    "    ],\n",
    "    diag_kind=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faceting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Faceting'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Categorical by categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Categorical by continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target variable evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Target-variable-evaluation'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:12:48.804821Z",
     "start_time": "2019-07-20T04:12:48.196841Z"
    }
   },
   "outputs": [],
   "source": [
    "# evaluate distribution of target variable\n",
    "train.edaTransformInitial(data=train.target, name=train.target.name)\n",
    "train.edaTransformLog1(data=train.target, name=train.target.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:12:48.818925Z",
     "start_time": "2019-07-20T04:12:48.814360Z"
    }
   },
   "outputs": [],
   "source": [
    "# log + 1 transform target\n",
    "train.target = np.log1p(train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Data-preparation'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers (preliminary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Outliers-preliminary'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Evaluate'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:12:48.836781Z",
     "start_time": "2019-07-20T04:12:48.823587Z"
    }
   },
   "outputs": [],
   "source": [
    "# identify columns that have zero missing values\n",
    "nonNull = train.data.columns[train.data.isnull().sum() == 0].values.tolist()\n",
    "\n",
    "# identify intersection between non-null columns and continuous columns\n",
    "nonNullNumCol = list(set(nonNull).intersection(train.featureByDtype_[\"continuous\"]))\n",
    "print(nonNull)\n",
    "print(nonNullNumCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:12:48.920099Z",
     "start_time": "2019-07-20T04:12:48.839227Z"
    }
   },
   "outputs": [],
   "source": [
    "# identify outliers using IQR\n",
    "trainPipe = pipeline.Pipeline([\n",
    "        (\"outlier\",train.OutlierIQR(outlierCount=5, iqrStep=1.5, features=nonNullNumCol, dropOutliers=False))\n",
    "    ])\n",
    "train.data = trainPipe.transform(train.data)\n",
    "\n",
    "# capture outliers\n",
    "iqrOutliers = np.array(sorted(trainPipe.named_steps[\"outlier\"].outliers_))\n",
    "print(iqrOutliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:12:49.243785Z",
     "start_time": "2019-07-20T04:12:48.923109Z"
    }
   },
   "outputs": [],
   "source": [
    "# identify outliers using Isolation Forest\n",
    "clf = ensemble.IsolationForest(\n",
    "    behaviour=\"new\", max_samples=train.data.shape[0], random_state=0, contamination=0.02\n",
    ")\n",
    "clf.fit(train.data[nonNullNumCol])\n",
    "preds = clf.predict(train.data[nonNullNumCol])\n",
    "\n",
    "# evaluate index values\n",
    "mask = np.isin(preds, -1)\n",
    "ifOutliers = np.where(mask)\n",
    "print(ifOutliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:12:54.602619Z",
     "start_time": "2019-07-20T04:12:49.246485Z"
    }
   },
   "outputs": [],
   "source": [
    "# identify outliers using extended isolation forest\n",
    "trainPipe = pipeline.Pipeline([\n",
    "    (\"outlier\",train.ExtendedIsoForest(\n",
    "                cols=nonNullNumCol,\n",
    "                nTrees=100,\n",
    "                sampleSize=256,\n",
    "                ExtensionLevel=1,\n",
    "                anomaliesRatio=0.009,\n",
    "                dropOutliers=False,))\n",
    "    ])\n",
    "train.data = trainPipe.transform(train.data)\n",
    "\n",
    "# capture outliers\n",
    "eifOutliers = np.array(sorted(trainPipe.named_steps[\"outlier\"].outliers_))\n",
    "print(eifOutliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:13:00.446691Z",
     "start_time": "2019-07-20T04:12:54.605373Z"
    }
   },
   "outputs": [],
   "source": [
    "# identify outliers using Extended Isolation Forest\n",
    "if_eif = eif.iForest(\n",
    "    train.data[nonNullNumCol].values, ntrees=100, sample_size=256, ExtensionLevel=1\n",
    ")\n",
    "\n",
    "# calculate anomaly scores\n",
    "anomalies_ratio = 0.009\n",
    "anomaly_scores = if_eif.compute_paths(X_in=train.data[nonNullNumCol].values)\n",
    "anomaly_scores_sorted = np.argsort(anomaly_scores)\n",
    "eifOutliers = anomaly_scores_sorted[\n",
    "    -int(np.ceil(anomalies_ratio * train.data.shape[0])) :\n",
    "]\n",
    "print(sorted(eifOutliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:13:00.456727Z",
     "start_time": "2019-07-20T04:13:00.449738Z"
    }
   },
   "outputs": [],
   "source": [
    "# identify outliers that are identified in multiple algorithms\n",
    "# reduce(np.intersect1d, (iqrOutliers, ifOutliers, eifOutliers))\n",
    "outliers = reduce(np.intersect1d, (ifOutliers, eifOutliers))\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validation outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'remove'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:13:00.469087Z",
     "start_time": "2019-07-20T04:13:00.459708Z"
    }
   },
   "outputs": [],
   "source": [
    "# capture index values of known outliers\n",
    "knownOutliers = (\n",
    "    train.data[train.data[\"LotArea\"] > 60000].index.values.tolist()\n",
    "    + train.data[train.data[\"LotFrontage\"] > 300].index.values.tolist()\n",
    "    + train.data[train.data[\"GrLivArea\"] > 4000].index.values.tolist()\n",
    ")\n",
    "knownOutliers = sorted(set(knownOutliers))\n",
    "print(knownOutliers)\n",
    "\n",
    "# train.data = train.data.drop(train.data.index[outliers])\n",
    "# train.target = np.delete(train.target, outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:13:00.477632Z",
     "start_time": "2019-07-20T04:13:00.471936Z"
    }
   },
   "outputs": [],
   "source": [
    "# index of known outliers and outliers identified with the known outliers removed\n",
    "outliers = [\n",
    "    53,\n",
    "    185,\n",
    "    197,\n",
    "    437,\n",
    "    492,\n",
    "    762,\n",
    "    796,\n",
    "    821,\n",
    "    847,\n",
    "    1161,\n",
    "    1221,\n",
    "    1318,\n",
    "    1376,\n",
    "    249,\n",
    "    313,\n",
    "    335,\n",
    "    451,\n",
    "    523,\n",
    "    691,\n",
    "    706,\n",
    "    934,\n",
    "    1182,\n",
    "    1298,\n",
    "]\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:13:00.489233Z",
     "start_time": "2019-07-20T04:13:00.481079Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove outlers from predictors and response\n",
    "train.data = train.data.drop(train.data.index[outliers])\n",
    "train.target = train.target.drop(index=outliers)\n",
    "print(train.data.shape)\n",
    "print(train.target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing data\n",
    "\n",
    "-__MCAR__ - Completely unsystematic missingness, completely unralted to any of the other variables. simple imputation of mean, median or mode is most acceptable for this type of missingness.\n",
    "\n",
    "-__MAR__ - The nature of the missing data is related to observed data in other variables, not the missing data. The missing data is conditional on some other variable.  For example, men are more likely to tell you their weight than woemn. The missingness of weight has to do with gender.\n",
    "\n",
    "-__MNAR__ - There is a relationship between the propensity of a value to be missing and its values. For example, the wealthiest people choosing not to state their income.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Missing-data'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Evaluate1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training missingness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:13:00.866536Z",
     "start_time": "2019-07-20T04:13:00.496302Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate missing data\n",
    "train.edaMissingSummary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:10:36.085012Z",
     "start_time": "2019-07-20T04:10:35.221591Z"
    }
   },
   "outputs": [],
   "source": [
    "# missingno matrix\n",
    "msno.matrix(train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:18:42.711748Z",
     "start_time": "2019-07-20T04:18:34.629118Z"
    }
   },
   "outputs": [],
   "source": [
    "# missingno bar\n",
    "msno.bar(train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:18:43.779201Z",
     "start_time": "2019-07-20T04:18:42.718350Z"
    }
   },
   "outputs": [],
   "source": [
    "# missingno heatmap\n",
    "msno.heatmap(train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:18:45.691943Z",
     "start_time": "2019-07-20T04:18:43.782724Z"
    }
   },
   "outputs": [],
   "source": [
    "# missingno dendrogram\n",
    "msno.dendrogram(train.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Validation missingness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T03:59:27.783835Z",
     "start_time": "2019-07-20T03:59:27.335381Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate missing data\n",
    "valid.edaMissingSummary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:13:19.552351Z",
     "start_time": "2019-07-20T04:13:18.869157Z"
    }
   },
   "outputs": [],
   "source": [
    "# missingno matrix\n",
    "msno.matrix(valid.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:13:41.246607Z",
     "start_time": "2019-07-20T04:13:29.662780Z"
    }
   },
   "outputs": [],
   "source": [
    "# missingno bar\n",
    "msno.bar(valid.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:14:13.308822Z",
     "start_time": "2019-07-20T04:14:11.020009Z"
    }
   },
   "outputs": [],
   "source": [
    "# missingno heatmap\n",
    "msno.heatmap(valid.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:14:24.187695Z",
     "start_time": "2019-07-20T04:14:22.372604Z"
    }
   },
   "outputs": [],
   "source": [
    "# missingno dendrogram\n",
    "msno.dendrogram(valid.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Training vs. validation missingness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T03:59:27.804085Z",
     "start_time": "2019-07-20T03:59:27.786501Z"
    }
   },
   "outputs": [],
   "source": [
    "# compare feature with missing data\n",
    "train.missingColCompare(train.data, valid.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Impute'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Impute training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T03:59:27.896985Z",
     "start_time": "2019-07-20T03:59:27.806559Z"
    }
   },
   "outputs": [],
   "source": [
    "# apply imputations to missing data in training dataset\n",
    "trainPipe = pipeline.Pipeline([\n",
    "        (\"imputeConstantCat\",train.ConstantImputer(\n",
    "                cols=[\n",
    "                    \"PoolQC\",\n",
    "                    \"Alley\",\n",
    "                    \"Fence\",\n",
    "                    \"FireplaceQu\",\n",
    "                    \"GarageType\",\n",
    "                    \"GarageFinish\",\n",
    "                    \"GarageQual\",\n",
    "                    \"MiscFeature\",\n",
    "                    \"GarageCond\",\n",
    "                    \"BsmtQual\",\n",
    "                    \"BsmtCond\",\n",
    "                    \"BsmtExposure\",\n",
    "                    \"BsmtFinType1\",\n",
    "                    \"BsmtFinType2\",\n",
    "                    \"MasVnrType\",\n",
    "                ],\n",
    "                fill=\"Nonexistent\",)),\n",
    "        (\"imputeConstantNum\",train.ConstantImputer(cols=[\"GarageYrBlt\", \"MasVnrArea\"], fill=0)),\n",
    "        (\"imputeMode\", train.ModeImputer(cols=[\"Electrical\"])),\n",
    "        (\"imputeContext\",train.ContextImputer(nullCol=\"LotFrontage\", contextCol=\"Neighborhood\", strategy=\"mean\")),\n",
    "    ])\n",
    "train.data = trainPipe.transform(train.data)\n",
    "train.edaMissingSummary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Impute validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T03:59:28.036068Z",
     "start_time": "2019-07-20T03:59:27.899698Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# apply imputations to missing data in validation dataset\n",
    "validPipe = pipeline.Pipeline([\n",
    "        (\"imputeConstantCat\",valid.ConstantImputer(\n",
    "                cols=[\n",
    "                    \"PoolQC\",\n",
    "                    \"Alley\",\n",
    "                    \"Fence\",\n",
    "                    \"FireplaceQu\",\n",
    "                    \"GarageType\",\n",
    "                    \"GarageFinish\",\n",
    "                    \"GarageQual\",\n",
    "                    \"MiscFeature\",\n",
    "                    \"GarageCond\",\n",
    "                    \"BsmtQual\",\n",
    "                    \"BsmtCond\",\n",
    "                    \"BsmtExposure\",\n",
    "                    \"BsmtFinType1\",\n",
    "                    \"BsmtFinType2\",\n",
    "                    \"MasVnrType\",\n",
    "                ],\n",
    "                fill=\"Nonexistent\",)),\n",
    "        (\"imputeConstantNum\",valid.ConstantImputer(cols=[\"GarageYrBlt\",\"MasVnrArea\",\"BsmtUnfSF\",\"GarageArea\",\"BsmtFinSF1\",\"TotalBsmtSF\",\"BsmtFinSF2\",],fill=0,)),\n",
    "        (\"imputeModeCat\",valid.ModeImputer(cols=[\"Functional\",\"SaleType\",\"Exterior1st\",\"MSZoning\",\"Exterior2nd\",\"KitchenQual\",\"Utilities\",])),\n",
    "        (\"imputeModeNum\",valid.NumericalImputer(cols=[\"BsmtHalfBath\", \"GarageCars\", \"BsmtFullBath\"],strategy=\"most_frequent\",)),\n",
    "        (\"imputeContext\",valid.ContextImputer(nullCol=\"LotFrontage\",contextCol=\"Neighborhood\",strategy=\"mean\",train=False,\n",
    "                trainValue=trainPipe.named_steps[\"imputeContext\"].trainValue_,)),\n",
    "    ])\n",
    "valid.data = validPipe.transform(valid.data)\n",
    "valid.edaMissingSummary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Engineering'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Evaluate3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Engineer'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Engineer training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T03:59:28.046711Z",
     "start_time": "2019-07-20T03:59:28.038792Z"
    }
   },
   "outputs": [],
   "source": [
    "# additional features\n",
    "train.data[\"BsmtFinSF\"] = train.data[\"BsmtFinSF1\"] + train.data[\"BsmtFinSF2\"]\n",
    "train.data[\"TotalSF\"] = (\n",
    "    train.data[\"TotalBsmtSF\"] + train.data[\"1stFlrSF\"] + train.data[\"2ndFlrSF\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Engineer validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T03:59:28.058778Z",
     "start_time": "2019-07-20T03:59:28.050161Z"
    }
   },
   "outputs": [],
   "source": [
    "# additional features\n",
    "valid.data[\"BsmtFinSF\"] = valid.data[\"BsmtFinSF1\"] + valid.data[\"BsmtFinSF2\"]\n",
    "valid.data[\"TotalSF\"] = (\n",
    "    valid.data[\"TotalBsmtSF\"] + valid.data[\"1stFlrSF\"] + valid.data[\"2ndFlrSF\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Encoding'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Evaluate2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training feature evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T03:59:28.089713Z",
     "start_time": "2019-07-20T03:59:28.061900Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# counts of unique values in training data categorical columns\n",
    "train.data[train.featureByDtype_[\"categorical\"]].apply(pd.Series.nunique, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T03:59:28.154194Z",
     "start_time": "2019-07-20T03:59:28.092976Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print unique values in each categorical columns\n",
    "for col in train.data[train.featureByDtype_[\"categorical\"]]:\n",
    "    print(col, np.unique(train.data[col]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validation feature evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T03:59:28.193070Z",
     "start_time": "2019-07-20T03:59:28.158253Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# counts of unique values in validation data string columns\n",
    "valid.data[valid.featureByDtype_[\"categorical\"]].apply(pd.Series.nunique, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T03:59:28.246110Z",
     "start_time": "2019-07-20T03:59:28.195728Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print unique values in each categorical columns\n",
    "for col in valid.data[valid.featureByDtype_[\"categorical\"]]:\n",
    "    if col not in [\"Name\", \"Cabin\"]:\n",
    "        print(col, np.unique(valid.data[col]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training vs. validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T03:59:28.303026Z",
     "start_time": "2019-07-20T03:59:28.250033Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# identify values that are present in the training data but not the validation data, and vice versa\n",
    "for col in train.featureByDtype_[\"categorical\"]:\n",
    "    trainValues = train.data[col].unique()\n",
    "    validValues = valid.data[col].unique()\n",
    "\n",
    "    trainDiff = set(trainValues) - set(validValues)\n",
    "    validDiff = set(validValues) - set(trainValues)\n",
    "\n",
    "    if len(trainDiff) > 0 or len(validDiff) > 0:\n",
    "        print(\"\\n\\n*** \" + col)\n",
    "        print(\"Value present in training data, not in validation data\")\n",
    "        print(trainDiff)\n",
    "        print(\"Value present in validation data, not in training data\")\n",
    "        print(validDiff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Encode'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encode training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T03:59:28.429314Z",
     "start_time": "2019-07-20T03:59:28.310335Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ordinal column encoding instructions\n",
    "ordinalEncodings = {\n",
    "    \"Street\": {\"Grvl\": 0, \"Pave\": 1},\n",
    "    \"Alley\": {\"Nonexistent\": 0, \"Grvl\": 1, \"Pave\": 2},\n",
    "    \"LotShape\": {\"IR3\": 0, \"IR2\": 1, \"IR1\": 2, \"Reg\": 3},\n",
    "    \"Utilities\": {\"ELO\": 0, \"NoSeWa\": 1, \"NoSewr\": 2, \"AllPub\": 3},\n",
    "    \"LotConfig\": {\"FR3\": 0, \"FR2\": 1, \"Corner\": 2, \"Inside\": 3, \"CulDSac\": 4},\n",
    "    \"LandSlope\": {\"Sev\": 0, \"Mod\": 1, \"Gtl\": 2},\n",
    "    \"ExterQual\": {\"Po\": 0, \"Fa\": 1, \"TA\": 2, \"Gd\": 3, \"Ex\": 4},\n",
    "    \"ExterCond\": {\"Po\": 0, \"Fa\": 1, \"TA\": 2, \"Gd\": 3, \"Ex\": 4},\n",
    "    \"BsmtQual\": {\"Nonexistent\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n",
    "    \"BsmtCond\": {\"Nonexistent\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n",
    "    \"BsmtExposure\": {\"Nonexistent\": 0, \"No\": 1, \"Mn\": 2, \"Av\": 3, \"Gd\": 4},\n",
    "    \"BsmtFinType1\": {\n",
    "        \"Nonexistent\": 0,\n",
    "        \"Unf\": 1,\n",
    "        \"LwQ\": 2,\n",
    "        \"BLQ\": 3,\n",
    "        \"Rec\": 4,\n",
    "        \"ALQ\": 5,\n",
    "        \"GLQ\": 6,\n",
    "    },  # split?\n",
    "    \"BsmtFinType2\": {\n",
    "        \"Nonexistent\": 0,\n",
    "        \"Unf\": 1,\n",
    "        \"LwQ\": 2,\n",
    "        \"BLQ\": 3,\n",
    "        \"Rec\": 4,\n",
    "        \"ALQ\": 5,\n",
    "        \"GLQ\": 6,\n",
    "    },  # split?\n",
    "    \"HeatingQC\": {\"Po\": 0, \"Fa\": 1, \"TA\": 2, \"Gd\": 3, \"Ex\": 4},\n",
    "    \"CentralAir\": {\"N\": 0, \"Y\": 1},\n",
    "    \"Electrical\": {\"FuseP\": 0, \"FuseF\": 1, \"FuseA\": 2, \"Mix\": 3, \"SBrkr\": 4},\n",
    "    \"KitchenQual\": {\"Po\": 0, \"Fa\": 1, \"TA\": 2, \"Gd\": 3, \"Ex\": 4},\n",
    "    \"Functional\": {\n",
    "        \"Sal\": 0,\n",
    "        \"Sev\": 1,\n",
    "        \"Maj2\": 2,\n",
    "        \"Maj1\": 3,\n",
    "        \"Mod\": 4,\n",
    "        \"Min2\": 5,\n",
    "        \"Min1\": 6,\n",
    "        \"Typ\": 7,\n",
    "    },\n",
    "    \"FireplaceQu\": {\"Nonexistent\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n",
    "    \"GarageFinish\": {\"Nonexistent\": 0, \"Unf\": 1, \"RFn\": 2, \"Fin\": 3},\n",
    "    \"GarageQual\": {\"Nonexistent\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n",
    "    \"GarageCond\": {\"Nonexistent\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n",
    "    \"PavedDrive\": {\"N\": 0, \"P\": 1, \"Y\": 2},\n",
    "    \"PoolQC\": {\"Nonexistent\": 0, \"Fa\": 1, \"TA\": 2, \"Gd\": 3, \"Ex\": 4},\n",
    "}\n",
    "\n",
    "# nominal columns\n",
    "nomCatCols = [\n",
    "    \"MSSubClass\",\n",
    "    \"MSZoning\",\n",
    "    \"LandContour\",\n",
    "    \"Neighborhood\",\n",
    "    \"Condition1\",\n",
    "    \"Condition2\",\n",
    "    \"BldgType\",\n",
    "    \"HouseStyle\",\n",
    "    \"RoofStyle\",\n",
    "    \"RoofMatl\",\n",
    "    \"Exterior1st\",\n",
    "    \"Exterior2nd\",\n",
    "    \"MasVnrType\",\n",
    "    \"Foundation\",\n",
    "    \"Heating\",\n",
    "    \"GarageType\",\n",
    "    \"Fence\",\n",
    "    \"SaleType\",\n",
    "    \"SaleCondition\",\n",
    "    \"MiscFeature\",\n",
    "]\n",
    "\n",
    "# apply encodings to training data\n",
    "trainPipe = pipeline.Pipeline(\n",
    "    [\n",
    "        (\"encodeOrdinal\", train.CustomOrdinalEncoder(encodings=ordinalEncodings)),\n",
    "        (\"dummyNominal\", train.Dummies(cols=nomCatCols, dropFirst=False)),\n",
    "    ]\n",
    ")\n",
    "train.data = trainPipe.transform(train.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encode validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T03:59:28.544834Z",
     "start_time": "2019-07-20T03:59:28.431848Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# apply encodings to validation data\n",
    "validPipe = pipeline.Pipeline(\n",
    "    [\n",
    "        (\"encodeOrdinal\", valid.CustomOrdinalEncoder(encodings=ordinalEncodings)),\n",
    "        (\"dummyNominal\", valid.Dummies(cols=nomCatCols, dropFirst=False)),\n",
    "        (\"levels\", valid.MissingDummies(trainCols=train.data.columns)),\n",
    "    ]\n",
    ")\n",
    "valid.data = validPipe.transform(valid.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Transformation'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Evaluate4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training feature transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T03:59:28.739992Z",
     "start_time": "2019-07-20T03:59:28.547311Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate skew of continuous features - validation data\n",
    "train.skewSummary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validation feature transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T03:59:28.923441Z",
     "start_time": "2019-07-20T03:59:28.745339Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate skew of continuous features - training data\n",
    "valid.skewSummary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Transform'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T03:59:29.476295Z",
     "start_time": "2019-07-20T03:59:28.926123Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# skew correct in training dataset, which also learns te best lambda value for each columns\n",
    "trainPipe = pipeline.Pipeline([\n",
    "        (\"skew\",train.SkewTransform(cols=train.featureByDtype_[\"continuous\"], skewMin=0.75, pctZeroMax=1.0, verbose = True))\n",
    "    ])\n",
    "train.data = trainPipe.transform(train.data)\n",
    "train.skewSummary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T03:59:29.739980Z",
     "start_time": "2019-07-20T03:59:29.479372Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# skew correction in validation dataset using lambdas learned on training data\n",
    "validPipe = pipeline.Pipeline([\n",
    "        (\"skew\",valid.SkewTransform(train=False, trainValue=trainPipe.named_steps[\"skew\"].trainValue_))\n",
    "    ])\n",
    "valid.data = validPipe.transform(valid.data)\n",
    "valid.skewSummary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers (final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Outliers-final'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Evaluate5'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:01:11.475345Z",
     "start_time": "2019-07-20T04:01:11.415203Z"
    }
   },
   "outputs": [],
   "source": [
    "# identify outliers using IQR\n",
    "trainPipe = pipeline.Pipeline([\n",
    "        (\"outlier\",train.OutlierIQR(outlierCount=8, iqrStep=1.5, features=nonNullNumCol, dropOutliers=False))\n",
    "    ])\n",
    "train.data = trainPipe.transform(train.data)\n",
    "\n",
    "# capture outliers\n",
    "iqrOutliers = np.array(sorted(trainPipe.named_steps[\"outlier\"].outliers_))\n",
    "print(iqrOutliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:01:15.750072Z",
     "start_time": "2019-07-20T04:01:15.466635Z"
    }
   },
   "outputs": [],
   "source": [
    "# identify outliers using Isolation Forest\n",
    "clf = ensemble.IsolationForest(\n",
    "    behaviour=\"new\", max_samples=train.data.shape[0], random_state=0, contamination=0.02\n",
    ")\n",
    "clf.fit(train.data[nonNullNumCol])\n",
    "preds = clf.predict(train.data[nonNullNumCol])\n",
    "# np.unique(preds, return_counts = True)\n",
    "\n",
    "# evaluate index values\n",
    "mask = np.isin(preds, -1)  # np.in1d if np.isin is not available\n",
    "ifOutliers = np.where(mask)\n",
    "print(ifOutliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:01:28.543175Z",
     "start_time": "2019-07-20T04:01:21.943647Z"
    }
   },
   "outputs": [],
   "source": [
    "# identify outliers using extended isolation forest\n",
    "trainPipe = pipeline.Pipeline([\n",
    "    (\"outlier\",train.ExtendedIsoForest(\n",
    "                cols=nonNullNumCol,\n",
    "                nTrees=100,\n",
    "                sampleSize=256,\n",
    "                ExtensionLevel=1,\n",
    "                anomaliesRatio=0.009,\n",
    "                dropOutliers=False,))\n",
    "    ])\n",
    "train.data = trainPipe.transform(train.data)\n",
    "\n",
    "# capture outliers\n",
    "eifOutliers = np.array(sorted(trainPipe.named_steps[\"outlier\"].outliers_))\n",
    "print(eifOutliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:01:35.259348Z",
     "start_time": "2019-07-20T04:01:35.253295Z"
    }
   },
   "outputs": [],
   "source": [
    "# identify outliers that are identified in multiple algorithms\n",
    "# reduce(np.intersect1d, (iqrOutliers, ifOutliers, eifOutliers))\n",
    "reduce(np.intersect1d, (ifOutliers, eifOutliers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'remove1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Data evaluation'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Feature-importance'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:01:38.226241Z",
     "start_time": "2019-07-20T04:01:38.120262Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# feature importance summary table\n",
    "featureImp = train.featureImportanceSummary()\n",
    "featureImp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rationality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Rationality'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:03:37.387031Z",
     "start_time": "2019-07-20T04:03:33.429112Z"
    }
   },
   "outputs": [],
   "source": [
    "# percent difference summary\n",
    "dfDiff = abs(\n",
    "    (\n",
    "        ((valid.data.describe() + 1) - (train.data.describe() + 1))\n",
    "        / (train.data.describe() + 1)\n",
    "    )\n",
    "    * 100\n",
    ")\n",
    "dfDiff = dfDiff[dfDiff.columns].replace({0: np.nan})\n",
    "dfDiff[dfDiff < 0] = np.nan\n",
    "dfDiff = dfDiff.fillna(\"\")\n",
    "display(dfDiff)\n",
    "display(train.data[dfDiff.columns].describe())\n",
    "display(valid.data[dfDiff.columns].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value override"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Value override'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:04:41.418522Z",
     "start_time": "2019-07-20T04:04:41.414207Z"
    }
   },
   "outputs": [],
   "source": [
    "# change clearly erroneous value to what it probably was\n",
    "valid.data[\"GarageYrBlt\"].replace({2207: 2007}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Correlation3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:07:36.371105Z",
     "start_time": "2019-07-20T04:07:35.832613Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# correlation heat map with most highly correlated features relative to the target\n",
    "p = PrettierPlot()\n",
    "ax = p.makeCanvas()\n",
    "p.prettyCorrHeatmapTarget(df=train.data, target=train.target, thresh=0.6, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Remarks - There are three pairs of highly correlated features:\n",
    "    - 'GarageArea' and 'GarageCars'\n",
    "    - 'TotRmsAbvGrd' and 'GrLivArea'\n",
    "    - '1stFlrSF' and 'TotalBsmtSF\n",
    "This makes sense, given what each feature represents and how each pair items relate to each other. We likely only need one feature from each pair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Modeling'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data-preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Data-preparation'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:08:19.417675Z",
     "start_time": "2019-07-20T04:08:18.824004Z"
    },
    "code_folding": [
     20,
     73,
     103
    ]
   },
   "outputs": [],
   "source": [
    "# import training data\n",
    "dfTrain = pd.read_csv(\"/home/data-science-portfolio/data/kaggleHousingPrices/train.csv\")\n",
    "train = mlm.Machine(\n",
    "    data=dfTrain,\n",
    "    target=[\"SalePrice\"],\n",
    "    removeFeatures=[\"Id\", \"MiscVal\"],\n",
    "    overrideCat=[\n",
    "        \"MSSubClass\",\n",
    "        \"OverallQual\",\n",
    "        \"OverallCond\",\n",
    "        \"YearBuilt\",\n",
    "        \"YearRemodAdd\",\n",
    "        \"MoSold\",\n",
    "        \"YrSold\",\n",
    "    ],\n",
    "    targetType=\"continuous\",\n",
    ")\n",
    "\n",
    "### training data transformation pipeline\n",
    "### ordinal columns\n",
    "ordinalEncodings = {\n",
    "    \"Street\": {\"Grvl\": 0, \"Pave\": 1},\n",
    "    \"Alley\": {\"Nonexistent\": 0, \"Grvl\": 1, \"Pave\": 2},\n",
    "    \"LotShape\": {\"IR3\": 0, \"IR2\": 1, \"IR1\": 2, \"Reg\": 3},\n",
    "    \"Utilities\": {\"ELO\": 0, \"NoSeWa\": 1, \"NoSewr\": 2, \"AllPub\": 3},\n",
    "    \"LotConfig\": {\"FR3\": 0, \"FR2\": 1, \"Corner\": 2, \"Inside\": 3, \"CulDSac\": 4},\n",
    "    \"LandSlope\": {\"Sev\": 0, \"Mod\": 1, \"Gtl\": 2},\n",
    "    \"ExterQual\": {\"Po\": 0, \"Fa\": 1, \"TA\": 2, \"Gd\": 3, \"Ex\": 4},\n",
    "    \"ExterCond\": {\"Po\": 0, \"Fa\": 1, \"TA\": 2, \"Gd\": 3, \"Ex\": 4},\n",
    "    \"BsmtQual\": {\"Nonexistent\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n",
    "    \"BsmtCond\": {\"Nonexistent\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n",
    "    \"BsmtExposure\": {\"Nonexistent\": 0, \"No\": 1, \"Mn\": 2, \"Av\": 3, \"Gd\": 4},\n",
    "    \"BsmtFinType1\": {\n",
    "        \"Nonexistent\": 0,\n",
    "        \"Unf\": 1,\n",
    "        \"LwQ\": 2,\n",
    "        \"BLQ\": 3,\n",
    "        \"Rec\": 4,\n",
    "        \"ALQ\": 5,\n",
    "        \"GLQ\": 6,\n",
    "    },  # split?\n",
    "    \"BsmtFinType2\": {\n",
    "        \"Nonexistent\": 0,\n",
    "        \"Unf\": 1,\n",
    "        \"LwQ\": 2,\n",
    "        \"BLQ\": 3,\n",
    "        \"Rec\": 4,\n",
    "        \"ALQ\": 5,\n",
    "        \"GLQ\": 6,\n",
    "    },  # split?\n",
    "    \"HeatingQC\": {\"Po\": 0, \"Fa\": 1, \"TA\": 2, \"Gd\": 3, \"Ex\": 4},\n",
    "    \"CentralAir\": {\"N\": 0, \"Y\": 1},\n",
    "    \"Electrical\": {\"FuseP\": 0, \"FuseF\": 1, \"FuseA\": 2, \"Mix\": 3, \"SBrkr\": 4},\n",
    "    \"KitchenQual\": {\"Po\": 0, \"Fa\": 1, \"TA\": 2, \"Gd\": 3, \"Ex\": 4},\n",
    "    \"Functional\": {\n",
    "        \"Sal\": 0,\n",
    "        \"Sev\": 1,\n",
    "        \"Maj2\": 2,\n",
    "        \"Maj1\": 3,\n",
    "        \"Mod\": 4,\n",
    "        \"Min2\": 5,\n",
    "        \"Min1\": 6,\n",
    "        \"Typ\": 7,\n",
    "    },\n",
    "    \"FireplaceQu\": {\"Nonexistent\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n",
    "    \"GarageFinish\": {\"Nonexistent\": 0, \"Unf\": 1, \"RFn\": 2, \"Fin\": 3},\n",
    "    \"GarageQual\": {\"Nonexistent\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n",
    "    \"GarageCond\": {\"Nonexistent\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n",
    "    \"PavedDrive\": {\"N\": 0, \"P\": 1, \"Y\": 2},\n",
    "    \"PoolQC\": {\"Nonexistent\": 0, \"Fa\": 1, \"TA\": 2, \"Gd\": 3, \"Ex\": 4},\n",
    "}\n",
    "\n",
    "### nominal columns\n",
    "nomCatCols = [\n",
    "    \"MSSubClass\",\n",
    "    \"MSZoning\",\n",
    "    \"LandContour\",\n",
    "    \"Neighborhood\",\n",
    "    \"Condition1\",\n",
    "    \"Condition2\",\n",
    "    \"BldgType\",\n",
    "    \"HouseStyle\",\n",
    "    \"RoofStyle\",\n",
    "    \"RoofMatl\",\n",
    "    \"Exterior1st\",\n",
    "    \"Exterior2nd\",\n",
    "    \"MasVnrType\",\n",
    "    \"Foundation\",\n",
    "    \"Heating\",\n",
    "    \"GarageType\",\n",
    "    \"Fence\",\n",
    "    \"SaleType\",\n",
    "    \"SaleCondition\",\n",
    "    \"MiscFeature\",\n",
    "]\n",
    "\n",
    "### additional features\n",
    "train.data[\"BsmtFinSF\"] = train.data[\"BsmtFinSF1\"] + train.data[\"BsmtFinSF2\"]\n",
    "train.data[\"TotalSF\"] = (\n",
    "    train.data[\"TotalBsmtSF\"] + train.data[\"1stFlrSF\"] + train.data[\"2ndFlrSF\"]\n",
    ")\n",
    "\n",
    "### observation removal\n",
    "outliers = [\n",
    "    53,\n",
    "    185,\n",
    "    197,\n",
    "    437,\n",
    "    492,\n",
    "    762,\n",
    "    796,\n",
    "    821,\n",
    "    847,\n",
    "    1161,\n",
    "    1221,\n",
    "    1318,\n",
    "    1376,\n",
    "    249,\n",
    "    313,\n",
    "    335,\n",
    "    451,\n",
    "    523,\n",
    "    691,\n",
    "    706,\n",
    "    934,\n",
    "    1182,\n",
    "    1298,\n",
    "]\n",
    "train.data = train.data.drop(train.data.index[outliers])\n",
    "train.target = train.target.drop(index=outliers)\n",
    "\n",
    "### pre-processing pipeline\n",
    "trainPipe = pipeline.Pipeline([\n",
    "    (\"imputeConstantCat\",train.ConstantImputer(cols=[\"PoolQC\",\"Alley\",\"Fence\",\"FireplaceQu\",\"GarageType\",\"GarageFinish\",\"GarageQual\",\"MiscFeature\",\"GarageCond\",\"BsmtQual\",\n",
    "                    \"BsmtCond\",\"BsmtExposure\",\"BsmtFinType1\",\"BsmtFinType2\",\"MasVnrType\",],fill=\"Nonexistent\")),\n",
    "        (\"imputeConstantNum\",train.ConstantImputer(cols=[\"GarageYrBlt\", \"MasVnrArea\"], fill=0)),\n",
    "        (\"imputeMode\", train.ModeImputer(cols=[\"Electrical\"])),\n",
    "        (\"imputeContext\",train.ContextImputer(nullCol=\"LotFrontage\", contextCol=\"Neighborhood\", strategy=\"most_frequent\")),\n",
    "        (\"encodeOrdinal\", train.CustomOrdinalEncoder(encodings=ordinalEncodings)),\n",
    "        (\"dummyNominal\", train.Dummies(cols=nomCatCols, dropFirst=True)),\n",
    "        (\"skew\",train.SkewTransform(cols=train.featureByDtype_[\"continuous\"], skewMin=0.05, pctZeroMax=1.0)),\n",
    "        (\"scale\", train.Robust(cols=\"non-binary\")),\n",
    "\n",
    "    ])\n",
    "train.data = trainPipe.transform(train.data)\n",
    "\n",
    "train.target = np.log1p(train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:08:24.807888Z",
     "start_time": "2019-07-20T04:08:24.509718Z"
    }
   },
   "outputs": [],
   "source": [
    "# import valid data\n",
    "dfValid = pd.read_csv(\"/home/data-science-portfolio/data/kaggleHousingPrices/test.csv\")\n",
    "valid = mlm.Machine(\n",
    "    data=dfValid,\n",
    "    removeFeatures=[\"Id\", \"MiscVal\"],\n",
    "    overrideCat=[\n",
    "        \"MSSubClass\",\n",
    "        \"OverallQual\",\n",
    "        \"OverallCond\",\n",
    "        \"YearBuilt\",\n",
    "        \"YearRemodAdd\",\n",
    "        \"MoSold\",\n",
    "        \"YrSold\",\n",
    "    ],\n",
    "    targetType=\"continuous\",\n",
    ")\n",
    "\n",
    "### additional features\n",
    "valid.data[\"BsmtFinSF\"] = valid.data[\"BsmtFinSF1\"] + valid.data[\"BsmtFinSF2\"]\n",
    "valid.data[\"TotalSF\"] = (\n",
    "    valid.data[\"TotalBsmtSF\"] + valid.data[\"1stFlrSF\"] + valid.data[\"2ndFlrSF\"]\n",
    ")\n",
    "valid.data.loc[valid.data[\"TotalSF\"].isnull(), \"TotalSF\"] = (\n",
    "    valid.data[\"1stFlrSF\"] + valid.data[\"2ndFlrSF\"]\n",
    ")\n",
    "\n",
    "### pre-processing pipeline\n",
    "validPipe = pipeline.Pipeline([\n",
    "        (\"imputeConstantCat\",valid.ConstantImputer(cols=[\"PoolQC\",\"Alley\",\"Fence\",\"FireplaceQu\",\"GarageType\",\"GarageFinish\",\"GarageQual\",\"MiscFeature\",\"GarageCond\",\n",
    "                    \"BsmtQual\",\"BsmtCond\",\"BsmtExposure\",\"BsmtFinType1\",\"BsmtFinType2\",\"MasVnrType\",],fill=\"Nonexistent\")),\n",
    "        (\"imputeConstantNum\",valid.ConstantImputer(cols=[\"GarageYrBlt\",\"MasVnrArea\",\"BsmtUnfSF\",\"GarageArea\",\"BsmtFinSF1\",\"TotalBsmtSF\",\"BsmtFinSF2\",],fill=0)),\n",
    "        (\"imputeModeCat\",valid.ModeImputer(cols=[\"Functional\",\"SaleType\",\"Exterior1st\",\"MSZoning\",\"Exterior2nd\",\"KitchenQual\",\"Utilities\"],train=False,# trainValue=train.data)),\n",
    "                                          trainValue=train.data.merge(trainPipe.named_steps[\"dummyNominal\"].originalCols_, right_index = True, left_index = True))),\n",
    "        (\"imputeModeNum\",valid.NumericalImputer(cols=[\"BsmtHalfBath\", \"GarageCars\", \"BsmtFullBath\"],strategy=\"most_frequent\")),\n",
    "        (\"imputeContext\",valid.ContextImputer(nullCol=\"LotFrontage\",contextCol=\"Neighborhood\",train=False,trainValue=trainPipe.named_steps[\"imputeContext\"].trainValue_)),\n",
    "        (\"encodeOrdinal\", valid.CustomOrdinalEncoder(encodings=ordinalEncodings)),\n",
    "        (\"dummyNominal\", valid.Dummies(cols=nomCatCols, dropFirst=True)),\n",
    "        (\"skew\",valid.SkewTransform(cols=valid.featureByDtype_[\"continuous\"],train=False,trainValue=trainPipe.named_steps[\"skew\"].trainValue_)),\n",
    "        (\"scale\",valid.Robust(cols=\"non-binary\",train=False,trainValue=trainPipe.named_steps[\"scale\"].trainValue_)),\n",
    "        (\"levels\", valid.MissingDummies(trainCols=train.data.columns)),\n",
    "    ])\n",
    "valid.data = validPipe.transform(valid.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian hyper-parameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Bayesian-hyper-parameter-optimization'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T04:08:52.810022Z",
     "start_time": "2019-07-20T04:08:52.684586Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# parameter space\n",
    "allSpace = {\n",
    "    \"linear_model.Lasso\": {\"alpha\": hp.uniform(\"alpha\", 0.0000001, 10)},\n",
    "    \"linear_model.Ridge\": {\"alpha\": hp.uniform(\"alpha\", 0.0001, 20)},\n",
    "    \"linear_model.ElasticNet\": {\n",
    "        \"alpha\": hp.uniform(\"alpha\", 0.0000001, 10),\n",
    "        \"l1_ratio\": hp.uniform(\"l1_ratio\", 0.0, 0.2),\n",
    "    },\n",
    "    \"kernel_ridge.KernelRidge\": {\n",
    "        \"alpha\": hp.uniform(\"alpha\", 0.0001, 15),\n",
    "        \"kernel\": hp.choice(\"kernel\", [\"linear\", \"polynomial\", \"rbf\"]),\n",
    "        \"degree\": hp.choice(\"degree\", [2, 3]),\n",
    "        \"gamma\": hp.uniform(\"gamma\", 6.0, 8.0),\n",
    "    },\n",
    "    \"lightgbm.LGBMRegressor\": {\n",
    "        \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.4, 0.65),\n",
    "        \"boosting_type\": hp.choice(\"boosting_type\", [\"gbdt\"]),\n",
    "        \"subsample\": hp.uniform(\"subsample\", 0.5, 1),\n",
    "        \"learning_rate\": hp.uniform(\"learning_rate\", 0.000000001, 0.05),\n",
    "        \"max_depth\": hp.choice(\"max_depth\", np.arange(2, 8, dtype=int)),\n",
    "        \"min_child_samples\": hp.uniform(\"min_child_samples\", 10, 100),\n",
    "        \"n_estimators\": hp.choice(\"n_estimators\", np.arange(100, 4000, 10, dtype=int)),\n",
    "        \"num_leaves\": hp.uniform(\"num_leaves\", 8, 150),\n",
    "        \"reg_alpha\": hp.uniform(\"reg_alpha\", 0.0, 0.2),\n",
    "        \"reg_lambda\": hp.uniform(\"reg_lambda\", 0.05, 0.25),\n",
    "        \"subsample_for_bin\": hp.uniform(\"subsample_for_bin\", 200000, 400000),\n",
    "    },\n",
    "    \"xgboost.XGBRegressor\": {\n",
    "        \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.4, 0.65),\n",
    "        \"gamma\": hp.uniform(\"gamma\", 0.0, 2),\n",
    "        \"reg_alpha\": hp.uniform(\"reg_alpha\", 0.0, 0.3),\n",
    "        \"reg_lambda\": hp.uniform(\"reg_lambda\", 0.4, 1.0),\n",
    "        \"learning_rate\": hp.uniform(\"learning_rate\", 0.00001, 0.08),\n",
    "        \"max_depth\": hp.choice(\"max_depth\", np.arange(2, 12, dtype=int)),\n",
    "        \"min_child_weight\": hp.uniform(\"min_child_weight\", 1, 8),\n",
    "        \"n_estimators\": hp.choice(\"n_estimators\", np.arange(4000, 10000, 10, dtype=int)),\n",
    "        \"subsample\": hp.uniform(\"subsample\", 0.5, 0.8),\n",
    "    },\n",
    "    \"ensemble.RandomForestRegressor\": {\n",
    "        \"bootstrap\": hp.choice(\"bootstrap\", [True, False]),\n",
    "        \"max_depth\": hp.choice(\"max_depth\", np.arange(8, 20, dtype=int)),\n",
    "        \"n_estimators\": hp.choice(\"n_estimators\", np.arange(100, 40000, 10, dtype=int)),\n",
    "        \"max_features\": hp.choice(\"max_features\", [\"sqrt\"]),\n",
    "        \"min_samples_split\": hp.choice(\n",
    "            \"min_samples_split\", np.arange(2, 20, dtype=int)\n",
    "        ),\n",
    "        \"min_samples_leaf\": hp.choice(\"min_samples_leaf\", np.arange(2, 15, dtype=int)),\n",
    "    },\n",
    "    \"ensemble.GradientBoostingRegressor\": {\n",
    "        \"n_estimators\": hp.choice(\"n_estimators\", np.arange(100, 10000, 10, dtype=int)),\n",
    "        \"max_depth\": hp.choice(\"max_depth\", np.arange(2, 20, dtype=int)),\n",
    "        \"max_features\": hp.choice(\"max_features\", [\"auto\", \"sqrt\"]),\n",
    "        \"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 0.2),\n",
    "        \"loss\": hp.choice(\"loss\", [\"ls\", \"lad\", \"huber\", \"quantile\"]),\n",
    "        \"min_samples_split\": hp.choice(\n",
    "            \"min_samples_split\", np.arange(2, 40, dtype=int)\n",
    "        ),\n",
    "        \"min_samples_leaf\": hp.choice(\"min_samples_leaf\", np.arange(2, 40, dtype=int)),\n",
    "    },\n",
    "    \"ensemble.AdaBoostRegressor\": {\n",
    "        \"n_estimators\": hp.choice(\"n_estimators\", np.arange(100, 10000, 10, dtype=int)),\n",
    "        \"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 0.2),\n",
    "        \"loss\": hp.choice(\"loss\", [\"linear\", \"square\", \"exponential\"]),\n",
    "    },\n",
    "    \"ensemble.ExtraTreesRegressor\": {\n",
    "        \"n_estimators\": hp.choice(\"n_estimators\", np.arange(100, 10000, 10, dtype=int)),\n",
    "        \"max_depth\": hp.choice(\"max_depth\", np.arange(2, 20, dtype=int)),\n",
    "        \"min_samples_split\": hp.choice(\n",
    "            \"min_samples_split\", np.arange(2, 40, dtype=int)\n",
    "        ),\n",
    "        \"min_samples_leaf\": hp.choice(\"min_samples_leaf\", np.arange(2, 40, dtype=int)),\n",
    "        \"max_features\": hp.choice(\"max_features\", [\"auto\", \"sqrt\"]),\n",
    "    },\n",
    "    \"svm.SVR\": {\n",
    "        \"C\": hp.uniform(\"C\", 0.00001, 10),\n",
    "        \"kernel\": hp.choice(\"kernel\", [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]),\n",
    "        \"degree\": hp.choice(\"degree\", [2, 3]),\n",
    "        \"gamma\": hp.uniform(\"gamma\", 0.0001, 10),\n",
    "        \"epsilon\": hp.uniform(\"epsilon\", 0.001, 5),\n",
    "    },\n",
    "    \"neighbors.KNeighborsRegressor\": {\n",
    "        \"algorithm\": hp.choice(\"algorithm\", [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"]),\n",
    "        \"n_neighbors\": hp.choice(\"n_neighbors\", np.arange(1, 20, dtype=int)),\n",
    "        \"weights\": hp.choice(\"weights\", [\"distance\", \"uniform\"]),\n",
    "        \"p\": hp.choice(\"p\", [1, 2]),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T16:59:07.258337Z",
     "start_time": "2019-07-18T16:55:40.411794Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# execute bayesian optimization grid search\n",
    "analysis = \"housing\"\n",
    "train.execBayesOptimSearch(\n",
    "    allSpace=allSpace,\n",
    "    resultsDir=\"{}_hyperopt_{}.csv\".format(rundate, analysis),\n",
    "    X=train.data,\n",
    "    y=train.target,\n",
    "    scoring=\"rmsle\",\n",
    "    n_folds=2,\n",
    "    n_jobs=4,\n",
    "    iters=50,\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model loss by iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Model-loss-by-iteration'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T17:13:07.514965Z",
     "start_time": "2019-07-18T17:13:07.354774Z"
    }
   },
   "outputs": [],
   "source": [
    "# read scores summary table\n",
    "analysis = 'housing'\n",
    "resultsDf = pd.read_csv(\"{}_hyperopt_{}.csv\".format(rundate, analysis), na_values=\"nan\")\n",
    "resultsDict = train.unpackRawParams(resultsDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T17:13:10.725968Z",
     "start_time": "2019-07-18T17:13:09.210203Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loss plot\n",
    "train.lossPlot(resultsAsDict=resultsDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter selection by iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Parameter-selection-by-iteration'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T17:13:23.721392Z",
     "start_time": "2019-07-18T17:13:18.481944Z"
    }
   },
   "outputs": [],
   "source": [
    "# estimator parameter plots\n",
    "train.paramPlot(resultsAsDict=resultsDict, allSpace=allSpace, nIter=100, chartProp = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model performance evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Model-performance-evaluation'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model with full set of predictor variables\n",
    "linReg = linear_model.LinearRegression()\n",
    "linReg.fit(XTrain, yTrain)\n",
    "yPredsTrain = linReg.predict(XTrain)\n",
    "yPredsTest = linReg.predict(XTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat value 1 X times (len of train then test array)\n",
    "yActual = np.vstack((yTrain, yTest))\n",
    "yPreds = np.vstack((yPredsTrain, yPredsTest))\n",
    "yType = np.hstack((np.repeat(0, yTrain.shape[0]), np.repeat(1, yTest.shape[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Residual-plots'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize predictions using residual plot\n",
    "p = PrettierPlot()\n",
    "ax = p.makeCanvas(title=\"\", xLabel=\"Predicted values\", yLabel=\"Residuals\", yShift=0.8)\n",
    "p.pretty2dScatterHue(\n",
    "    x=yPreds,\n",
    "    y=yPreds - yActual,\n",
    "    target=yType,\n",
    "    label=[\"Training\", \"Test\"],\n",
    "    xUnits=\"f\",\n",
    "    yUnits=\"f\",\n",
    "    bbox=(1.2, 0.9),\n",
    "    ax=ax,\n",
    ")\n",
    "plt.hlines(y=0, xmin=-10, xmax=50, color=\"black\", lw=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model explanability\n",
    "\n",
    "https://www.kaggle.com/learn/machine-learning-explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Feature-importance'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Permutation-importance'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T08:30:55.873743Z",
     "start_time": "2019-03-24T08:30:55.870060Z"
    }
   },
   "outputs": [],
   "source": [
    "# permutation importance\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "perm = PermutationImportance(my_model, random_state=1).fit(val_X, val_y)\n",
    "eli5.show_weights(perm, feature_names=val_X.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Partial-plots'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "from matplotlib import pyplot as plt\n",
    "from pdpbox import pdp, get_dataset, info_plots\n",
    "\n",
    "# Create the data that we will plot\n",
    "pdp_goals = pdp.pdp_isolate(\n",
    "    model=tree_model, dataset=val_X, model_features=feature_names, feature=\"Goal Scored\"\n",
    ")\n",
    "\n",
    "# plot it\n",
    "pdp.pdp_plot(pdp_goals, \"Goal Scored\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_to_plot = \"Distance Covered (Kms)\"\n",
    "pdp_dist = pdp.pdp_isolate(\n",
    "    model=tree_model,\n",
    "    dataset=val_X,\n",
    "    model_features=feature_names,\n",
    "    feature=feature_to_plot,\n",
    ")\n",
    "\n",
    "pdp.pdp_plot(pdp_dist, feature_to_plot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=0).fit(train_X, train_y)\n",
    "\n",
    "pdp_dist = pdp.pdp_isolate(\n",
    "    model=rf_model, dataset=val_X, model_features=feature_names, feature=feature_to_plot\n",
    ")\n",
    "\n",
    "pdp.pdp_plot(pdp_dist, feature_to_plot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D plots\n",
    "# Similar to previous PDP plot except we use pdp_interact instead of pdp_isolate and pdp_interact_plot instead of pdp_isolate_plot\n",
    "features_to_plot = [\"Goal Scored\", \"Distance Covered (Kms)\"]\n",
    "inter1 = pdp.pdp_interact(\n",
    "    model=tree_model,\n",
    "    dataset=val_X,\n",
    "    model_features=feature_names,\n",
    "    features=features_to_plot,\n",
    ")\n",
    "\n",
    "pdp.pdp_interact_plot(\n",
    "    pdp_interact_out=inter1, feature_names=features_to_plot, plot_type=\"contour\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'SHAP-values'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "row_to_show = 5\n",
    "data_for_prediction = val_X.iloc[\n",
    "    row_to_show\n",
    "]  # use 1 row of data here. Could use multiple rows if desired\n",
    "data_for_prediction_array = data_for_prediction.values.reshape(1, -1)\n",
    "\n",
    "\n",
    "my_model.predict_proba(data_for_prediction_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap  # package used to calculate Shap values\n",
    "\n",
    "# Create object that can calculate shap values\n",
    "explainer = shap.TreeExplainer(my_model)\n",
    "\n",
    "# Calculate Shap values\n",
    "shap_values = explainer.shap_values(data_for_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value[1], shap_values[1], data_for_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Kernel SHAP to explain test set predictions\n",
    "k_explainer = shap.KernelExplainer(my_model.predict_proba, train_X)\n",
    "k_shap_values = k_explainer.shap_values(data_for_prediction)\n",
    "shap.force_plot(k_explainer.expected_value[1], k_shap_values[1], data_for_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.DeepExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap  # package used to calculate Shap values\n",
    "\n",
    "# Create object that can calculate shap values\n",
    "explainer = shap.TreeExplainer(my_model)\n",
    "\n",
    "# calculate shap values. This is what we will plot.\n",
    "# Calculate shap_values for all of val_X rather than a single row, to have more data for plot.\n",
    "shap_values = explainer.shap_values(val_X)\n",
    "\n",
    "# Make plot. Index of [1] is explained in text below.\n",
    "shap.summary_plot(shap_values[1], val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap  # package used to calculate Shap values\n",
    "\n",
    "# Create object that can calculate shap values\n",
    "explainer = shap.TreeExplainer(my_model)\n",
    "\n",
    "# calculate shap values. This is what we will plot.\n",
    "shap_values = explainer.shap_values(X)\n",
    "\n",
    "# make plot.\n",
    "shap.dependence_plot(\n",
    "    \"Ball Possession %\", shap_values[1], X, interaction_index=\"Goal Scored\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Stacking'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primary models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Primary-models'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T14:05:17.965746Z",
     "start_time": "2019-03-24T14:05:17.669308Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T14:11:12.912222Z",
     "start_time": "2019-03-24T14:09:44.583800Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T14:11:26.441649Z",
     "start_time": "2019-03-24T14:11:26.032435Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Meta-model'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T14:16:24.776352Z",
     "start_time": "2019-03-24T14:12:03.005790Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T14:16:24.983826Z",
     "start_time": "2019-03-24T14:16:24.779451Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Submission'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Standard'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T13:46:12.681655Z",
     "start_time": "2019-03-24T13:46:06.563199Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T13:46:14.138741Z",
     "start_time": "2019-03-24T13:46:14.106125Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate prediction submission file\n",
    "my_submission = pd.DataFrame({\"Id\": dfTest.Id, \"SalePrice\": np.expm1(yPred)})\n",
    "my_submission.to_csv(\"data/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'Stack'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T14:17:12.332889Z",
     "start_time": "2019-03-24T14:17:11.732365Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T14:17:12.422440Z",
     "start_time": "2019-03-24T14:17:12.335453Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate prediction submission file\n",
    "my_submission = pd.DataFrame({\"Id\": dfTest.Id, \"SalePrice\": np.expm1(yPred)})\n",
    "my_submission.to_csv(\"data/submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
