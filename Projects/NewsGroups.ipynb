{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project info - unsupervised learning with KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "The Scitkit-learn module 'datasets' includes the 20 News Groups dataset, which is a text dataset including roughly 18,000 articles on 20 different topics.\n",
    "\n",
    "The dataset includes labels for each article, but can also be analyzed in an unsupervised fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules and tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T15:01:47.627117Z",
     "start_time": "2018-11-30T15:01:36.359001Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:78% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Standard libary and settings\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import warnings\n",
    "from optparse import OptionParser\n",
    "from time import time\n",
    "warnings.simplefilter('ignore')\n",
    "dataPath = os.path.abspath(os.path.join('../Data'))\n",
    "modulePath = os.path.abspath(os.path.join('../CustomModules'))\n",
    "sys.path.append(modulePath) if modulePath not in sys.path else None\n",
    "from IPython.core.display import display, HTML; display(HTML(\"<style>.container { width:78% !important; }</style>\"))\n",
    "\n",
    "\n",
    "# Data extensions and settings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.options.display.float_format = '{:,.6f}'.format\n",
    "np.set_printoptions(threshold = np.inf, suppress = True)\n",
    "\n",
    "\n",
    "# Modeling extensions\n",
    "import sklearn.svm as svm\n",
    "import sklearn.base as base\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.pipeline as pipeline\n",
    "import sklearn.ensemble as ensemble\n",
    "import sklearn.linear_model as linear_model\n",
    "import sklearn.preprocessing as preprocessing\n",
    "import sklearn.model_selection as model_selection\n",
    "import sklearn.feature_selection as feature_selection\n",
    "import sklearn.feature_extraction as feature_extraction\n",
    "import sklearn.decomposition as decomposition\n",
    "import sklearn.datasets as datasets\n",
    "import sklearn.cluster as cluster\n",
    "\n",
    "\n",
    "# Visualization extensions and settings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Magic functions\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load, clean, inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T15:01:49.931573Z",
     "start_time": "2018-11-30T15:01:47.629237Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset dimensions: (11314,)\n",
      "Test dataset dimensions: (7532,)\n"
     ]
    }
   ],
   "source": [
    "# Load data from scikit-learn\n",
    "\n",
    "XTrain = datasets.fetch_20newsgroups(subset = 'train', remove = ('headers','footers','quotes'))\n",
    "XTest = datasets.fetch_20newsgroups(subset = 'test', remove = ('headers','footers','quotes'))\n",
    "\n",
    "# Train/test dimensions\n",
    "\n",
    "print('Train dataset dimensions: {0}'.format(XTrain.filenames.shape))\n",
    "print('Test dataset dimensions: {0}'.format(XTest.filenames.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T15:01:49.938184Z",
     "start_time": "2018-11-30T15:01:49.933618Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review article categories\n",
    "\n",
    "Labels = XTrain.target_names\n",
    "Labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T15:01:49.945506Z",
     "start_time": "2018-11-30T15:01:49.940272Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample from train data\n",
    "\n",
    "XTrain.data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T15:01:49.951800Z",
     "start_time": "2018-11-30T15:01:49.947365Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rec.autos'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Corresponding label\n",
    "\n",
    "ix = XTrain.target[0]\n",
    "Labels[ix]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert text to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T15:01:51.839782Z",
     "start_time": "2018-11-30T15:01:49.953786Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 101321)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a bag of words model and use term frequency - inverse document frequency\n",
    "# to understand how common or uncommon each word that appears in each document\n",
    "# is relative to the rest of documents in the corpus\n",
    "\n",
    "tfidf = feature_extraction.text.TfidfVectorizer(max_df = 0.5\n",
    "                                               ,stop_words = 'english'\n",
    "                                               ,ngram_range = (1,1)\n",
    "                                               ,lowercase = True\n",
    "                                               ,strip_accents = 'unicode'\n",
    "                                              )\n",
    "\n",
    "tfidfPipe = pipeline.Pipeline([\n",
    "        ('vec', tfidf)\n",
    "    ])\n",
    "\n",
    "vectorized = tfidfPipe.fit_transform(XTrain.data)\n",
    "vectorized.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T15:01:51.947726Z",
     "start_time": "2018-11-30T15:01:51.841695Z"
    }
   },
   "outputs": [],
   "source": [
    "# Capture all unique words\n",
    "\n",
    "vec = tfidfPipe.named_steps['vec']\n",
    "features = vec.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Document-specific word importances__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T15:01:51.954537Z",
     "start_time": "2018-11-30T15:01:51.949893Z"
    }
   },
   "outputs": [],
   "source": [
    "# Functions to determine word importance\n",
    "\n",
    "def top_tfidf_feats(row, features, top_n=25):\n",
    "    \"\"\"\n",
    "    Get top n tfidf values in row and return them \n",
    "    with their corresponding feature names.\n",
    "    \"\"\"\n",
    "    topn_ids = np.argsort(row)[::-1][:top_n]\n",
    "    top_feats = [(features[i], row[i]) for i in topn_ids]\n",
    "    df = pd.DataFrame(top_feats)\n",
    "    df.columns = ['feature', 'tfidf']\n",
    "    return df\n",
    "\n",
    "def top_feats_in_doc(Xtr, features, row_id, top_n=25):\n",
    "    \"\"\"\n",
    "    Top tfidf features in specific document (matrix row) \n",
    "    \"\"\"\n",
    "    row = np.squeeze(Xtr[row_id].toarray())\n",
    "    return top_tfidf_feats(row, features, top_n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate single article and word importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T15:01:51.961597Z",
     "start_time": "2018-11-30T15:01:51.957173Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A fair number of brave souls who upgraded their SI clock oscillator have\\nshared their experiences for this poll. Please send a brief message detailing\\nyour experiences with the procedure. Top speed attained, CPU rated speed,\\nadd on cards and adapters, heat sinks, hour of usage per day, floppy disk\\nfunctionality with 800 and 1.4 m floppies are especially requested.\\n\\nI will be summarizing in the next two days, so please add to the network\\nknowledge base if you have done the clock upgrade and haven't answered this\\npoll. Thanks.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample from training data\n",
    "\n",
    "XTrain.data[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T15:01:51.967953Z",
     "start_time": "2018-11-30T15:01:51.963834Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'comp.sys.mac.hardware'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Corresponding label for that training sample\n",
    "\n",
    "ix = XTrain.target[1]\n",
    "Labels[ix]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T15:01:52.019774Z",
     "start_time": "2018-11-30T15:01:51.970030Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>poll</td>\n",
       "      <td>0.316272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>experiences</td>\n",
       "      <td>0.264929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clock</td>\n",
       "      <td>0.245559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>add</td>\n",
       "      <td>0.205684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>speed</td>\n",
       "      <td>0.198320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>attained</td>\n",
       "      <td>0.181335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sinks</td>\n",
       "      <td>0.178748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>summarizing</td>\n",
       "      <td>0.176433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>detailing</td>\n",
       "      <td>0.172428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>oscillator</td>\n",
       "      <td>0.163521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature    tfidf\n",
       "0         poll 0.316272\n",
       "1  experiences 0.264929\n",
       "2        clock 0.245559\n",
       "3          add 0.205684\n",
       "4        speed 0.198320\n",
       "5     attained 0.181335\n",
       "6        sinks 0.178748\n",
       "7  summarizing 0.176433\n",
       "8    detailing 0.172428\n",
       "9   oscillator 0.163521"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print words based on highest word importance values, within a single document\n",
    "\n",
    "tfidfImp = top_feats_in_doc(vectorized, features, row_id = 1, top_n = 10)\n",
    "tfidfImp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Corpus-wide word importances__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T15:01:52.026596Z",
     "start_time": "2018-11-30T15:01:52.021855Z"
    }
   },
   "outputs": [],
   "source": [
    "# The function is used for identifying word importances, across entire corpus\n",
    "\n",
    "def top_mean_feats(Xtr, features, grp_ids = None, min_tfidf = 0.1, top_n = 25):\n",
    "    \"\"\"\n",
    "    Return the top n features that on average are most important amongst \n",
    "    documents in rows indentified by indices in grp_ids.\n",
    "    \"\"\"\n",
    "    if grp_ids:\n",
    "        D = Xtr[grp_ids].toarray()\n",
    "    else:\n",
    "        D = Xtr.toarray()\n",
    "\n",
    "    D[D < min_tfidf] = 0\n",
    "    tfidf_means = np.mean(D, axis=0)\n",
    "    return top_tfidf_feats(tfidf_means, features, top_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T15:02:06.676919Z",
     "start_time": "2018-11-30T15:01:52.029519Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>god</td>\n",
       "      <td>0.002043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00</td>\n",
       "      <td>0.001441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>key</td>\n",
       "      <td>0.001398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scsi</td>\n",
       "      <td>0.001385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>drive</td>\n",
       "      <td>0.001293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>window</td>\n",
       "      <td>0.001196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mouse</td>\n",
       "      <td>0.001164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>jesus</td>\n",
       "      <td>0.001111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>car</td>\n",
       "      <td>0.001017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>israel</td>\n",
       "      <td>0.000976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature    tfidf\n",
       "0     god 0.002043\n",
       "1      00 0.001441\n",
       "2     key 0.001398\n",
       "3    scsi 0.001385\n",
       "4   drive 0.001293\n",
       "5  window 0.001196\n",
       "6   mouse 0.001164\n",
       "7   jesus 0.001111\n",
       "8     car 0.001017\n",
       "9  israel 0.000976"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print words based on highest word importance values, within the entire corpus\n",
    "\n",
    "top_mean_feats(vectorized, features, grp_ids = None, min_tfidf = 0.3, top_n = 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Category-specific word importances__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T15:02:06.688094Z",
     "start_time": "2018-11-30T15:02:06.680633Z"
    }
   },
   "outputs": [],
   "source": [
    "# The function is used for identifying word importances, within each document category\n",
    "\n",
    "def top_feats_by_class(Xtr, y, features, min_tfidf = 0.1, top_n = 25):\n",
    "    \"\"\"\n",
    "    Return a list of dfs, where each df holds top_n features and \n",
    "    their mean tfidf value calculated across documents with the \n",
    "    same class label.\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    labels = np.unique(y)\n",
    "    for label in labels:\n",
    "        ids = np.where(y == label)\n",
    "        feats_df = top_mean_feats(Xtr, features, ids\n",
    "                                  , min_tfidf = min_tfidf, top_n = top_n)\n",
    "        feats_df.label = label\n",
    "        dfs.append(feats_df)\n",
    "    return dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T15:02:14.128173Z",
     "start_time": "2018-11-30T15:02:06.690829Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>atheism</td>\n",
       "      <td>0.008466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>god</td>\n",
       "      <td>0.007822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deletion</td>\n",
       "      <td>0.007319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>islam</td>\n",
       "      <td>0.007053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>objective</td>\n",
       "      <td>0.006983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>moral</td>\n",
       "      <td>0.006553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>motto</td>\n",
       "      <td>0.006197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>religion</td>\n",
       "      <td>0.005106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>satan</td>\n",
       "      <td>0.004969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bible</td>\n",
       "      <td>0.004946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature    tfidf\n",
       "0    atheism 0.008466\n",
       "1        god 0.007822\n",
       "2   deletion 0.007319\n",
       "3      islam 0.007053\n",
       "4  objective 0.006983\n",
       "5      moral 0.006553\n",
       "6      motto 0.006197\n",
       "7   religion 0.005106\n",
       "8      satan 0.004969\n",
       "9      bible 0.004946"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print words based on highest word importance values, within each class of documents\n",
    "# In this case we're looking at atheism\n",
    "\n",
    "dfs = top_feats_by_class(vectorized, XTrain.target, features\n",
    "                   , min_tfidf = 0.3, top_n = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T15:03:45.915385Z",
     "start_time": "2018-11-30T15:03:45.905105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top features within category type sci.space \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>space</td>\n",
       "      <td>0.013757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lunar</td>\n",
       "      <td>0.005013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>moon</td>\n",
       "      <td>0.004835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spacecraft</td>\n",
       "      <td>0.004635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>launch</td>\n",
       "      <td>0.004398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nasa</td>\n",
       "      <td>0.004284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>shuttle</td>\n",
       "      <td>0.004244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>centaur</td>\n",
       "      <td>0.003727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gehrels</td>\n",
       "      <td>0.003191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>yo</td>\n",
       "      <td>0.003048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature    tfidf\n",
       "0       space 0.013757\n",
       "1       lunar 0.005013\n",
       "2        moon 0.004835\n",
       "3  spacecraft 0.004635\n",
       "4      launch 0.004398\n",
       "5        nasa 0.004284\n",
       "6     shuttle 0.004244\n",
       "7     centaur 0.003727\n",
       "8     gehrels 0.003191\n",
       "9          yo 0.003048"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "\n",
    "topicIx = 14\n",
    "\n",
    "print('Top features within category type {0} \\n'.format(Labels[topicIx]))\n",
    "display(dfs[topicIx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster analysis\n",
    "\n",
    "This section executes cluster analysis, an unsupervised learning technique, on the documents. It groups individual documents with other document that are determined by the algorithm to be similar. In this model, we will use KMeans to find K different clusters. In this case, we will use k = 20, because we know ther are 20 different categories. We can then compare the documents and their cluster labels to the actual labels to see how well KMeans performed its unsupervised learning task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T15:10:30.412041Z",
     "start_time": "2018-11-30T15:10:30.406487Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create parameter grid to review different values for ngram_range, \n",
    "# use_idf, and max_df\n",
    "\n",
    "paramGrid = {'tfidf__ngram_range': [(1, 1)]\n",
    "              ,'tfidf__use_idf': (True, False)\n",
    "              ,'tfidf__max_df' :  np.linspace(0.3, 0.8, 10)\n",
    "}\n",
    "\n",
    "# Make pipeline for TfidfVectorizer and kmean\n",
    "# For Tfidf, remove English stop words from the corpus and lowercase all words\n",
    "# For Kmeans, determine 20 different clusters among documents\n",
    "\n",
    "tfidfPipe = pipeline.Pipeline([('tfidf', feature_extraction.text.TfidfVectorizer(stop_words = 'english'\n",
    "                                                                       ,lowercase = True\n",
    "                                                                       ,strip_accents = 'unicode'))\n",
    "                      ,('kmeans', cluster.KMeans(n_clusters = 20\n",
    "                                                ,init = 'k-means++'\n",
    "                                                ,random_state = 1\n",
    "                                                ,n_init = 3\n",
    "                                                ))\n",
    "                      ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T16:07:04.679865Z",
     "start_time": "2018-11-30T15:10:34.390542Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] tfidf__max_df=0.3, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  tfidf__max_df=0.3, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2140.731560542527, total=  27.7s\n",
      "[CV] tfidf__max_df=0.3, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   29.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  tfidf__max_df=0.3, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2126.0122146313674, total=  32.6s\n",
      "[CV] tfidf__max_df=0.3, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  1.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  tfidf__max_df=0.3, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2141.947820076083, total=  30.9s\n",
      "[CV] tfidf__max_df=0.3, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  tfidf__max_df=0.3, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2179.278770373121, total=  15.8s\n",
      "[CV] tfidf__max_df=0.3, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.3, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2139.674836694193, total=  22.7s\n",
      "[CV] tfidf__max_df=0.3, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.3, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2080.961744817154, total=  38.3s\n",
      "[CV] tfidf__max_df=0.3, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.3, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2064.0262588973687, total=  38.3s\n",
      "[CV] tfidf__max_df=0.3, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.3, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2083.9666944942082, total=  49.2s\n",
      "[CV] tfidf__max_df=0.3, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.3, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2145.663342475798, total=  38.1s\n",
      "[CV] tfidf__max_df=0.3, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.3, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2143.4693705540694, total=  26.6s\n",
      "[CV] tfidf__max_df=0.3555555555555555, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.3555555555555555, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2140.731560542527, total=  26.2s\n",
      "[CV] tfidf__max_df=0.3555555555555555, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.3555555555555555, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2126.0122146313674, total=  31.0s\n",
      "[CV] tfidf__max_df=0.3555555555555555, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.3555555555555555, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2141.947820076083, total=  29.5s\n",
      "[CV] tfidf__max_df=0.3555555555555555, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.3555555555555555, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2179.278770373121, total=  15.2s\n",
      "[CV] tfidf__max_df=0.3555555555555555, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.3555555555555555, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2139.674836694193, total=  21.6s\n",
      "[CV] tfidf__max_df=0.3555555555555555, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.3555555555555555, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2080.961744817154, total=  36.2s\n",
      "[CV] tfidf__max_df=0.3555555555555555, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.3555555555555555, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2064.0262588973687, total=  36.6s\n",
      "[CV] tfidf__max_df=0.3555555555555555, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.3555555555555555, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2083.9666944942082, total=  47.3s\n",
      "[CV] tfidf__max_df=0.3555555555555555, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.3555555555555555, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2145.663342475798, total=  38.0s\n",
      "[CV] tfidf__max_df=0.3555555555555555, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.3555555555555555, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2143.4693705540694, total=  26.8s\n",
      "[CV] tfidf__max_df=0.4111111111111111, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.4111111111111111, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2140.731560542527, total=  25.9s\n",
      "[CV] tfidf__max_df=0.4111111111111111, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.4111111111111111, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2126.0122146313674, total=  30.8s\n",
      "[CV] tfidf__max_df=0.4111111111111111, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.4111111111111111, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2141.947820076083, total=  29.3s\n",
      "[CV] tfidf__max_df=0.4111111111111111, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.4111111111111111, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2179.278770373121, total=  16.0s\n",
      "[CV] tfidf__max_df=0.4111111111111111, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.4111111111111111, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2139.674836694193, total=  21.5s\n",
      "[CV] tfidf__max_df=0.4111111111111111, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.4111111111111111, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2080.961744817154, total=  36.2s\n",
      "[CV] tfidf__max_df=0.4111111111111111, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.4111111111111111, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2064.0262588973687, total=  39.4s\n",
      "[CV] tfidf__max_df=0.4111111111111111, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.4111111111111111, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2083.9666944942082, total=  52.0s\n",
      "[CV] tfidf__max_df=0.4111111111111111, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.4111111111111111, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2145.663342475798, total=  42.3s\n",
      "[CV] tfidf__max_df=0.4111111111111111, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.4111111111111111, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2143.4693705540694, total=  29.2s\n",
      "[CV] tfidf__max_df=0.4666666666666667, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.4666666666666667, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2140.731560542527, total=  28.8s\n",
      "[CV] tfidf__max_df=0.4666666666666667, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.4666666666666667, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2126.0122146313674, total=  34.6s\n",
      "[CV] tfidf__max_df=0.4666666666666667, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.4666666666666667, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2141.947820076083, total=  32.6s\n",
      "[CV] tfidf__max_df=0.4666666666666667, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.4666666666666667, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2179.278770373121, total=  16.6s\n",
      "[CV] tfidf__max_df=0.4666666666666667, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.4666666666666667, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2139.674836694193, total=  23.9s\n",
      "[CV] tfidf__max_df=0.4666666666666667, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.4666666666666667, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2080.961744817154, total=  40.2s\n",
      "[CV] tfidf__max_df=0.4666666666666667, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.4666666666666667, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2064.0262588973687, total=  40.4s\n",
      "[CV] tfidf__max_df=0.4666666666666667, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.4666666666666667, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2083.9666944942082, total=  52.2s\n",
      "[CV] tfidf__max_df=0.4666666666666667, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.4666666666666667, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2145.663342475798, total=  42.3s\n",
      "[CV] tfidf__max_df=0.4666666666666667, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.4666666666666667, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2143.4693705540694, total=  29.2s\n",
      "[CV] tfidf__max_df=0.5222222222222221, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.5222222222222221, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2140.731560542527, total=  28.8s\n",
      "[CV] tfidf__max_df=0.5222222222222221, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.5222222222222221, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2126.0122146313674, total=  34.6s\n",
      "[CV] tfidf__max_df=0.5222222222222221, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  tfidf__max_df=0.5222222222222221, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2141.947820076083, total=  32.8s\n",
      "[CV] tfidf__max_df=0.5222222222222221, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.5222222222222221, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2179.278770373121, total=  16.6s\n",
      "[CV] tfidf__max_df=0.5222222222222221, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.5222222222222221, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2139.674836694193, total=  23.9s\n",
      "[CV] tfidf__max_df=0.5222222222222221, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.5222222222222221, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2080.961744817154, total=  40.5s\n",
      "[CV] tfidf__max_df=0.5222222222222221, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.5222222222222221, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2064.0262588973687, total=  40.5s\n",
      "[CV] tfidf__max_df=0.5222222222222221, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.5222222222222221, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2083.9666944942082, total=  55.0s\n",
      "[CV] tfidf__max_df=0.5222222222222221, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.5222222222222221, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2145.663342475798, total=  41.7s\n",
      "[CV] tfidf__max_df=0.5222222222222221, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.5222222222222221, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2143.4693705540694, total=  29.4s\n",
      "[CV] tfidf__max_df=0.5777777777777777, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.5777777777777777, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2140.731560542527, total=  28.8s\n",
      "[CV] tfidf__max_df=0.5777777777777777, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.5777777777777777, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2126.0122146313674, total=  32.9s\n",
      "[CV] tfidf__max_df=0.5777777777777777, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.5777777777777777, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2141.947820076083, total=  29.2s\n",
      "[CV] tfidf__max_df=0.5777777777777777, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.5777777777777777, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2179.278770373121, total=  15.1s\n",
      "[CV] tfidf__max_df=0.5777777777777777, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.5777777777777777, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2139.674836694193, total=  21.5s\n",
      "[CV] tfidf__max_df=0.5777777777777777, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.5777777777777777, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2080.961744817154, total=  36.1s\n",
      "[CV] tfidf__max_df=0.5777777777777777, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.5777777777777777, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2064.0262588973687, total=  36.3s\n",
      "[CV] tfidf__max_df=0.5777777777777777, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.5777777777777777, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2083.9666944942082, total=  47.4s\n",
      "[CV] tfidf__max_df=0.5777777777777777, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.5777777777777777, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2145.663342475798, total=  38.1s\n",
      "[CV] tfidf__max_df=0.5777777777777777, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.5777777777777777, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2143.4693705540694, total=  26.5s\n",
      "[CV] tfidf__max_df=0.6333333333333333, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.6333333333333333, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2140.731560542527, total=  26.3s\n",
      "[CV] tfidf__max_df=0.6333333333333333, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.6333333333333333, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2126.0122146313674, total=  31.1s\n",
      "[CV] tfidf__max_df=0.6333333333333333, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.6333333333333333, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2141.947820076083, total=  32.5s\n",
      "[CV] tfidf__max_df=0.6333333333333333, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.6333333333333333, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2179.278770373121, total=  16.4s\n",
      "[CV] tfidf__max_df=0.6333333333333333, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.6333333333333333, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2139.674836694193, total=  22.1s\n",
      "[CV] tfidf__max_df=0.6333333333333333, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.6333333333333333, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2080.961744817154, total=  39.2s\n",
      "[CV] tfidf__max_df=0.6333333333333333, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.6333333333333333, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2064.0262588973687, total=  40.8s\n",
      "[CV] tfidf__max_df=0.6333333333333333, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.6333333333333333, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2083.9666944942082, total=  51.1s\n",
      "[CV] tfidf__max_df=0.6333333333333333, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.6333333333333333, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2145.663342475798, total=  39.8s\n",
      "[CV] tfidf__max_df=0.6333333333333333, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.6333333333333333, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2143.4693705540694, total=  28.5s\n",
      "[CV] tfidf__max_df=0.6888888888888889, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.6888888888888889, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2140.731560542527, total=  28.1s\n",
      "[CV] tfidf__max_df=0.6888888888888889, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.6888888888888889, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2126.0122146313674, total=  33.3s\n",
      "[CV] tfidf__max_df=0.6888888888888889, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.6888888888888889, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2141.947820076083, total=  30.8s\n",
      "[CV] tfidf__max_df=0.6888888888888889, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.6888888888888889, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2179.278770373121, total=  16.2s\n",
      "[CV] tfidf__max_df=0.6888888888888889, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.6888888888888889, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2139.674836694193, total=  22.8s\n",
      "[CV] tfidf__max_df=0.6888888888888889, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.6888888888888889, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2080.961744817154, total=  38.8s\n",
      "[CV] tfidf__max_df=0.6888888888888889, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.6888888888888889, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2064.0262588973687, total=  39.4s\n",
      "[CV] tfidf__max_df=0.6888888888888889, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.6888888888888889, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2083.9666944942082, total=  49.3s\n",
      "[CV] tfidf__max_df=0.6888888888888889, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.6888888888888889, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2145.663342475798, total=  40.6s\n",
      "[CV] tfidf__max_df=0.6888888888888889, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.6888888888888889, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2143.4693705540694, total=  27.0s\n",
      "[CV] tfidf__max_df=0.7444444444444445, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  tfidf__max_df=0.7444444444444445, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2140.731560542527, total=  26.5s\n",
      "[CV] tfidf__max_df=0.7444444444444445, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.7444444444444445, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2126.0122146313674, total=  31.6s\n",
      "[CV] tfidf__max_df=0.7444444444444445, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.7444444444444445, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2141.947820076083, total=  29.8s\n",
      "[CV] tfidf__max_df=0.7444444444444445, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.7444444444444445, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2179.278770373121, total=  15.4s\n",
      "[CV] tfidf__max_df=0.7444444444444445, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.7444444444444445, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2139.674836694193, total=  21.9s\n",
      "[CV] tfidf__max_df=0.7444444444444445, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.7444444444444445, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2080.961744817154, total=  37.4s\n",
      "[CV] tfidf__max_df=0.7444444444444445, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.7444444444444445, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2064.0262588973687, total=  37.0s\n",
      "[CV] tfidf__max_df=0.7444444444444445, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.7444444444444445, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2083.9666944942082, total=  50.3s\n",
      "[CV] tfidf__max_df=0.7444444444444445, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.7444444444444445, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2145.663342475798, total=  38.7s\n",
      "[CV] tfidf__max_df=0.7444444444444445, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.7444444444444445, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2143.4693705540694, total=  26.9s\n",
      "[CV] tfidf__max_df=0.8, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.8, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2140.731560542527, total=  26.4s\n",
      "[CV] tfidf__max_df=0.8, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.8, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2126.0122146313674, total=  31.3s\n",
      "[CV] tfidf__max_df=0.8, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.8, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2141.947820076083, total=  29.7s\n",
      "[CV] tfidf__max_df=0.8, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.8, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2179.278770373121, total=  15.3s\n",
      "[CV] tfidf__max_df=0.8, tfidf__ngram_range=(1, 1), tfidf__use_idf=True \n",
      "[CV]  tfidf__max_df=0.8, tfidf__ngram_range=(1, 1), tfidf__use_idf=True, score=-2139.674836694193, total=  21.8s\n",
      "[CV] tfidf__max_df=0.8, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.8, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2080.961744817154, total=  36.9s\n",
      "[CV] tfidf__max_df=0.8, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.8, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2064.0262588973687, total=  36.9s\n",
      "[CV] tfidf__max_df=0.8, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.8, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2083.9666944942082, total=  48.0s\n",
      "[CV] tfidf__max_df=0.8, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.8, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2145.663342475798, total=  38.5s\n",
      "[CV] tfidf__max_df=0.8, tfidf__ngram_range=(1, 1), tfidf__use_idf=False \n",
      "[CV]  tfidf__max_df=0.8, tfidf__ngram_range=(1, 1), tfidf__use_idf=False, score=-2143.4693705540694, total=  26.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed: 56.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,...20, n_init=3, n_jobs=None, precompute_distances='auto',\n",
       "    random_state=1, tol=0.0001, verbose=0))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'tfidf__ngram_range': [(1, 1)], 'tfidf__use_idf': (True, False), 'tfidf__max_df': array([0.3    , 0.35556, 0.41111, 0.46667, 0.52222, 0.57778, 0.63333,\n",
       "       0.68889, 0.74444, 0.8    ])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform 5-fold CV grid search using paramgrid and pipeline\n",
    "\n",
    "gridSearch = model_selection.GridSearchCV(tfidfPipe\n",
    "                                         ,paramGrid\n",
    "                                         ,cv = 5\n",
    "                                         ,verbose = 4\n",
    "                                         ,refit = True)\n",
    "gridSearch.fit(XTrain.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-29T00:14:07.396860Z",
     "start_time": "2018-10-29T00:14:05.599338Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "vec = tfidfPipe.named_steps['tfidf']\n",
    "XTrainVec = vec.fit_transform(XTrain.data)\n",
    "km = gridSearch.best_estimator_\n",
    "km.fit(XTrainVec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-29T00:15:40.273669Z",
     "start_time": "2018-10-29T00:15:40.259253Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(XTrain.target, km.labels_))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(XTrain.target, km.labels_))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(XTrain.target, km.labels_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-29T00:16:03.671878Z",
     "start_time": "2018-10-29T00:16:03.657844Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Adjusted Rand-Index: %.3f\"\n",
    "      % metrics.adjusted_rand_score(Labels, km.labels_))\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(X, km.labels_, sample_size=1000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
