{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project info - unsupervised learning with KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "The Scitkit-learn module 'datasets' includes the 20 News Groups dataset, which is a text dataset including roughly 18,000 articles on 20 different topics.\n",
    "\n",
    "The dataset includes labels for each article, but can also be analyzed in an unsupervised fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules and tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T15:14:12.749030Z",
     "start_time": "2018-12-02T15:14:12.737922Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:78% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Standard libary and settings\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import warnings\n",
    "from optparse import OptionParser\n",
    "from time import time\n",
    "warnings.simplefilter('ignore')\n",
    "dataPath = os.path.abspath(os.path.join('../Data'))\n",
    "modulePath = os.path.abspath(os.path.join('../CustomModules'))\n",
    "sys.path.append(modulePath) if modulePath not in sys.path else None\n",
    "from IPython.core.display import display, HTML; display(HTML(\"<style>.container { width:78% !important; }</style>\"))\n",
    "\n",
    "\n",
    "# Data extensions and settings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.options.display.float_format = '{:,.6f}'.format\n",
    "np.set_printoptions(threshold = np.inf, suppress = True)\n",
    "\n",
    "\n",
    "# Modeling extensions\n",
    "import sklearn.svm as svm\n",
    "import sklearn.base as base\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.pipeline as pipeline\n",
    "import sklearn.ensemble as ensemble\n",
    "import sklearn.linear_model as linear_model\n",
    "import sklearn.preprocessing as preprocessing\n",
    "import sklearn.model_selection as model_selection\n",
    "import sklearn.feature_selection as feature_selection\n",
    "import sklearn.feature_extraction as feature_extraction\n",
    "import sklearn.decomposition as decomposition\n",
    "import sklearn.datasets as datasets\n",
    "import sklearn.cluster as cluster\n",
    "\n",
    "\n",
    "# Visualization extensions and settings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Magic functions\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load, clean, inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T13:33:58.968815Z",
     "start_time": "2018-12-04T13:33:54.630718Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset dimensions: (4865,)\n"
     ]
    }
   ],
   "source": [
    "# Load data from scikit-learn\n",
    "\n",
    "X = datasets.fetch_20newsgroups(subset = 'all'\n",
    "                                ,remove = ('headers','footers','quotes')\n",
    "                                ,categories = ['talk.politics.guns','rec.sport.hockey','comp.graphics','sci.space','rec.motorcycles'])\n",
    "\n",
    "# Dataset dimensions\n",
    "\n",
    "print('Dataset dimensions: {0}'.format(X.filenames.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T13:34:04.050695Z",
     "start_time": "2018-12-04T13:34:04.045860Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4]), array([973, 996, 999, 987, 910]))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(X.target, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T13:34:05.706699Z",
     "start_time": "2018-12-04T13:34:05.701750Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comp.graphics',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.space',\n",
       " 'talk.politics.guns']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review article categories\n",
    "\n",
    "Labels = X.target_names\n",
    "Labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T13:34:18.738073Z",
     "start_time": "2018-12-04T13:34:18.734198Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Chemical weapons are not concidered a *very* effectiv weapon against\\nmillitary forces. On civillians on the other hand....\\n\\nThat's one GOOD reason for banning it.\\n\\nYou need VAST amounts of chemicals to be affective, so the best reason\\nto have/use it is price. (that's why it's called The Poor Mans A-bomb)\\n\\nAny thoughts on Bio-weapons ??\\t\\n\\nIf this discusion is about civillians having chem-weapons;\\nWhat should they use them on?? Rob a bank ??\\n\\n\\n\\n\\tThis is not a .signature.\\n\\tIt's merely a computergenerated text to waste bandwith\\n\\tand to bring down the evil Internet.\\n\""
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample from train data\n",
    "\n",
    "X.data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T13:34:18.746940Z",
     "start_time": "2018-12-04T13:34:18.740750Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'talk.politics.guns'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Corresponding label\n",
    "\n",
    "ix = X.target[0]\n",
    "Labels[ix]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert text to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T13:34:19.497689Z",
     "start_time": "2018-12-04T13:34:18.749086Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4865, 42619)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a bag of words model and use term frequency - inverse document frequency\n",
    "# to understand how common or uncommon each word that appears in each document\n",
    "# is relative to the rest of documents in the corpus\n",
    "\n",
    "tfidf = feature_extraction.text.TfidfVectorizer(max_df = 0.5\n",
    "                                               ,stop_words = 'english'\n",
    "                                               ,ngram_range = (1,1)\n",
    "                                               ,lowercase = True\n",
    "                                               ,strip_accents = 'unicode'\n",
    "                                              )\n",
    "\n",
    "tfidfPipe = pipeline.Pipeline([\n",
    "        ('vec', tfidf)\n",
    "    ])\n",
    "\n",
    "vectorized = tfidfPipe.fit_transform(X.data)\n",
    "vectorized.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T13:34:19.765264Z",
     "start_time": "2018-12-04T13:34:19.499839Z"
    }
   },
   "outputs": [],
   "source": [
    "# Capture all unique words\n",
    "\n",
    "vec = tfidfPipe.named_steps['vec']\n",
    "features = vec.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Document-specific word importances__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T13:34:19.771967Z",
     "start_time": "2018-12-04T13:34:19.767608Z"
    }
   },
   "outputs": [],
   "source": [
    "# Functions to determine word importance\n",
    "\n",
    "def top_tfidf_feats(row, features, top_n = 25):\n",
    "    \"\"\"\n",
    "    Get top n tfidf values in row and return them \n",
    "    with their corresponding feature names.\n",
    "    \"\"\"\n",
    "    topn_ids = np.argsort(row)[::-1][:top_n]\n",
    "    top_feats = [(features[i], row[i]) for i in topn_ids]\n",
    "    df = pd.DataFrame(top_feats)\n",
    "    df.columns = ['feature', 'tfidf']\n",
    "    return df\n",
    "\n",
    "def top_feats_in_doc(Xtr, features, row_id, top_n = 25):\n",
    "    \"\"\"\n",
    "    Top tfidf features in specific document (matrix row) \n",
    "    \"\"\"\n",
    "    row = np.squeeze(Xtr[row_id].toarray())\n",
    "    return top_tfidf_feats(row, features, top_n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate single article and word importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T13:34:19.778756Z",
     "start_time": "2018-12-04T13:34:19.774333Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nIf I may offer a constructive criticism, perhaps you should decide if you\\nlove vehicles or the use they are put to. I, myself, think the F-86 is\\na beautiful aircraft, but rest assured, I wouldn't even think of flying\\nit in combat today. Most of us want access to space and judge vehicles\\non how they perform.\\n\\n\\nNot to this degree.\\n\\n\\nWhy?\\n\\n\\nYour wrong. The DC approach is very tollerent of failure. It also has\\nthe advantage of far greater reliability do to its reusable nature (Shuttle\\nisn't reusable, it's salvagable).\\n\\n\\nThe flip over happens at a very low speed, not supersonic. If the DC-X\\nshows the flip over works, it will work unless the laws of physics change.\\n\\n\\nThe final DC-1 will have fully intact abort throughout the entire flight\\nenvelop. Upon re-entry for example, it can loose about 80% of available\\nthrust and still land safely.\\n\\n\\nEverything can suffer from catastrophic failure but that's not the same\\nthing. Shuttle simply isn't a fault tolerent design, SSTO is.\\n\\n\\nYou don't put your patients in conditions where there is no way out. You\\nwouldn't for example, give a patient a drug and not monitor them for\\nharmful side effects would you?\\n\\n\\nYou are very much in the minority. If the DC series fails to make orbit, it\\nwill still be a very worthwhile effort. It will show us EXACTLY what we do\\nneed to do to build SSTO.\\n\\n\\nAgain, refering to the DC-1, it will provide fully intact abort theroughout\\nthe flight envelop. Shuttle doesn't. DC is fault tollerent, Shuttle isn't.\\n\\n\\nNot true. Build a passenger pallet (a fairly easy thing to do) and it will\\ncarry passengers.\\n\\n\\nI would suggest you talk to the DC-X crew themselves. Their original\\nschedule had an operational DC-1 flying in 96.\\n\\n\\nYour ignoring the dammage it does. Mannes space has a reputation for being\\nunreliable and hugely expensive. Shuttle supporters only make it easy for\\nopponents of manned space to kill it.\\n\\n\\nThe only way to prove those things is to build it.\\n\\n  Allen\\n\""
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample from training data\n",
    "\n",
    "X.data[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T13:34:19.785447Z",
     "start_time": "2018-12-04T13:34:19.780918Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sci.space'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Corresponding label for that training sample\n",
    "\n",
    "ix = X.target[1]\n",
    "Labels[ix]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T13:34:19.799027Z",
     "start_time": "2018-12-04T13:34:19.787747Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dc</td>\n",
       "      <td>0.442381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shuttle</td>\n",
       "      <td>0.245136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>envelop</td>\n",
       "      <td>0.184074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tollerent</td>\n",
       "      <td>0.184074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>build</td>\n",
       "      <td>0.161937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>abort</td>\n",
       "      <td>0.155066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>flip</td>\n",
       "      <td>0.152601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>intact</td>\n",
       "      <td>0.148402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>reusable</td>\n",
       "      <td>0.143356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ssto</td>\n",
       "      <td>0.132968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature    tfidf\n",
       "0         dc 0.442381\n",
       "1    shuttle 0.245136\n",
       "2    envelop 0.184074\n",
       "3  tollerent 0.184074\n",
       "4      build 0.161937\n",
       "5      abort 0.155066\n",
       "6       flip 0.152601\n",
       "7     intact 0.148402\n",
       "8   reusable 0.143356\n",
       "9       ssto 0.132968"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print words based on highest word importance values, within a single document\n",
    "\n",
    "tfidfImp = top_feats_in_doc(vectorized, features, row_id = 1, top_n = 10)\n",
    "tfidfImp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Corpus-wide word importances__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T13:34:19.805135Z",
     "start_time": "2018-12-04T13:34:19.801044Z"
    }
   },
   "outputs": [],
   "source": [
    "# The function is used for identifying word importances, across entire corpus\n",
    "\n",
    "def top_mean_feats(Xtr, features, grp_ids = None, min_tfidf = 0.1, top_n = 25):\n",
    "    \"\"\"\n",
    "    Return the top n features that on average are most important amongst \n",
    "    documents in rows indentified by indices in grp_ids.\n",
    "    \"\"\"\n",
    "    if grp_ids:\n",
    "        D = Xtr[grp_ids].toarray()\n",
    "    else:\n",
    "        D = Xtr.toarray()\n",
    "\n",
    "    D[D < min_tfidf] = 0\n",
    "    tfidf_means = np.mean(D, axis=0)\n",
    "    return top_tfidf_feats(tfidf_means, features, top_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T13:34:21.438511Z",
     "start_time": "2018-12-04T13:34:19.808374Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>game</td>\n",
       "      <td>0.002047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dog</td>\n",
       "      <td>0.001838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gm</td>\n",
       "      <td>0.001543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>graphics</td>\n",
       "      <td>0.001445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bike</td>\n",
       "      <td>0.001400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>feustel</td>\n",
       "      <td>0.001276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>list</td>\n",
       "      <td>0.001187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>espn</td>\n",
       "      <td>0.001155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tiff</td>\n",
       "      <td>0.001071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>captain</td>\n",
       "      <td>0.001059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature    tfidf\n",
       "0      game 0.002047\n",
       "1       dog 0.001838\n",
       "2        gm 0.001543\n",
       "3  graphics 0.001445\n",
       "4      bike 0.001400\n",
       "5   feustel 0.001276\n",
       "6      list 0.001187\n",
       "7      espn 0.001155\n",
       "8      tiff 0.001071\n",
       "9   captain 0.001059"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print words based on highest word importance values, within the entire corpus\n",
    "\n",
    "top_mean_feats(vectorized, features, grp_ids = None, min_tfidf = 0.3, top_n = 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Category-specific word importances__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T13:34:21.444694Z",
     "start_time": "2018-12-04T13:34:21.440078Z"
    }
   },
   "outputs": [],
   "source": [
    "# The function is used for identifying word importances, within each document category\n",
    "\n",
    "def top_feats_by_class(Xtr, y, features, min_tfidf = 0.1, top_n = 25):\n",
    "    \"\"\"\n",
    "    Return a list of dfs, where each df holds top_n features and \n",
    "    their mean tfidf value calculated across documents with the \n",
    "    same class label.\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    labels = np.unique(y)\n",
    "    for label in labels:\n",
    "        ids = np.where(y == label)\n",
    "        feats_df = top_mean_feats(Xtr, features, ids\n",
    "                                  , min_tfidf = min_tfidf, top_n = top_n)\n",
    "        feats_df.label = label\n",
    "        dfs.append(feats_df)\n",
    "    return dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T13:34:23.102905Z",
     "start_time": "2018-12-04T13:34:21.447304Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print words based on highest word importance values, within each class of documents\n",
    "# In this case we're looking at atheism\n",
    "\n",
    "dfs = top_feats_by_class(vectorized, X.target, features\n",
    "                   , min_tfidf = 0.3, top_n = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T13:34:23.115711Z",
     "start_time": "2018-12-04T13:34:23.105050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top features within category type rec.motorcycles \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dog</td>\n",
       "      <td>0.008978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bike</td>\n",
       "      <td>0.006840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>helmet</td>\n",
       "      <td>0.003991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bmw</td>\n",
       "      <td>0.003601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>list</td>\n",
       "      <td>0.003596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>shaft</td>\n",
       "      <td>0.003569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tony</td>\n",
       "      <td>0.003293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>honda</td>\n",
       "      <td>0.003292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lock</td>\n",
       "      <td>0.003257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>drive</td>\n",
       "      <td>0.003177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature    tfidf\n",
       "0     dog 0.008978\n",
       "1    bike 0.006840\n",
       "2  helmet 0.003991\n",
       "3     bmw 0.003601\n",
       "4    list 0.003596\n",
       "5   shaft 0.003569\n",
       "6    tony 0.003293\n",
       "7   honda 0.003292\n",
       "8    lock 0.003257\n",
       "9   drive 0.003177"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Review top words by importance for a specific class\n",
    "\n",
    "topicIx = 1\n",
    "\n",
    "print('Top features within category type {0} \\n'.format(Labels[topicIx]))\n",
    "display(dfs[topicIx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster analysis\n",
    "\n",
    "This section executes cluster analysis, an unsupervised learning technique, on the documents. It groups individual documents with other document that are determined by the algorithm to be similar. In this model, we will use KMeans to find K different clusters. In this case, we will use k = 20, because we know ther are 20 different categories. We can then compare the documents and their cluster labels to the actual labels to see how well KMeans performed its unsupervised learning task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T13:34:23.123450Z",
     "start_time": "2018-12-04T13:34:23.117656Z"
    }
   },
   "outputs": [],
   "source": [
    "def gridSearch(data, params):\n",
    "    tfidf = feature_extraction.text.TfidfVectorizer(stop_words = 'english'\n",
    "                                                   ,lowercase = True\n",
    "                                                   ,strip_accents = 'unicode')\n",
    "\n",
    "    lr_tfidf = pipeline.Pipeline([('vect', tfidf),\n",
    "                                 ('clf', cluster.KMeans(init = 'k-means++'\n",
    "                                                        ,n_clusters = 5\n",
    "                                                        ,random_state = 0\n",
    "                                                        ,verbose = 0))])\n",
    "    gsTfIdf = model_selection.GridSearchCV(lr_tfidf\n",
    "                                           ,params\n",
    "                                           ,verbose = 1\n",
    "                                           ,refit = True)\n",
    "\n",
    "    gsTfIdf.fit(data)\n",
    "    print()\n",
    "    print(\"Best score: %0.3f\" % gsTfIdf.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = gsTfIdf.best_estimator_.get_params()\n",
    "    for param_name in sorted(params.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    return gsTfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T15:46:24.247252Z",
     "start_time": "2018-12-04T13:34:23.125711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 240 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 720 out of 720 | elapsed: 131.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best score: -99.840\n",
      "Best parameters set:\n",
      "\tvect__max_df: 0.25\n",
      "\tvect__max_features: 14000\n",
      "\tvect__ngram_range: (1, 1)\n",
      "\tvect__norm: 'l1'\n",
      "\tvect__use_idf: False\n"
     ]
    }
   ],
   "source": [
    "paramGrid = {'vect__ngram_range': [(1, 1)]\n",
    "              ,'vect__use_idf': (True, False)\n",
    "              ,'vect__max_df' :  np.linspace(0.25, 0.75, 4)\n",
    "              ,'vect__max_features' : np.arange(5000, 14001, 1000)\n",
    "              ,'vect__norm' : ['l1', 'l2', None]\n",
    "}\n",
    "\n",
    "gsTfIdf = gridSearch(X.data, paramGrid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T15:46:24.902241Z",
     "start_time": "2018-12-04T15:46:24.249706Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replicate best model as chosen by GridSearchCV\n",
    "\n",
    "tfidf = feature_extraction.text.TfidfVectorizer(max_df = 0.25\n",
    "                                                ,max_features = 14000\n",
    "                                                ,norm = 'l1'\n",
    "                                                ,stop_words = 'english'\n",
    "                                                ,ngram_range = (1,1)\n",
    "                                                ,lowercase = True\n",
    "                                                ,strip_accents = 'unicode'\n",
    "                                                ,use_idf = False\n",
    "                                               )\n",
    "\n",
    "XTrainVec = tfidf.fit_transform(X.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T04:36:57.083572Z",
     "start_time": "2018-12-05T04:34:56.177705Z"
    }
   },
   "outputs": [],
   "source": [
    "distortions = []\n",
    "for i in range(1,15):\n",
    "    km = cluster.KMeans(n_clusters = i\n",
    "                       ,init = 'k-means++'\n",
    "                       ,n_init = 3\n",
    "                       ,max_iter = 100\n",
    "                       ,random_state = 0)\n",
    "    km.fit(XTrainVec)\n",
    "    distortions.append(km.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T04:36:57.090371Z",
     "start_time": "2018-12-05T04:36:57.085714Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[291.27830287180535,\n",
       " 290.451356440413,\n",
       " 289.6718446544072,\n",
       " 288.81056542901734,\n",
       " 286.95281226036235,\n",
       " 287.21441029252907,\n",
       " 285.4224657502927,\n",
       " 284.51875688866073,\n",
       " 285.1047063620473,\n",
       " 284.9120815733429,\n",
       " 284.16913518948957,\n",
       " 282.7059269293158,\n",
       " 281.1250932311441,\n",
       " 281.2212709090196]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distortions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T02:12:58.410482Z",
     "start_time": "2018-12-03T02:12:42.210828Z"
    }
   },
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "kmlabels = gridSearch.best_estimator_.fit_predict(X.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T03:14:26.771440Z",
     "start_time": "2018-12-02T03:14:26.753712Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.269\n",
      "Completeness: 0.341\n",
      "V-measure: 0.301\n"
     ]
    }
   ],
   "source": [
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(X.target, km.labels_))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(X.target, km.labels_))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(X.target, km.labels_))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
